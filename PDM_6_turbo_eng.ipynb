{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "740f4b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.signal import savgol_filter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression,SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score,classification_report, confusion_matrix, mean_absolute_error, mean_squared_error,r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor,AdaBoostRegressor, BaggingRegressor\n",
    "from sklearn.svm import SVR,LinearSVR,NuSVR\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras.backend as K\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Bidirectional, GRU, LSTM, RepeatVector, TimeDistributed,Conv1D,MaxPooling1D,ReLU,UpSampling1D,Input,LeakyReLU\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.merge import concatenate\n",
    "from tensorflow.keras.layers import Average\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pywt\n",
    "from scipy.fft import fft,ifft\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "891eeb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train_FD001.txt', sep = ' ', header = None)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "be915424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_act = data[[f for f in range(0, 26)]]\n",
    "data_act.columns = [\"ID\", \"Cycle\", \"OpSet1\", \"OpSet2\", \"OpSet3\", \"SensorMeasure1\", \"SensorMeasure2\", \"SensorMeasure3\", \"SensorMeasure4\",\n",
    "                \"SensorMeasure5\", \"SensorMeasure6\", \"SensorMeasure7\", \"SensorMeasure8\", \"SensorMeasure9\", \"SensorMeasure10\", \"SensorMeasure11\",\n",
    "                \"SensorMeasure12\", \"SensorMeasure13\", \"SensorMeasure14\", \"SensorMeasure15\", \"SensorMeasure16\",\n",
    "                \"SensorMeasure17\", \"SensorMeasure18\", \"SensorMeasure19\", \"SensorMeasure20\", \"SensorMeasure21\"]\n",
    "len(np.unique(data_act['OpSet2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58435279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MaxCycleID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  MaxCycleID\n",
       "0   1         192\n",
       "1   2         287\n",
       "2   3         179\n",
       "3   4         189\n",
       "4   5         269"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_cycles_df = data_act.groupby([\"ID\"], sort=False)[\"Cycle\"].max().reset_index().rename(columns={\"Cycle\" : \"MaxCycleID\"})\n",
    "max_cycles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d33f375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>OpSet1</th>\n",
       "      <th>OpSet2</th>\n",
       "      <th>OpSet3</th>\n",
       "      <th>SensorMeasure1</th>\n",
       "      <th>SensorMeasure2</th>\n",
       "      <th>SensorMeasure3</th>\n",
       "      <th>SensorMeasure4</th>\n",
       "      <th>SensorMeasure5</th>\n",
       "      <th>...</th>\n",
       "      <th>SensorMeasure14</th>\n",
       "      <th>SensorMeasure15</th>\n",
       "      <th>SensorMeasure16</th>\n",
       "      <th>SensorMeasure17</th>\n",
       "      <th>SensorMeasure18</th>\n",
       "      <th>SensorMeasure19</th>\n",
       "      <th>SensorMeasure20</th>\n",
       "      <th>SensorMeasure21</th>\n",
       "      <th>MaxCycleID</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>192</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>192</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>192</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>192</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>192</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Cycle  OpSet1  OpSet2  OpSet3  SensorMeasure1  SensorMeasure2  \\\n",
       "0   1      1 -0.0007 -0.0004   100.0          518.67          641.82   \n",
       "1   1      2  0.0019 -0.0003   100.0          518.67          642.15   \n",
       "2   1      3 -0.0043  0.0003   100.0          518.67          642.35   \n",
       "3   1      4  0.0007  0.0000   100.0          518.67          642.35   \n",
       "4   1      5 -0.0019 -0.0002   100.0          518.67          642.37   \n",
       "\n",
       "   SensorMeasure3  SensorMeasure4  SensorMeasure5  ...  SensorMeasure14  \\\n",
       "0         1589.70         1400.60           14.62  ...          8138.62   \n",
       "1         1591.82         1403.14           14.62  ...          8131.49   \n",
       "2         1587.99         1404.20           14.62  ...          8133.23   \n",
       "3         1582.79         1401.87           14.62  ...          8133.83   \n",
       "4         1582.85         1406.22           14.62  ...          8133.80   \n",
       "\n",
       "   SensorMeasure15  SensorMeasure16  SensorMeasure17  SensorMeasure18  \\\n",
       "0           8.4195             0.03              392             2388   \n",
       "1           8.4318             0.03              392             2388   \n",
       "2           8.4178             0.03              390             2388   \n",
       "3           8.3682             0.03              392             2388   \n",
       "4           8.4294             0.03              393             2388   \n",
       "\n",
       "   SensorMeasure19  SensorMeasure20  SensorMeasure21  MaxCycleID  RUL  \n",
       "0            100.0            39.06          23.4190         192  191  \n",
       "1            100.0            39.00          23.4236         192  190  \n",
       "2            100.0            38.95          23.3442         192  189  \n",
       "3            100.0            38.88          23.3739         192  188  \n",
       "4            100.0            38.90          23.4044         192  187  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FD001_df = pd.merge(data_act, max_cycles_df, how=\"inner\", on=\"ID\")\n",
    "FD001_df[\"RUL\"] = FD001_df[\"MaxCycleID\"] - FD001_df[\"Cycle\"]\n",
    "FD001_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "63d00c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0003\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "df_FD001 = FD001_df.copy().drop(columns=[\"ID\", \"Cycle\", \"OpSet1\",\"OpSet2\",\"OpSet3\", \"MaxCycleID\", \"RUL\"], axis=1)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "# print(df_FD001)\n",
    "scaled_df_FD001 = pd.DataFrame(scaler.fit_transform(df_FD001.values))\n",
    "scaled_df_FD001 = FD001_df[[\"ID\", \"Cycle\", \"RUL\", \"OpSet1\",\"OpSet2\",\"OpSet3\"]].join(scaled_df_FD001)\n",
    "scaled_df_FD001.columns = [\"ID\", \"Cycle\",\"RUL\",\"OpSet1\",\"OpSet2\", \"OpSet3\",\"SensorMeasure1\", \"SensorMeasure2\", \"SensorMeasure3\", \"SensorMeasure4\",\n",
    "                \"SensorMeasure5\", \"SensorMeasure6\", \"SensorMeasure7\", \"SensorMeasure8\", \"SensorMeasure9\", \"SensorMeasure10\", \"SensorMeasure11\",\n",
    "                \"SensorMeasure12\", \"SensorMeasure13\", \"SensorMeasure14\", \"SensorMeasure15\", \"SensorMeasure16\",\n",
    "                \"SensorMeasure17\", \"SensorMeasure18\", \"SensorMeasure19\", \"SensorMeasure20\", \"SensorMeasure21\"]\n",
    "print(scaled_df_FD001['OpSet2'].value_counts().idxmax())\n",
    "print(scaled_df_FD001['OpSet1'].value_counts().idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d8e75c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20631, 158)\n",
      "(20631, 13)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "enc_opset1 = OneHotEncoder()\n",
    "enc_opset2 = OneHotEncoder()\n",
    "opset1_enc = enc_opset1.fit_transform(scaled_df_FD001['OpSet1'].values.reshape(-1,1)).toarray()\n",
    "print(opset1_enc.shape)\n",
    "opset2_enc = enc_opset2.fit_transform(scaled_df_FD001['OpSet2'].values.reshape(-1,1)).toarray()\n",
    "print(opset2_enc.shape)\n",
    "print(type(opset1_enc))\n",
    "print(type(opset2_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e49d3b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Cycle', 'RUL', 'OpSet1', 'OpSet2', 'OpSet3', 'SensorMeasure2',\n",
       "       'SensorMeasure3', 'SensorMeasure4', 'SensorMeasure7', 'SensorMeasure8',\n",
       "       'SensorMeasure9', 'SensorMeasure11', 'SensorMeasure12',\n",
       "       'SensorMeasure13', 'SensorMeasure14', 'SensorMeasure15',\n",
       "       'SensorMeasure17', 'SensorMeasure20', 'SensorMeasure21'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_clean_df_FD001 = scaled_df_FD001.drop(columns=[\"SensorMeasure1\", \"SensorMeasure5\", \"SensorMeasure6\", \"SensorMeasure10\",\n",
    "                                         \"SensorMeasure16\", \"SensorMeasure18\", \"SensorMeasure19\"])\n",
    "scaled_clean_df_FD001.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef49fba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = ['SensorMeasure2',\n",
    "       'SensorMeasure3', 'SensorMeasure4', 'SensorMeasure7', 'SensorMeasure8',\n",
    "       'SensorMeasure9', 'SensorMeasure11', 'SensorMeasure12',\n",
    "       'SensorMeasure13', 'SensorMeasure14', 'SensorMeasure15',\n",
    "       'SensorMeasure17', 'SensorMeasure20', 'SensorMeasure21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d97af52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20631, 14)\n",
      "<class 'numpy.ndarray'>\n",
      "(20631, 185)\n",
      "(20631,)\n"
     ]
    }
   ],
   "source": [
    "X_num_tr = scaled_clean_df_FD001[num_col].values\n",
    "print(X_num_tr.shape)\n",
    "print(type(X_num_tr))\n",
    "X_tr = np.concatenate([X_num_tr,opset1_enc,opset2_enc], axis = 1)\n",
    "print(X_tr.shape)\n",
    "y_tr = scaled_clean_df_FD001['RUL'].values\n",
    "print(y_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f0ccb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_tr)\n",
    "var_comp = np.cumsum(pca.explained_variance_ratio_).tolist()\n",
    "# print(var_comp)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')\n",
    "for i in range(len(var_comp)):\n",
    "    if var_comp[i] > 0.95:\n",
    "        print(i+1)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "646966fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=93)\n",
    "X_tr_pc = pca.fit_transform(X_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "969cdadb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>OpSet1</th>\n",
       "      <th>OpSet2</th>\n",
       "      <th>OpSet3</th>\n",
       "      <th>SensorMeasure1</th>\n",
       "      <th>SensorMeasure2</th>\n",
       "      <th>SensorMeasure3</th>\n",
       "      <th>SensorMeasure4</th>\n",
       "      <th>SensorMeasure5</th>\n",
       "      <th>...</th>\n",
       "      <th>SensorMeasure12</th>\n",
       "      <th>SensorMeasure13</th>\n",
       "      <th>SensorMeasure14</th>\n",
       "      <th>SensorMeasure15</th>\n",
       "      <th>SensorMeasure16</th>\n",
       "      <th>SensorMeasure17</th>\n",
       "      <th>SensorMeasure18</th>\n",
       "      <th>SensorMeasure19</th>\n",
       "      <th>SensorMeasure20</th>\n",
       "      <th>SensorMeasure21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.02</td>\n",
       "      <td>1585.29</td>\n",
       "      <td>1398.21</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.72</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8125.55</td>\n",
       "      <td>8.4052</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.86</td>\n",
       "      <td>23.3735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.71</td>\n",
       "      <td>1588.45</td>\n",
       "      <td>1395.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.16</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>8139.62</td>\n",
       "      <td>8.3803</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.02</td>\n",
       "      <td>23.3916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.46</td>\n",
       "      <td>1586.94</td>\n",
       "      <td>1401.34</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.97</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8130.10</td>\n",
       "      <td>8.4441</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.08</td>\n",
       "      <td>23.4166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.44</td>\n",
       "      <td>1584.12</td>\n",
       "      <td>1406.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.38</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8132.90</td>\n",
       "      <td>8.3917</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.3737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.51</td>\n",
       "      <td>1587.19</td>\n",
       "      <td>1401.92</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.15</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8129.54</td>\n",
       "      <td>8.4031</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.4130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Cycle  OpSet1  OpSet2  OpSet3  SensorMeasure1  SensorMeasure2  \\\n",
       "0   1      1  0.0023  0.0003   100.0          518.67          643.02   \n",
       "1   1      2 -0.0027 -0.0003   100.0          518.67          641.71   \n",
       "2   1      3  0.0003  0.0001   100.0          518.67          642.46   \n",
       "3   1      4  0.0042  0.0000   100.0          518.67          642.44   \n",
       "4   1      5  0.0014  0.0000   100.0          518.67          642.51   \n",
       "\n",
       "   SensorMeasure3  SensorMeasure4  SensorMeasure5  ...  SensorMeasure12  \\\n",
       "0         1585.29         1398.21           14.62  ...           521.72   \n",
       "1         1588.45         1395.42           14.62  ...           522.16   \n",
       "2         1586.94         1401.34           14.62  ...           521.97   \n",
       "3         1584.12         1406.42           14.62  ...           521.38   \n",
       "4         1587.19         1401.92           14.62  ...           522.15   \n",
       "\n",
       "   SensorMeasure13  SensorMeasure14  SensorMeasure15  SensorMeasure16  \\\n",
       "0          2388.03          8125.55           8.4052             0.03   \n",
       "1          2388.06          8139.62           8.3803             0.03   \n",
       "2          2388.03          8130.10           8.4441             0.03   \n",
       "3          2388.05          8132.90           8.3917             0.03   \n",
       "4          2388.03          8129.54           8.4031             0.03   \n",
       "\n",
       "   SensorMeasure17  SensorMeasure18  SensorMeasure19  SensorMeasure20  \\\n",
       "0              392             2388            100.0            38.86   \n",
       "1              393             2388            100.0            39.02   \n",
       "2              393             2388            100.0            39.08   \n",
       "3              391             2388            100.0            39.00   \n",
       "4              390             2388            100.0            38.99   \n",
       "\n",
       "   SensorMeasure21  \n",
       "0          23.3735  \n",
       "1          23.3916  \n",
       "2          23.4166  \n",
       "3          23.3737  \n",
       "4          23.4130  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_FD001 = pd.read_csv('test_FD001.txt', sep = ' ', header = None)\n",
    "test_data_FD001 = test_data_FD001[[f for f in range(0, 26)]]\n",
    "test_data_FD001.columns = [\"ID\", \"Cycle\", \"OpSet1\", \"OpSet2\", \"OpSet3\", \"SensorMeasure1\", \"SensorMeasure2\", \"SensorMeasure3\", \"SensorMeasure4\",\n",
    "                \"SensorMeasure5\", \"SensorMeasure6\", \"SensorMeasure7\", \"SensorMeasure8\", \"SensorMeasure9\", \"SensorMeasure10\", \"SensorMeasure11\",\n",
    "                \"SensorMeasure12\", \"SensorMeasure13\", \"SensorMeasure14\", \"SensorMeasure15\", \"SensorMeasure16\",\n",
    "                \"SensorMeasure17\", \"SensorMeasure18\", \"SensorMeasure19\", \"SensorMeasure20\", \"SensorMeasure21\"]\n",
    "test_data_FD001.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b646c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MaxCycleID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  MaxCycleID\n",
       "0   1          31\n",
       "1   2          49\n",
       "2   3         126\n",
       "3   4         106\n",
       "4   5          98"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_cycles_df_test = test_data_FD001.groupby([\"ID\"], sort=False)[\"Cycle\"].max().reset_index().rename(columns={\"Cycle\" : \"MaxCycleID\"})\n",
    "max_cycles_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "413235a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Eng_rul</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Eng_rul  ID\n",
       "0      112   1\n",
       "1       98   2\n",
       "2       69   3\n",
       "3       82   4\n",
       "4       91   5"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_rul_FD001 = pd.read_csv('RUL_FD001.txt', header = None)\n",
    "y_test_rul_FD001.columns = ['Eng_rul']\n",
    "y_test_rul_FD001['ID'] = max_cycles_df_test['ID']\n",
    "y_test_rul_FD001.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aab32967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>MaxCycleID</th>\n",
       "      <th>MaxCycleIDAct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>106</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>98</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  MaxCycleID  MaxCycleIDAct\n",
       "0   1          31            143\n",
       "1   2          49            147\n",
       "2   3         126            195\n",
       "3   4         106            188\n",
       "4   5          98            189"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_cycles_df_test['MaxCycleIDAct'] = y_test_rul_FD001['Eng_rul']+ max_cycles_df_test['MaxCycleID']\n",
    "max_cycles_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c38a927e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>OpSet1</th>\n",
       "      <th>OpSet2</th>\n",
       "      <th>OpSet3</th>\n",
       "      <th>SensorMeasure1</th>\n",
       "      <th>SensorMeasure2</th>\n",
       "      <th>SensorMeasure3</th>\n",
       "      <th>SensorMeasure4</th>\n",
       "      <th>SensorMeasure5</th>\n",
       "      <th>...</th>\n",
       "      <th>SensorMeasure14</th>\n",
       "      <th>SensorMeasure15</th>\n",
       "      <th>SensorMeasure16</th>\n",
       "      <th>SensorMeasure17</th>\n",
       "      <th>SensorMeasure18</th>\n",
       "      <th>SensorMeasure19</th>\n",
       "      <th>SensorMeasure20</th>\n",
       "      <th>SensorMeasure21</th>\n",
       "      <th>MaxCycleID</th>\n",
       "      <th>MaxCycleIDAct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.02</td>\n",
       "      <td>1585.29</td>\n",
       "      <td>1398.21</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8125.55</td>\n",
       "      <td>8.4052</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.86</td>\n",
       "      <td>23.3735</td>\n",
       "      <td>31</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.71</td>\n",
       "      <td>1588.45</td>\n",
       "      <td>1395.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8139.62</td>\n",
       "      <td>8.3803</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.02</td>\n",
       "      <td>23.3916</td>\n",
       "      <td>31</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.46</td>\n",
       "      <td>1586.94</td>\n",
       "      <td>1401.34</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8130.10</td>\n",
       "      <td>8.4441</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.08</td>\n",
       "      <td>23.4166</td>\n",
       "      <td>31</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.44</td>\n",
       "      <td>1584.12</td>\n",
       "      <td>1406.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8132.90</td>\n",
       "      <td>8.3917</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.3737</td>\n",
       "      <td>31</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.51</td>\n",
       "      <td>1587.19</td>\n",
       "      <td>1401.92</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8129.54</td>\n",
       "      <td>8.4031</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.4130</td>\n",
       "      <td>31</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Cycle  OpSet1  OpSet2  OpSet3  SensorMeasure1  SensorMeasure2  \\\n",
       "0   1      1  0.0023  0.0003   100.0          518.67          643.02   \n",
       "1   1      2 -0.0027 -0.0003   100.0          518.67          641.71   \n",
       "2   1      3  0.0003  0.0001   100.0          518.67          642.46   \n",
       "3   1      4  0.0042  0.0000   100.0          518.67          642.44   \n",
       "4   1      5  0.0014  0.0000   100.0          518.67          642.51   \n",
       "\n",
       "   SensorMeasure3  SensorMeasure4  SensorMeasure5  ...  SensorMeasure14  \\\n",
       "0         1585.29         1398.21           14.62  ...          8125.55   \n",
       "1         1588.45         1395.42           14.62  ...          8139.62   \n",
       "2         1586.94         1401.34           14.62  ...          8130.10   \n",
       "3         1584.12         1406.42           14.62  ...          8132.90   \n",
       "4         1587.19         1401.92           14.62  ...          8129.54   \n",
       "\n",
       "   SensorMeasure15  SensorMeasure16  SensorMeasure17  SensorMeasure18  \\\n",
       "0           8.4052             0.03              392             2388   \n",
       "1           8.3803             0.03              393             2388   \n",
       "2           8.4441             0.03              393             2388   \n",
       "3           8.3917             0.03              391             2388   \n",
       "4           8.4031             0.03              390             2388   \n",
       "\n",
       "   SensorMeasure19  SensorMeasure20  SensorMeasure21  MaxCycleID  \\\n",
       "0            100.0            38.86          23.3735          31   \n",
       "1            100.0            39.02          23.3916          31   \n",
       "2            100.0            39.08          23.4166          31   \n",
       "3            100.0            39.00          23.3737          31   \n",
       "4            100.0            38.99          23.4130          31   \n",
       "\n",
       "   MaxCycleIDAct  \n",
       "0            143  \n",
       "1            143  \n",
       "2            143  \n",
       "3            143  \n",
       "4            143  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_FD001 = pd.merge(test_data_FD001, max_cycles_df_test, how=\"inner\", on=\"ID\")\n",
    "test_df_FD001.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8105966f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>OpSet1</th>\n",
       "      <th>OpSet2</th>\n",
       "      <th>OpSet3</th>\n",
       "      <th>SensorMeasure1</th>\n",
       "      <th>SensorMeasure2</th>\n",
       "      <th>SensorMeasure3</th>\n",
       "      <th>SensorMeasure4</th>\n",
       "      <th>SensorMeasure5</th>\n",
       "      <th>...</th>\n",
       "      <th>SensorMeasure15</th>\n",
       "      <th>SensorMeasure16</th>\n",
       "      <th>SensorMeasure17</th>\n",
       "      <th>SensorMeasure18</th>\n",
       "      <th>SensorMeasure19</th>\n",
       "      <th>SensorMeasure20</th>\n",
       "      <th>SensorMeasure21</th>\n",
       "      <th>MaxCycleID</th>\n",
       "      <th>MaxCycleIDAct</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.02</td>\n",
       "      <td>1585.29</td>\n",
       "      <td>1398.21</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4052</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.86</td>\n",
       "      <td>23.3735</td>\n",
       "      <td>31</td>\n",
       "      <td>143</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.71</td>\n",
       "      <td>1588.45</td>\n",
       "      <td>1395.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.3803</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.02</td>\n",
       "      <td>23.3916</td>\n",
       "      <td>31</td>\n",
       "      <td>143</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.46</td>\n",
       "      <td>1586.94</td>\n",
       "      <td>1401.34</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4441</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.08</td>\n",
       "      <td>23.4166</td>\n",
       "      <td>31</td>\n",
       "      <td>143</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.44</td>\n",
       "      <td>1584.12</td>\n",
       "      <td>1406.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.3917</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.3737</td>\n",
       "      <td>31</td>\n",
       "      <td>143</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.51</td>\n",
       "      <td>1587.19</td>\n",
       "      <td>1401.92</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4031</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.4130</td>\n",
       "      <td>31</td>\n",
       "      <td>143</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Cycle  OpSet1  OpSet2  OpSet3  SensorMeasure1  SensorMeasure2  \\\n",
       "0   1      1  0.0023  0.0003   100.0          518.67          643.02   \n",
       "1   1      2 -0.0027 -0.0003   100.0          518.67          641.71   \n",
       "2   1      3  0.0003  0.0001   100.0          518.67          642.46   \n",
       "3   1      4  0.0042  0.0000   100.0          518.67          642.44   \n",
       "4   1      5  0.0014  0.0000   100.0          518.67          642.51   \n",
       "\n",
       "   SensorMeasure3  SensorMeasure4  SensorMeasure5  ...  SensorMeasure15  \\\n",
       "0         1585.29         1398.21           14.62  ...           8.4052   \n",
       "1         1588.45         1395.42           14.62  ...           8.3803   \n",
       "2         1586.94         1401.34           14.62  ...           8.4441   \n",
       "3         1584.12         1406.42           14.62  ...           8.3917   \n",
       "4         1587.19         1401.92           14.62  ...           8.4031   \n",
       "\n",
       "   SensorMeasure16  SensorMeasure17  SensorMeasure18  SensorMeasure19  \\\n",
       "0             0.03              392             2388            100.0   \n",
       "1             0.03              393             2388            100.0   \n",
       "2             0.03              393             2388            100.0   \n",
       "3             0.03              391             2388            100.0   \n",
       "4             0.03              390             2388            100.0   \n",
       "\n",
       "   SensorMeasure20  SensorMeasure21  MaxCycleID  MaxCycleIDAct  RUL  \n",
       "0            38.86          23.3735          31            143  142  \n",
       "1            39.02          23.3916          31            143  141  \n",
       "2            39.08          23.4166          31            143  140  \n",
       "3            39.00          23.3737          31            143  139  \n",
       "4            38.99          23.4130          31            143  138  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_FD001[\"RUL\"] = test_df_FD001[\"MaxCycleIDAct\"] - test_df_FD001[\"Cycle\"]\n",
    "test_df_FD001.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2ec9582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Cycle</th>\n",
       "      <th>RUL</th>\n",
       "      <th>OpSet1</th>\n",
       "      <th>OpSet2</th>\n",
       "      <th>OpSet3</th>\n",
       "      <th>SensorMeasure1</th>\n",
       "      <th>SensorMeasure2</th>\n",
       "      <th>SensorMeasure3</th>\n",
       "      <th>SensorMeasure4</th>\n",
       "      <th>...</th>\n",
       "      <th>SensorMeasure12</th>\n",
       "      <th>SensorMeasure13</th>\n",
       "      <th>SensorMeasure14</th>\n",
       "      <th>SensorMeasure15</th>\n",
       "      <th>SensorMeasure16</th>\n",
       "      <th>SensorMeasure17</th>\n",
       "      <th>SensorMeasure18</th>\n",
       "      <th>SensorMeasure19</th>\n",
       "      <th>SensorMeasure20</th>\n",
       "      <th>SensorMeasure21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545181</td>\n",
       "      <td>0.310661</td>\n",
       "      <td>0.269413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646055</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.132160</td>\n",
       "      <td>0.308965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.661834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>141</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.379551</td>\n",
       "      <td>0.222316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739872</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.204768</td>\n",
       "      <td>0.213159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682171</td>\n",
       "      <td>0.686827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376506</td>\n",
       "      <td>0.346632</td>\n",
       "      <td>0.322248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699360</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.155640</td>\n",
       "      <td>0.458638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.721348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>139</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370482</td>\n",
       "      <td>0.285154</td>\n",
       "      <td>0.408001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573561</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.170090</td>\n",
       "      <td>0.257022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.662110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>138</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391566</td>\n",
       "      <td>0.352082</td>\n",
       "      <td>0.332039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737740</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.152751</td>\n",
       "      <td>0.300885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.716377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Cycle  RUL  OpSet1  OpSet2  OpSet3  SensorMeasure1  SensorMeasure2  \\\n",
       "0   1      1  142  0.0023  0.0003   100.0             0.0        0.545181   \n",
       "1   1      2  141 -0.0027 -0.0003   100.0             0.0        0.150602   \n",
       "2   1      3  140  0.0003  0.0001   100.0             0.0        0.376506   \n",
       "3   1      4  139  0.0042  0.0000   100.0             0.0        0.370482   \n",
       "4   1      5  138  0.0014  0.0000   100.0             0.0        0.391566   \n",
       "\n",
       "   SensorMeasure3  SensorMeasure4  ...  SensorMeasure12  SensorMeasure13  \\\n",
       "0        0.310661        0.269413  ...         0.646055         0.220588   \n",
       "1        0.379551        0.222316  ...         0.739872         0.264706   \n",
       "2        0.346632        0.322248  ...         0.699360         0.220588   \n",
       "3        0.285154        0.408001  ...         0.573561         0.250000   \n",
       "4        0.352082        0.332039  ...         0.737740         0.220588   \n",
       "\n",
       "   SensorMeasure14  SensorMeasure15  SensorMeasure16  SensorMeasure17  \\\n",
       "0         0.132160         0.308965              0.0         0.333333   \n",
       "1         0.204768         0.213159              0.0         0.416667   \n",
       "2         0.155640         0.458638              0.0         0.416667   \n",
       "3         0.170090         0.257022              0.0         0.250000   \n",
       "4         0.152751         0.300885              0.0         0.166667   \n",
       "\n",
       "   SensorMeasure18  SensorMeasure19  SensorMeasure20  SensorMeasure21  \n",
       "0              0.0              0.0         0.558140         0.661834  \n",
       "1              0.0              0.0         0.682171         0.686827  \n",
       "2              0.0              0.0         0.728682         0.721348  \n",
       "3              0.0              0.0         0.666667         0.662110  \n",
       "4              0.0              0.0         0.658915         0.716377  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_df_FD001 = test_df_FD001.copy().drop(columns=[\"ID\", \"Cycle\", \"OpSet1\", \"OpSet2\",\"OpSet3\", \"MaxCycleID\", \"MaxCycleIDAct\",\"RUL\"], axis=1)\n",
    "# print(te_df_FD001)\n",
    "scaled_te_df_FD001 = pd.DataFrame(scaler.transform(te_df_FD001.values))\n",
    "scaled_te_df_FD001 = test_df_FD001[[\"ID\", \"Cycle\", \"RUL\",\"OpSet1\",\"OpSet2\",\"OpSet3\"]].join(scaled_te_df_FD001)\n",
    "scaled_te_df_FD001.columns = [\"ID\", \"Cycle\",\"RUL\", \"OpSet1\", \"OpSet2\", \"OpSet3\",\"SensorMeasure1\", \"SensorMeasure2\", \"SensorMeasure3\", \"SensorMeasure4\",\n",
    "                \"SensorMeasure5\", \"SensorMeasure6\", \"SensorMeasure7\", \"SensorMeasure8\", \"SensorMeasure9\", \"SensorMeasure10\", \"SensorMeasure11\",\n",
    "                \"SensorMeasure12\", \"SensorMeasure13\", \"SensorMeasure14\", \"SensorMeasure15\", \"SensorMeasure16\",\n",
    "                \"SensorMeasure17\", \"SensorMeasure18\", \"SensorMeasure19\", \"SensorMeasure20\", \"SensorMeasure21\"]\n",
    "scaled_te_df_FD001.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6959106b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shivam.bhardwaj/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "unknown_opset1 = [-0.0082, -0.0079, -0.0077, -0.0071, 0.0075, 0.0078]\n",
    "unknown_opset2 = [0.0007]\n",
    "for i in range(13096):\n",
    "    if scaled_te_df_FD001['OpSet1'].iloc[i] in unknown_opset1:\n",
    "        scaled_te_df_FD001['OpSet1'].iloc[i] = 0.0000\n",
    "    if scaled_te_df_FD001['OpSet2'].iloc[i] in unknown_opset2:\n",
    "        scaled_te_df_FD001['OpSet2'].iloc[i] = -0.0003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a9839fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "opset1_enc_te = enc_opset1.transform(scaled_te_df_FD001['OpSet1'].values.reshape(-1,1)).toarray()\n",
    "opset2_enc_te = enc_opset2.transform(scaled_te_df_FD001['OpSet2'].values.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96061f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_te_num = scaled_te_df_FD001[num_col].values\n",
    "X_te = np.concatenate([X_te_num, opset1_enc_te, opset2_enc_te], axis = 1)\n",
    "X_te_pc = pca.transform(X_te)\n",
    "y_te = scaled_te_df_FD001['RUL'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2429d48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13096,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ac182149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq(in_arr,out_arr,lb):\n",
    "    x,y = [],[]\n",
    "    for i in range(in_arr.shape[0]):\n",
    "        if (i+lb) <= in_arr.shape[0]:\n",
    "            x.append(in_arr[i:(i+lb),:])\n",
    "            y.append(out_arr[(i+lb)-1])\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06fc6713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20504, 128, 93) (20504,)\n",
      "(12969, 128, 93) (12969,)\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train = get_seq(X_tr_pc,y_tr,128) \n",
    "x_test,y_test = get_seq(X_te_pc,y_te,128)\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d6d9e524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 128, 93)]         0         \n",
      "_________________________________________________________________\n",
      "Bi-LSTM-1 (LSTM)             (None, 128, 46)           25760     \n",
      "_________________________________________________________________\n",
      "DropOut-1 (Dropout)          (None, 128, 46)           0         \n",
      "_________________________________________________________________\n",
      "Bi-LSTM-2 (LSTM)             (None, 128, 23)           6440      \n",
      "_________________________________________________________________\n",
      "DropOut-2 (Dropout)          (None, 128, 23)           0         \n",
      "_________________________________________________________________\n",
      "Bi-LSTM-3 (LSTM)             (None, 11)                1540      \n",
      "_________________________________________________________________\n",
      "Dropout-3 (Dropout)          (None, 11)                0         \n",
      "_________________________________________________________________\n",
      "Fully-Connected (Dense)      (None, 9)                 108       \n",
      "_________________________________________________________________\n",
      "Dropout-4 (Dropout)          (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 33,858\n",
      "Trainable params: 33,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def rul_mdl1(batch_size = None,in_feature = x_train.shape[2], out_f = 1, len_ts = x_train.shape[1]):\n",
    "    inp = layers.Input(batch_shape= (batch_size, len_ts, x_train.shape[2]), name=\"Input\")\n",
    "    l1 = layers.LSTM(units = int(x_train.shape[2]/2),return_sequences = True, name = 'Bi-LSTM-1')(inp)\n",
    "    l1d = layers.Dropout(0.3, name = 'DropOut-1')(l1)\n",
    "    l2 = layers.LSTM(units = int(x_train.shape[2]/4),return_sequences = True, name = 'Bi-LSTM-2')(l1d)\n",
    "    l2d = layers.Dropout(0.3, name = 'DropOut-2')(l2)\n",
    "    l3 = layers.LSTM(units = int(x_train.shape[2]/8),return_sequences = False, name = 'Bi-LSTM-3')(l2d)\n",
    "    l3d = layers.Dropout(0.3, name = 'Dropout-3')(l3)\n",
    "    l4 = layers.Dense(units = int(x_train.shape[2]/10), activation = 'relu', name = 'Fully-Connected')(l3d)\n",
    "    l4d = layers.Dropout(0.3, name = 'Dropout-4')(l4)\n",
    "    out = layers.Dense(units = out_f, activation = 'linear', name = 'Output')(l4d)\n",
    "    M = models.Model(inputs = inp, outputs =  out)\n",
    "    M.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return M\n",
    "Model1 = rul_mdl1()\n",
    "Model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3ef7650c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4/4 [==============================] - 45s 9s/step - loss: 15301.6836 - val_loss: 19465.2734\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 42s 11s/step - loss: 15277.7441 - val_loss: 19422.4004\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 15236.1504 - val_loss: 19352.5625\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 15171.1357 - val_loss: 19254.7793\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 15070.4756 - val_loss: 19142.5566\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 14990.3105 - val_loss: 19097.6426\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 14947.4561 - val_loss: 19054.1953\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 14907.7695 - val_loss: 19009.4395\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 15s 3s/step - loss: 14866.5215 - val_loss: 18962.5977\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 14824.9336 - val_loss: 18913.7969\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 14781.9023 - val_loss: 18863.6230\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 14744.0029 - val_loss: 18812.7422\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 14698.3320 - val_loss: 18761.5488\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 14653.2324 - val_loss: 18710.4277\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 14602.7559 - val_loss: 18659.4453\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 14565.1152 - val_loss: 18608.7109\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 14514.0732 - val_loss: 18558.1191\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 14477.3135 - val_loss: 18507.5195\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 14432.6426 - val_loss: 18456.8613\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 14384.3779 - val_loss: 18405.7500\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 14336.4199 - val_loss: 18354.3066\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 14291.9238 - val_loss: 18302.7676\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 14243.9629 - val_loss: 18251.4453\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 14202.0938 - val_loss: 18200.1445\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 14150.6455 - val_loss: 18148.6562\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 14121.7305 - val_loss: 18097.0059\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 14066.2520 - val_loss: 18045.0586\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 14021.3477 - val_loss: 17992.7070\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 13977.8086 - val_loss: 17939.8809\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 13916.0986 - val_loss: 17886.4844\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 13874.1816 - val_loss: 17832.5469\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 13827.8711 - val_loss: 17778.0723\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 29s 7s/step - loss: 13783.1914 - val_loss: 17723.1426\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 13736.6377 - val_loss: 17667.8301\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 13680.0352 - val_loss: 17611.9023\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 13628.8486 - val_loss: 17555.4121\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 13581.3555 - val_loss: 17498.4277\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 13530.8965 - val_loss: 17440.8145\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 13478.9111 - val_loss: 17382.6445\n",
      "Epoch 40/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 13425.9912 - val_loss: 17323.8633\n",
      "Epoch 41/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 13380.2109 - val_loss: 17264.5391\n",
      "Epoch 42/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 13326.4541 - val_loss: 17204.6992\n",
      "Epoch 43/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 13269.9160 - val_loss: 17144.2754\n",
      "Epoch 44/1000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 13231.0625 - val_loss: 17083.3906\n",
      "Epoch 45/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 13170.5029 - val_loss: 17021.9473\n",
      "Epoch 46/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 13119.2617 - val_loss: 16960.0195\n",
      "Epoch 47/1000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 13055.5840 - val_loss: 16897.4531\n",
      "Epoch 48/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 13009.4531 - val_loss: 16834.3027\n",
      "Epoch 49/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 12957.0205 - val_loss: 16770.6289\n",
      "Epoch 50/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 12901.7520 - val_loss: 16706.4473\n",
      "Epoch 51/1000\n",
      "4/4 [==============================] - 20s 4s/step - loss: 12849.6709 - val_loss: 16641.7500\n",
      "Epoch 52/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 12790.3408 - val_loss: 16576.5879\n",
      "Epoch 53/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 12733.2617 - val_loss: 16510.9219\n",
      "Epoch 54/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 12678.6172 - val_loss: 16444.7500\n",
      "Epoch 55/1000\n",
      "4/4 [==============================] - 20s 4s/step - loss: 12611.5469 - val_loss: 16378.1289\n",
      "Epoch 56/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 12556.6455 - val_loss: 16310.9121\n",
      "Epoch 57/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 12487.5586 - val_loss: 16243.3027\n",
      "Epoch 58/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 12455.0557 - val_loss: 16175.2676\n",
      "Epoch 59/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 12386.3574 - val_loss: 16106.7764\n",
      "Epoch 60/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 12333.4600 - val_loss: 16037.8818\n",
      "Epoch 61/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 12253.3320 - val_loss: 15968.4600\n",
      "Epoch 62/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 12208.9521 - val_loss: 15898.7373\n",
      "Epoch 63/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 12152.2295 - val_loss: 15828.6396\n",
      "Epoch 64/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 12087.4541 - val_loss: 15758.1221\n",
      "Epoch 65/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 12011.8906 - val_loss: 15687.1260\n",
      "Epoch 66/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 11948.5459 - val_loss: 15615.7920\n",
      "Epoch 67/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 11904.6904 - val_loss: 15544.0527\n",
      "Epoch 68/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 11843.9766 - val_loss: 15472.1025\n",
      "Epoch 69/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 11800.8721 - val_loss: 15399.8721\n",
      "Epoch 70/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 11733.8330 - val_loss: 15327.4150\n",
      "Epoch 71/1000\n",
      "4/4 [==============================] - 17s 5s/step - loss: 11662.3623 - val_loss: 15254.6777\n",
      "Epoch 72/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 11602.9014 - val_loss: 15181.5166\n",
      "Epoch 73/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 11536.1621 - val_loss: 15108.1465\n",
      "Epoch 74/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 11474.9238 - val_loss: 15034.6035\n",
      "Epoch 75/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 11403.6973 - val_loss: 14960.7227\n",
      "Epoch 76/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 11367.1641 - val_loss: 14886.5967\n",
      "Epoch 77/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 22s 5s/step - loss: 11263.7637 - val_loss: 14812.2998\n",
      "Epoch 78/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 11198.1768 - val_loss: 14737.5996\n",
      "Epoch 79/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 11160.8271 - val_loss: 14662.7295\n",
      "Epoch 80/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 11122.4434 - val_loss: 14587.8252\n",
      "Epoch 81/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 11012.3174 - val_loss: 14512.7178\n",
      "Epoch 82/1000\n",
      "4/4 [==============================] - 20s 6s/step - loss: 10958.6973 - val_loss: 14437.3613\n",
      "Epoch 83/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 10920.0664 - val_loss: 14361.8262\n",
      "Epoch 84/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 10839.1309 - val_loss: 14286.1992\n",
      "Epoch 85/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 10775.8867 - val_loss: 14210.6143\n",
      "Epoch 86/1000\n",
      "4/4 [==============================] - 20s 4s/step - loss: 10738.6084 - val_loss: 14134.9150\n",
      "Epoch 87/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 10661.9346 - val_loss: 14059.3086\n",
      "Epoch 88/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 10604.6348 - val_loss: 13983.5205\n",
      "Epoch 89/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 10545.1562 - val_loss: 13907.8047\n",
      "Epoch 90/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 10485.7578 - val_loss: 13831.8955\n",
      "Epoch 91/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 10401.6816 - val_loss: 13755.9453\n",
      "Epoch 92/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 10367.9463 - val_loss: 13680.1768\n",
      "Epoch 93/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 10314.2627 - val_loss: 13604.5479\n",
      "Epoch 94/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 10189.4590 - val_loss: 13528.7617\n",
      "Epoch 95/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 10166.1465 - val_loss: 13452.8330\n",
      "Epoch 96/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 10109.2168 - val_loss: 13377.0225\n",
      "Epoch 97/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 10064.9912 - val_loss: 13301.4229\n",
      "Epoch 98/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 9990.3975 - val_loss: 13225.8193\n",
      "Epoch 99/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9910.0898 - val_loss: 13150.3330\n",
      "Epoch 100/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 9866.3066 - val_loss: 13074.8242\n",
      "Epoch 101/1000\n",
      "4/4 [==============================] - 17s 5s/step - loss: 9788.6211 - val_loss: 12999.4072\n",
      "Epoch 102/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 9710.2471 - val_loss: 12924.0654\n",
      "Epoch 103/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 9702.9209 - val_loss: 12849.0127\n",
      "Epoch 104/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 9576.0264 - val_loss: 12773.9482\n",
      "Epoch 105/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9547.9863 - val_loss: 12699.0615\n",
      "Epoch 106/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 9469.2578 - val_loss: 12624.2812\n",
      "Epoch 107/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9435.9141 - val_loss: 12549.6406\n",
      "Epoch 108/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 9363.0439 - val_loss: 12475.2676\n",
      "Epoch 109/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 9329.5566 - val_loss: 12401.0303\n",
      "Epoch 110/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 9259.5449 - val_loss: 12327.1621\n",
      "Epoch 111/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9165.6182 - val_loss: 12253.5332\n",
      "Epoch 112/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 9195.7881 - val_loss: 12180.0479\n",
      "Epoch 113/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9079.1660 - val_loss: 12106.8613\n",
      "Epoch 114/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 9055.1289 - val_loss: 12034.0664\n",
      "Epoch 115/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 8946.0898 - val_loss: 11961.5586\n",
      "Epoch 116/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8941.7549 - val_loss: 11889.3008\n",
      "Epoch 117/1000\n",
      "4/4 [==============================] - 20s 4s/step - loss: 8850.6406 - val_loss: 11817.4248\n",
      "Epoch 118/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8794.1611 - val_loss: 11745.8906\n",
      "Epoch 119/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 8721.3633 - val_loss: 11674.4043\n",
      "Epoch 120/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 8679.1533 - val_loss: 11603.2383\n",
      "Epoch 121/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 8640.3945 - val_loss: 11532.6582\n",
      "Epoch 122/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 8590.7188 - val_loss: 11462.4170\n",
      "Epoch 123/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 8578.7607 - val_loss: 11392.5430\n",
      "Epoch 124/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 8465.2559 - val_loss: 11323.0098\n",
      "Epoch 125/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8425.8193 - val_loss: 11253.9199\n",
      "Epoch 126/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 8397.0215 - val_loss: 11185.2920\n",
      "Epoch 127/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8319.2617 - val_loss: 11117.0762\n",
      "Epoch 128/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8277.2285 - val_loss: 11048.9834\n",
      "Epoch 129/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 8221.6191 - val_loss: 10981.4727\n",
      "Epoch 130/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 8122.4712 - val_loss: 10914.1650\n",
      "Epoch 131/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8090.3325 - val_loss: 10847.3994\n",
      "Epoch 132/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 8073.8916 - val_loss: 10780.9990\n",
      "Epoch 133/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 7993.4370 - val_loss: 10715.2754\n",
      "Epoch 134/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7979.7437 - val_loss: 10649.9541\n",
      "Epoch 135/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 7918.9102 - val_loss: 10585.3408\n",
      "Epoch 136/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7858.3560 - val_loss: 10521.2842\n",
      "Epoch 137/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 7863.4297 - val_loss: 10457.6699\n",
      "Epoch 138/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 7744.4292 - val_loss: 10394.5781\n",
      "Epoch 139/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 7725.4575 - val_loss: 10331.8193\n",
      "Epoch 140/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 7636.5581 - val_loss: 10269.3320\n",
      "Epoch 141/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7657.4980 - val_loss: 10207.3408\n",
      "Epoch 142/1000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 7542.3862 - val_loss: 10146.0830\n",
      "Epoch 143/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 7564.9751 - val_loss: 10085.1631\n",
      "Epoch 144/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7524.6709 - val_loss: 10024.8486\n",
      "Epoch 145/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7472.9478 - val_loss: 9965.1221\n",
      "Epoch 146/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 7415.1313 - val_loss: 9905.8027\n",
      "Epoch 147/1000\n",
      "4/4 [==============================] - 20s 6s/step - loss: 7399.3564 - val_loss: 9847.2715\n",
      "Epoch 148/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7378.0381 - val_loss: 9789.5078\n",
      "Epoch 149/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 7277.9673 - val_loss: 9732.2920\n",
      "Epoch 150/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 7289.9141 - val_loss: 9675.4473\n",
      "Epoch 151/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7244.1147 - val_loss: 9619.2852\n",
      "Epoch 152/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 7221.3599 - val_loss: 9563.8428\n",
      "Epoch 153/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7148.1797 - val_loss: 9508.8916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 7095.2676 - val_loss: 9454.4473\n",
      "Epoch 155/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 7055.7603 - val_loss: 9400.4287\n",
      "Epoch 156/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7075.1318 - val_loss: 9346.9609\n",
      "Epoch 157/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 6979.6719 - val_loss: 9294.1641\n",
      "Epoch 158/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 6935.2109 - val_loss: 9241.8389\n",
      "Epoch 159/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 6915.2773 - val_loss: 9189.9277\n",
      "Epoch 160/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6895.4102 - val_loss: 9138.6641\n",
      "Epoch 161/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 6845.3252 - val_loss: 9088.0801\n",
      "Epoch 162/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 6814.6406 - val_loss: 9038.1084\n",
      "Epoch 163/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6766.1709 - val_loss: 8988.6328\n",
      "Epoch 164/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6741.7383 - val_loss: 8939.7109\n",
      "Epoch 165/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6743.9014 - val_loss: 8891.5693\n",
      "Epoch 166/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 6682.9263 - val_loss: 8843.8730\n",
      "Epoch 167/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6678.5410 - val_loss: 8796.8613\n",
      "Epoch 168/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 6621.9883 - val_loss: 8750.3584\n",
      "Epoch 169/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 6645.4556 - val_loss: 8704.7861\n",
      "Epoch 170/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 6573.5938 - val_loss: 8659.7754\n",
      "Epoch 171/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6545.6724 - val_loss: 8615.2295\n",
      "Epoch 172/1000\n",
      "4/4 [==============================] - 20s 6s/step - loss: 6618.2026 - val_loss: 8571.3906\n",
      "Epoch 173/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6518.5049 - val_loss: 8528.1748\n",
      "Epoch 174/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 6469.7505 - val_loss: 8485.5205\n",
      "Epoch 175/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 6401.9580 - val_loss: 8443.4629\n",
      "Epoch 176/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6434.6460 - val_loss: 8402.3027\n",
      "Epoch 177/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 6421.3032 - val_loss: 8361.6641\n",
      "Epoch 178/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 6371.7578 - val_loss: 8321.4580\n",
      "Epoch 179/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 6298.0996 - val_loss: 8281.8008\n",
      "Epoch 180/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6288.9175 - val_loss: 8242.6045\n",
      "Epoch 181/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 6324.6572 - val_loss: 8204.0801\n",
      "Epoch 182/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 6252.0391 - val_loss: 8166.1694\n",
      "Epoch 183/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 6275.9624 - val_loss: 8128.8809\n",
      "Epoch 184/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6270.8960 - val_loss: 8092.2319\n",
      "Epoch 185/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 6232.2168 - val_loss: 8056.1436\n",
      "Epoch 186/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 6194.5264 - val_loss: 8020.5176\n",
      "Epoch 187/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6089.6714 - val_loss: 7985.4204\n",
      "Epoch 188/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 6156.6040 - val_loss: 7950.6772\n",
      "Epoch 189/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6132.5986 - val_loss: 7916.5830\n",
      "Epoch 190/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 6067.6533 - val_loss: 7883.1953\n",
      "Epoch 191/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 6138.6021 - val_loss: 7850.4551\n",
      "Epoch 192/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6071.2422 - val_loss: 7818.3613\n",
      "Epoch 193/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 6103.7388 - val_loss: 7786.6826\n",
      "Epoch 194/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 6078.1333 - val_loss: 7755.3188\n",
      "Epoch 195/1000\n",
      "4/4 [==============================] - 21s 4s/step - loss: 5985.6357 - val_loss: 7724.7896\n",
      "Epoch 196/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5995.4438 - val_loss: 7694.8794\n",
      "Epoch 197/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6026.9824 - val_loss: 7665.3501\n",
      "Epoch 198/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5968.2207 - val_loss: 7636.3027\n",
      "Epoch 199/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6058.9653 - val_loss: 7607.7988\n",
      "Epoch 200/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6004.8335 - val_loss: 7579.8765\n",
      "Epoch 201/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5940.2324 - val_loss: 7552.4019\n",
      "Epoch 202/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5984.1768 - val_loss: 7525.4092\n",
      "Epoch 203/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5960.2119 - val_loss: 7498.9834\n",
      "Epoch 204/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5933.3262 - val_loss: 7472.8926\n",
      "Epoch 205/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5936.5303 - val_loss: 7447.6108\n",
      "Epoch 206/1000\n",
      "4/4 [==============================] - 24s 5s/step - loss: 5869.9526 - val_loss: 7422.6523\n",
      "Epoch 207/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5916.6567 - val_loss: 7398.2607\n",
      "Epoch 208/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5829.0942 - val_loss: 7374.3018\n",
      "Epoch 209/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5858.7422 - val_loss: 7350.6436\n",
      "Epoch 210/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5879.2773 - val_loss: 7327.3428\n",
      "Epoch 211/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5880.2627 - val_loss: 7304.3965\n",
      "Epoch 212/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5782.5400 - val_loss: 7281.9854\n",
      "Epoch 213/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5824.9282 - val_loss: 7260.2739\n",
      "Epoch 214/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 5835.4448 - val_loss: 7239.0527\n",
      "Epoch 215/1000\n",
      "4/4 [==============================] - 27s 6s/step - loss: 5802.6890 - val_loss: 7218.2979\n",
      "Epoch 216/1000\n",
      "4/4 [==============================] - 20s 4s/step - loss: 5779.1895 - val_loss: 7197.7026\n",
      "Epoch 217/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5738.1094 - val_loss: 7177.3882\n",
      "Epoch 218/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5820.1035 - val_loss: 7157.3330\n",
      "Epoch 219/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5708.6465 - val_loss: 7137.6572\n",
      "Epoch 220/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5814.7183 - val_loss: 7118.3574\n",
      "Epoch 221/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 5733.2002 - val_loss: 7099.7563\n",
      "Epoch 222/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5746.9336 - val_loss: 7081.4341\n",
      "Epoch 223/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5745.8403 - val_loss: 7063.7061\n",
      "Epoch 224/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 5776.1050 - val_loss: 7046.3184\n",
      "Epoch 225/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5686.3960 - val_loss: 7029.1807\n",
      "Epoch 226/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5729.1328 - val_loss: 7012.5137\n",
      "Epoch 227/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5716.3560 - val_loss: 6996.3599\n",
      "Epoch 228/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5729.9780 - val_loss: 6980.6318\n",
      "Epoch 229/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5676.1089 - val_loss: 6965.0981\n",
      "Epoch 230/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5689.0229 - val_loss: 6949.8804\n",
      "Epoch 231/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 5656.4805 - val_loss: 6934.9507\n",
      "Epoch 232/1000\n",
      "4/4 [==============================] - 25s 7s/step - loss: 5712.5498 - val_loss: 6920.4648\n",
      "Epoch 233/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5665.1875 - val_loss: 6906.1318\n",
      "Epoch 234/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5672.7974 - val_loss: 6892.0576\n",
      "Epoch 235/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5696.9868 - val_loss: 6878.3394\n",
      "Epoch 236/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5668.9810 - val_loss: 6865.0107\n",
      "Epoch 237/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 5624.3579 - val_loss: 6851.9502\n",
      "Epoch 238/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5656.1489 - val_loss: 6838.9019\n",
      "Epoch 239/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5631.2036 - val_loss: 6826.2012\n",
      "Epoch 240/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5611.6094 - val_loss: 6813.8628\n",
      "Epoch 241/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5577.7607 - val_loss: 6801.9062\n",
      "Epoch 242/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5641.5938 - val_loss: 6790.1328\n",
      "Epoch 243/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5634.4062 - val_loss: 6778.6157\n",
      "Epoch 244/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5622.0605 - val_loss: 6767.2993\n",
      "Epoch 245/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5636.0503 - val_loss: 6756.3018\n",
      "Epoch 246/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5628.2529 - val_loss: 6745.5381\n",
      "Epoch 247/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5656.3608 - val_loss: 6734.8325\n",
      "Epoch 248/1000\n",
      "4/4 [==============================] - 27s 7s/step - loss: 5606.5229 - val_loss: 6724.6055\n",
      "Epoch 249/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5639.2993 - val_loss: 6714.4565\n",
      "Epoch 250/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5610.1045 - val_loss: 6704.7280\n",
      "Epoch 251/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5566.5444 - val_loss: 6694.8262\n",
      "Epoch 252/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5589.9199 - val_loss: 6685.0942\n",
      "Epoch 253/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 5620.1538 - val_loss: 6675.7739\n",
      "Epoch 254/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5599.6426 - val_loss: 6666.6553\n",
      "Epoch 255/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5616.0220 - val_loss: 6657.8667\n",
      "Epoch 256/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5588.8340 - val_loss: 6649.3989\n",
      "Epoch 257/1000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 5557.7256 - val_loss: 6641.0488\n",
      "Epoch 258/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5590.9468 - val_loss: 6632.9302\n",
      "Epoch 259/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5589.9219 - val_loss: 6625.1035\n",
      "Epoch 260/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5573.5835 - val_loss: 6617.3296\n",
      "Epoch 261/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5636.3604 - val_loss: 6609.7363\n",
      "Epoch 262/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5565.9795 - val_loss: 6602.6079\n",
      "Epoch 263/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 5634.7012 - val_loss: 6595.6372\n",
      "Epoch 264/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5521.4658 - val_loss: 6588.8638\n",
      "Epoch 265/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5604.7744 - val_loss: 6582.1616\n",
      "Epoch 266/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5631.6318 - val_loss: 6575.8330\n",
      "Epoch 267/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5560.2500 - val_loss: 6569.5732\n",
      "Epoch 268/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5611.9727 - val_loss: 6563.6226\n",
      "Epoch 269/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5595.8682 - val_loss: 6557.8164\n",
      "Epoch 270/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5598.9380 - val_loss: 6552.0923\n",
      "Epoch 271/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5561.1367 - val_loss: 6546.4263\n",
      "Epoch 272/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5585.5342 - val_loss: 6540.7349\n",
      "Epoch 273/1000\n",
      "4/4 [==============================] - 27s 6s/step - loss: 5608.0591 - val_loss: 6535.3623\n",
      "Epoch 274/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5603.9282 - val_loss: 6530.1504\n",
      "Epoch 275/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5596.3242 - val_loss: 6525.0137\n",
      "Epoch 276/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5564.5415 - val_loss: 6519.7778\n",
      "Epoch 277/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5598.1948 - val_loss: 6514.8491\n",
      "Epoch 278/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5561.7524 - val_loss: 6510.0435\n",
      "Epoch 279/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5564.3096 - val_loss: 6505.5288\n",
      "Epoch 280/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5552.0820 - val_loss: 6501.0278\n",
      "Epoch 281/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5503.2476 - val_loss: 6496.6187\n",
      "Epoch 282/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 5553.9990 - val_loss: 6492.0942\n",
      "Epoch 283/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5522.0640 - val_loss: 6487.7002\n",
      "Epoch 284/1000\n",
      "4/4 [==============================] - 20s 6s/step - loss: 5527.9106 - val_loss: 6483.4233\n",
      "Epoch 285/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5548.3120 - val_loss: 6479.2520\n",
      "Epoch 286/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5590.0767 - val_loss: 6475.2905\n",
      "Epoch 287/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5558.8657 - val_loss: 6471.4390\n",
      "Epoch 288/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5547.1118 - val_loss: 6467.4546\n",
      "Epoch 289/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 5560.8638 - val_loss: 6463.4902\n",
      "Epoch 290/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5587.5391 - val_loss: 6460.0283\n",
      "Epoch 291/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5548.4966 - val_loss: 6456.6226\n",
      "Epoch 292/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5610.4263 - val_loss: 6453.2842\n",
      "Epoch 293/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5591.6089 - val_loss: 6450.1255\n",
      "Epoch 294/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5571.7515 - val_loss: 6447.1235\n",
      "Epoch 295/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5551.6338 - val_loss: 6444.0117\n",
      "Epoch 296/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5580.0732 - val_loss: 6441.0464\n",
      "Epoch 297/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 5663.7388 - val_loss: 6438.2729\n",
      "Epoch 298/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5548.1475 - val_loss: 6435.5601\n",
      "Epoch 299/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 5506.9639 - val_loss: 6432.8569\n",
      "Epoch 300/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5593.9565 - val_loss: 6430.1602\n",
      "Epoch 301/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5543.6797 - val_loss: 6427.4785\n",
      "Epoch 302/1000\n",
      "4/4 [==============================] - 20s 4s/step - loss: 5585.2822 - val_loss: 6424.9409\n",
      "Epoch 303/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5577.3779 - val_loss: 6422.4385\n",
      "Epoch 304/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5497.5425 - val_loss: 6419.9546\n",
      "Epoch 305/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5539.5435 - val_loss: 6417.3525\n",
      "Epoch 306/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5496.2119 - val_loss: 6414.9224\n",
      "Epoch 307/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5562.1689 - val_loss: 6412.5796\n",
      "Epoch 308/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 21s 5s/step - loss: 5612.4341 - val_loss: 6410.6279\n",
      "Epoch 309/1000\n",
      "4/4 [==============================] - 36s 9s/step - loss: 5583.2417 - val_loss: 6408.9287\n",
      "Epoch 310/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 5555.3345 - val_loss: 6407.2852\n",
      "Epoch 311/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 5633.7524 - val_loss: 6405.4971\n",
      "Epoch 312/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5555.3779 - val_loss: 6403.8213\n",
      "Epoch 313/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5574.7344 - val_loss: 6402.0972\n",
      "Epoch 314/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5591.7407 - val_loss: 6400.7856\n",
      "Epoch 315/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5549.5405 - val_loss: 6399.2432\n",
      "Epoch 316/1000\n",
      "4/4 [==============================] - 24s 5s/step - loss: 5597.6997 - val_loss: 6397.7427\n",
      "Epoch 317/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5591.9468 - val_loss: 6396.1738\n",
      "Epoch 318/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5515.0205 - val_loss: 6394.3672\n",
      "Epoch 319/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 5536.5615 - val_loss: 6392.8086\n",
      "Epoch 320/1000\n",
      "4/4 [==============================] - 44s 11s/step - loss: 5559.9478 - val_loss: 6391.3594\n",
      "Epoch 321/1000\n",
      "4/4 [==============================] - 43s 11s/step - loss: 5512.6011 - val_loss: 6389.5806\n",
      "Epoch 322/1000\n",
      "4/4 [==============================] - 50s 13s/step - loss: 5555.8003 - val_loss: 6387.9873\n",
      "Epoch 323/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 5522.4141 - val_loss: 6386.3179\n",
      "Epoch 324/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5569.4688 - val_loss: 6384.7886\n",
      "Epoch 325/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 5534.3345 - val_loss: 6383.3604\n",
      "Epoch 326/1000\n",
      "4/4 [==============================] - 28s 6s/step - loss: 5532.0073 - val_loss: 6382.0781\n",
      "Epoch 327/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5607.4902 - val_loss: 6380.8027\n",
      "Epoch 328/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5605.7642 - val_loss: 6379.7231\n",
      "Epoch 329/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 5586.0508 - val_loss: 6378.6069\n",
      "Epoch 330/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 5520.9868 - val_loss: 6377.5049\n",
      "Epoch 331/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5586.8613 - val_loss: 6376.4160\n",
      "Epoch 332/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5575.3267 - val_loss: 6375.3853\n",
      "Epoch 333/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 5561.1289 - val_loss: 6374.7681\n",
      "Epoch 334/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5562.5220 - val_loss: 6373.9927\n",
      "Epoch 335/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5578.4634 - val_loss: 6372.9795\n",
      "Epoch 336/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5539.5996 - val_loss: 6372.0361\n",
      "Epoch 337/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 5582.2749 - val_loss: 6371.1646\n",
      "Epoch 338/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 5543.9214 - val_loss: 6370.3403\n",
      "Epoch 339/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5578.4502 - val_loss: 6369.5186\n",
      "Epoch 340/1000\n",
      "4/4 [==============================] - 30s 8s/step - loss: 5586.4351 - val_loss: 6368.7642\n",
      "Epoch 341/1000\n",
      "4/4 [==============================] - 24s 5s/step - loss: 5542.1953 - val_loss: 6368.0391\n",
      "Epoch 342/1000\n",
      "4/4 [==============================] - 24s 7s/step - loss: 5593.6699 - val_loss: 6367.4087\n",
      "Epoch 343/1000\n",
      "4/4 [==============================] - 33s 8s/step - loss: 5473.9932 - val_loss: 6366.8477\n",
      "Epoch 344/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5560.6885 - val_loss: 6366.1509\n",
      "Epoch 345/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 5594.5049 - val_loss: 6365.3506\n",
      "Epoch 346/1000\n",
      "4/4 [==============================] - 27s 6s/step - loss: 5515.6685 - val_loss: 6364.6343\n",
      "Epoch 347/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5553.1826 - val_loss: 6363.9351\n",
      "Epoch 348/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5573.0312 - val_loss: 6363.2866\n",
      "Epoch 349/1000\n",
      "4/4 [==============================] - 30s 7s/step - loss: 5538.1226 - val_loss: 6362.7090\n",
      "Epoch 350/1000\n",
      "4/4 [==============================] - 29s 8s/step - loss: 5591.1353 - val_loss: 6362.0806\n",
      "Epoch 351/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5615.5923 - val_loss: 6361.7065\n",
      "Epoch 352/1000\n",
      "4/4 [==============================] - 27s 8s/step - loss: 5541.8179 - val_loss: 6361.0864\n",
      "Epoch 353/1000\n",
      "4/4 [==============================] - 45s 11s/step - loss: 5559.2212 - val_loss: 6360.3760\n",
      "Epoch 354/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5551.0146 - val_loss: 6359.6260\n",
      "Epoch 355/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5581.5444 - val_loss: 6358.8911\n",
      "Epoch 356/1000\n",
      "4/4 [==============================] - 29s 7s/step - loss: 5524.7168 - val_loss: 6358.2700\n",
      "Epoch 357/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5570.4746 - val_loss: 6357.4980\n",
      "Epoch 358/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5577.1562 - val_loss: 6357.0078\n",
      "Epoch 359/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 5539.5293 - val_loss: 6356.6782\n",
      "Epoch 360/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5580.6694 - val_loss: 6356.3872\n",
      "Epoch 361/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5568.0176 - val_loss: 6356.1670\n",
      "Epoch 362/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 5595.1802 - val_loss: 6355.7676\n",
      "Epoch 363/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 5568.4438 - val_loss: 6355.5581\n",
      "Epoch 364/1000\n",
      "4/4 [==============================] - 24s 7s/step - loss: 5600.8525 - val_loss: 6355.4663\n",
      "Epoch 365/1000\n",
      "4/4 [==============================] - 28s 7s/step - loss: 5536.6382 - val_loss: 6355.3867\n",
      "Epoch 366/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5503.2300 - val_loss: 6355.1670\n",
      "Epoch 367/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5513.1338 - val_loss: 6355.0107\n",
      "Epoch 368/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 5575.0708 - val_loss: 6354.6758\n",
      "Epoch 369/1000\n",
      "4/4 [==============================] - 30s 8s/step - loss: 5483.1104 - val_loss: 6354.1089\n",
      "Epoch 370/1000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 5542.7407 - val_loss: 6353.5405\n",
      "Epoch 371/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5592.4604 - val_loss: 6353.1689\n",
      "Epoch 372/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5516.2305 - val_loss: 6352.9937\n",
      "Epoch 373/1000\n",
      "4/4 [==============================] - 32s 8s/step - loss: 5512.8267 - val_loss: 6352.3965\n",
      "Epoch 374/1000\n",
      "4/4 [==============================] - 24s 5s/step - loss: 5542.6245 - val_loss: 6351.8521\n",
      "Epoch 375/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5546.2485 - val_loss: 6351.4595\n",
      "Epoch 376/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5561.3145 - val_loss: 6351.0752\n",
      "Epoch 377/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5596.7295 - val_loss: 6350.7666\n",
      "Epoch 378/1000\n",
      "4/4 [==============================] - 43s 12s/step - loss: 5527.8911 - val_loss: 6350.3594\n",
      "Epoch 379/1000\n",
      "4/4 [==============================] - 41s 10s/step - loss: 5558.6909 - val_loss: 6349.7124\n",
      "Epoch 380/1000\n",
      "4/4 [==============================] - 35s 7s/step - loss: 5507.2173 - val_loss: 6349.0552\n",
      "Epoch 381/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 5576.1519 - val_loss: 6348.8022\n",
      "Epoch 382/1000\n",
      "4/4 [==============================] - 31s 8s/step - loss: 5568.4121 - val_loss: 6348.5220\n",
      "Epoch 383/1000\n",
      "4/4 [==============================] - 29s 7s/step - loss: 5461.1035 - val_loss: 6348.2280\n",
      "Epoch 384/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5511.6963 - val_loss: 6347.6963\n",
      "Epoch 385/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 32s 8s/step - loss: 5578.9141 - val_loss: 6347.4727\n",
      "Epoch 386/1000\n",
      "4/4 [==============================] - 36s 8s/step - loss: 5512.8130 - val_loss: 6347.1523\n",
      "Epoch 387/1000\n",
      "4/4 [==============================] - 28s 7s/step - loss: 5581.3379 - val_loss: 6345.9229\n",
      "Epoch 388/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 5572.0840 - val_loss: 6342.8140\n",
      "Epoch 389/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5563.7720 - val_loss: 6339.2783\n",
      "Epoch 390/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5494.5879 - val_loss: 6335.1353\n",
      "Epoch 391/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5503.0146 - val_loss: 6330.3926\n",
      "Epoch 392/1000\n",
      "4/4 [==============================] - 27s 6s/step - loss: 5525.7358 - val_loss: 6324.9810\n",
      "Epoch 393/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5560.6431 - val_loss: 6319.0811\n",
      "Epoch 394/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5554.7480 - val_loss: 6313.3057\n",
      "Epoch 395/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5598.7710 - val_loss: 6307.4141\n",
      "Epoch 396/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5549.5972 - val_loss: 6301.6079\n",
      "Epoch 397/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5550.0908 - val_loss: 6295.5581\n",
      "Epoch 398/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5544.3496 - val_loss: 6289.5859\n",
      "Epoch 399/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5517.0366 - val_loss: 6283.0356\n",
      "Epoch 400/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5521.7085 - val_loss: 6276.7407\n",
      "Epoch 401/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5591.7852 - val_loss: 6270.8135\n",
      "Epoch 402/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5529.6958 - val_loss: 6265.0786\n",
      "Epoch 403/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5537.6035 - val_loss: 6259.0088\n",
      "Epoch 404/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5542.8867 - val_loss: 6253.0591\n",
      "Epoch 405/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5491.1304 - val_loss: 6247.3604\n",
      "Epoch 406/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5536.7534 - val_loss: 6242.4883\n",
      "Epoch 407/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5566.1406 - val_loss: 6238.1699\n",
      "Epoch 408/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5527.5356 - val_loss: 6234.7681\n",
      "Epoch 409/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5516.3867 - val_loss: 6231.4517\n",
      "Epoch 410/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 5566.0083 - val_loss: 6228.6382\n",
      "Epoch 411/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5440.7168 - val_loss: 6225.9907\n",
      "Epoch 412/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5468.7949 - val_loss: 6223.2310\n",
      "Epoch 413/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5544.0146 - val_loss: 6220.4404\n",
      "Epoch 414/1000\n",
      "4/4 [==============================] - 25s 5s/step - loss: 5557.6406 - val_loss: 6217.9429\n",
      "Epoch 415/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5469.8281 - val_loss: 6215.5981\n",
      "Epoch 416/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 5516.5264 - val_loss: 6212.4766\n",
      "Epoch 417/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5455.8477 - val_loss: 6209.7783\n",
      "Epoch 418/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5472.6855 - val_loss: 6207.6377\n",
      "Epoch 419/1000\n",
      "4/4 [==============================] - 32s 9s/step - loss: 5566.3125 - val_loss: 6206.0806\n",
      "Epoch 420/1000\n",
      "4/4 [==============================] - 73s 21s/step - loss: 5484.6460 - val_loss: 6204.6255\n",
      "Epoch 421/1000\n",
      "4/4 [==============================] - 50s 7s/step - loss: 5525.1787 - val_loss: 6202.9814\n",
      "Epoch 422/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5480.4683 - val_loss: 6201.4390\n",
      "Epoch 423/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5468.1582 - val_loss: 6200.7344\n",
      "Epoch 424/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5469.7715 - val_loss: 6200.3501\n",
      "Epoch 425/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5501.6230 - val_loss: 6200.0571\n",
      "Epoch 426/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 5480.9985 - val_loss: 6199.4478\n",
      "Epoch 427/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5524.6895 - val_loss: 6198.8813\n",
      "Epoch 428/1000\n",
      "4/4 [==============================] - 29s 6s/step - loss: 5545.1079 - val_loss: 6198.5278\n",
      "Epoch 429/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 5523.5688 - val_loss: 6198.1938\n",
      "Epoch 430/1000\n",
      "4/4 [==============================] - 24s 5s/step - loss: 5533.4004 - val_loss: 6197.9253\n",
      "Epoch 431/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5502.3535 - val_loss: 6197.7817\n",
      "Epoch 432/1000\n",
      "4/4 [==============================] - 24s 5s/step - loss: 5417.0073 - val_loss: 6197.3154\n",
      "Epoch 433/1000\n",
      "4/4 [==============================] - 17s 5s/step - loss: 5484.1724 - val_loss: 6196.8594\n",
      "Epoch 434/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5468.0371 - val_loss: 6196.4683\n",
      "Epoch 435/1000\n",
      "4/4 [==============================] - 33s 8s/step - loss: 5409.8472 - val_loss: 6196.3662\n",
      "Epoch 436/1000\n",
      "4/4 [==============================] - 35s 9s/step - loss: 5467.4561 - val_loss: 6195.8110\n",
      "Epoch 437/1000\n",
      "4/4 [==============================] - 36s 9s/step - loss: 5496.2407 - val_loss: 6196.2104\n",
      "Epoch 438/1000\n",
      "4/4 [==============================] - 40s 11s/step - loss: 5524.5957 - val_loss: 6196.6963\n",
      "Epoch 439/1000\n",
      "4/4 [==============================] - 62s 16s/step - loss: 5506.4746 - val_loss: 6198.3062\n",
      "Epoch 440/1000\n",
      "4/4 [==============================] - 73s 17s/step - loss: 5432.1650 - val_loss: 6198.8545\n",
      "Epoch 441/1000\n",
      "4/4 [==============================] - 41s 8s/step - loss: 5423.2363 - val_loss: 6199.1382\n",
      "Epoch 442/1000\n",
      "4/4 [==============================] - 39s 11s/step - loss: 5456.1440 - val_loss: 6199.7295\n",
      "Epoch 443/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 5480.2314 - val_loss: 6199.8008\n",
      "Epoch 444/1000\n",
      "4/4 [==============================] - 49s 15s/step - loss: 5465.1313 - val_loss: 6200.1001\n",
      "Epoch 445/1000\n",
      "4/4 [==============================] - 31s 8s/step - loss: 5521.8623 - val_loss: 6201.1162\n",
      "Epoch 446/1000\n",
      "4/4 [==============================] - 51s 14s/step - loss: 5447.3984 - val_loss: 6201.7271\n",
      "Epoch 447/1000\n",
      "4/4 [==============================] - 70s 16s/step - loss: 5471.3311 - val_loss: 6202.3276\n",
      "Epoch 448/1000\n",
      "4/4 [==============================] - 35s 8s/step - loss: 5457.5703 - val_loss: 6203.0186\n",
      "Epoch 449/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5473.7261 - val_loss: 6204.2905\n",
      "Epoch 450/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5463.1865 - val_loss: 6205.9165\n",
      "Epoch 451/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5463.9248 - val_loss: 6206.8467\n",
      "Epoch 452/1000\n",
      "4/4 [==============================] - 31s 8s/step - loss: 5458.4160 - val_loss: 6207.2437\n",
      "Epoch 453/1000\n",
      "4/4 [==============================] - 31s 7s/step - loss: 5495.7793 - val_loss: 6207.9873\n",
      "Epoch 454/1000\n",
      "4/4 [==============================] - 51s 14s/step - loss: 5423.4092 - val_loss: 6208.1348\n",
      "Epoch 455/1000\n",
      "4/4 [==============================] - 37s 9s/step - loss: 5500.5942 - val_loss: 6208.1631\n",
      "Epoch 456/1000\n",
      "4/4 [==============================] - 40s 10s/step - loss: 5482.3218 - val_loss: 6207.5942\n",
      "Epoch 457/1000\n",
      "4/4 [==============================] - 49s 11s/step - loss: 5433.6851 - val_loss: 6206.8047\n",
      "Epoch 458/1000\n",
      "4/4 [==============================] - 33s 8s/step - loss: 5438.8755 - val_loss: 6205.6538\n",
      "Epoch 459/1000\n",
      "4/4 [==============================] - 34s 8s/step - loss: 5444.5913 - val_loss: 6204.2471\n",
      "Epoch 460/1000\n",
      "4/4 [==============================] - 31s 8s/step - loss: 5449.0356 - val_loss: 6203.6787\n",
      "Epoch 461/1000\n",
      "4/4 [==============================] - 34s 7s/step - loss: 5496.8408 - val_loss: 6203.8784\n",
      "Epoch 462/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 34s 8s/step - loss: 5471.9702 - val_loss: 6204.9478\n",
      "Epoch 463/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 5435.7808 - val_loss: 6205.4766\n",
      "Epoch 464/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 5485.9663 - val_loss: 6204.1523\n",
      "Epoch 465/1000\n",
      "4/4 [==============================] - 41s 11s/step - loss: 5383.2383 - val_loss: 6203.8198\n",
      "Epoch 466/1000\n",
      "4/4 [==============================] - 36s 9s/step - loss: 5450.1714 - val_loss: 6203.3140\n",
      "Epoch 467/1000\n",
      "4/4 [==============================] - 33s 8s/step - loss: 5484.9541 - val_loss: 6204.6074\n",
      "Epoch 468/1000\n",
      "4/4 [==============================] - 30s 7s/step - loss: 5446.1460 - val_loss: 6206.3315\n",
      "Epoch 469/1000\n",
      "4/4 [==============================] - 37s 9s/step - loss: 5478.1084 - val_loss: 6208.4561\n",
      "Epoch 470/1000\n",
      "4/4 [==============================] - 33s 8s/step - loss: 5438.0864 - val_loss: 6210.6372\n",
      "Epoch 471/1000\n",
      "4/4 [==============================] - 28s 6s/step - loss: 5384.3711 - val_loss: 6210.8501\n",
      "Epoch 472/1000\n",
      "4/4 [==============================] - 36s 9s/step - loss: 5458.0977 - val_loss: 6210.5483\n",
      "Epoch 473/1000\n",
      "4/4 [==============================] - 36s 9s/step - loss: 5492.5112 - val_loss: 6212.3838\n",
      "Epoch 474/1000\n",
      "4/4 [==============================] - 40s 10s/step - loss: 5455.3047 - val_loss: 6214.7251\n",
      "Epoch 475/1000\n",
      "4/4 [==============================] - 32s 7s/step - loss: 5450.7324 - val_loss: 6217.0952\n",
      "Epoch 476/1000\n",
      "4/4 [==============================] - 34s 9s/step - loss: 5430.5972 - val_loss: 6219.6567\n",
      "Epoch 477/1000\n",
      "4/4 [==============================] - 32s 6s/step - loss: 5413.1426 - val_loss: 6221.9429\n",
      "Epoch 478/1000\n",
      "4/4 [==============================] - 30s 7s/step - loss: 5455.9956 - val_loss: 6223.7871\n",
      "Epoch 479/1000\n",
      "4/4 [==============================] - 33s 8s/step - loss: 5438.9761 - val_loss: 6226.1875\n",
      "Epoch 480/1000\n",
      "4/4 [==============================] - 27s 5s/step - loss: 5362.8257 - val_loss: 6226.6030\n",
      "Epoch 481/1000\n",
      "4/4 [==============================] - 27s 7s/step - loss: 5423.5420 - val_loss: 6226.1714\n",
      "Epoch 482/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5465.3867 - val_loss: 6225.7305\n",
      "Epoch 483/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 5461.4697 - val_loss: 6224.9316\n",
      "Epoch 484/1000\n",
      "4/4 [==============================] - 29s 8s/step - loss: 5395.0186 - val_loss: 6223.7607\n",
      "Epoch 485/1000\n",
      "4/4 [==============================] - 25s 7s/step - loss: 5454.2583 - val_loss: 6223.0815\n",
      "Epoch 486/1000\n",
      "4/4 [==============================] - 35s 10s/step - loss: 5438.2480 - val_loss: 6223.4233\n",
      "Epoch 487/1000\n",
      "4/4 [==============================] - 32s 6s/step - loss: 5406.6167 - val_loss: 6224.5195\n",
      "Epoch 488/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 5541.0957 - val_loss: 6226.2979\n",
      "Epoch 489/1000\n",
      "4/4 [==============================] - 32s 8s/step - loss: 5405.8662 - val_loss: 6226.9932\n",
      "Epoch 490/1000\n",
      "4/4 [==============================] - 30s 7s/step - loss: 5424.4341 - val_loss: 6228.4307\n",
      "Epoch 491/1000\n",
      "4/4 [==============================] - 43s 12s/step - loss: 5450.7339 - val_loss: 6230.8613\n",
      "Epoch 492/1000\n",
      "4/4 [==============================] - 58s 15s/step - loss: 5408.8003 - val_loss: 6232.8760\n",
      "Epoch 493/1000\n",
      "4/4 [==============================] - 43s 10s/step - loss: 5428.0493 - val_loss: 6233.6318\n",
      "Epoch 494/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 5428.6396 - val_loss: 6234.4800\n",
      "Epoch 495/1000\n",
      "4/4 [==============================] - 40s 10s/step - loss: 5405.3286 - val_loss: 6234.7212\n",
      "Epoch 496/1000\n",
      "4/4 [==============================] - 36s 9s/step - loss: 5478.7319 - val_loss: 6235.0254\n",
      "Epoch 497/1000\n",
      "4/4 [==============================] - 30s 7s/step - loss: 5448.4663 - val_loss: 6234.4839\n",
      "Epoch 498/1000\n",
      "4/4 [==============================] - 32s 8s/step - loss: 5454.3296 - val_loss: 6234.5483\n",
      "Epoch 499/1000\n",
      "4/4 [==============================] - 44s 12s/step - loss: 5392.3491 - val_loss: 6234.7153\n",
      "Epoch 500/1000\n",
      "4/4 [==============================] - 34s 7s/step - loss: 5470.0376 - val_loss: 6235.8345\n",
      "Epoch 501/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 5382.3779 - val_loss: 6235.9189\n",
      "Epoch 502/1000\n",
      "4/4 [==============================] - 32s 8s/step - loss: 5389.2290 - val_loss: 6235.5200\n",
      "Epoch 503/1000\n",
      "4/4 [==============================] - 30s 6s/step - loss: 5352.8823 - val_loss: 6236.2095\n",
      "Epoch 504/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5405.8545 - val_loss: 6237.3755\n",
      "Epoch 505/1000\n",
      "4/4 [==============================] - 38s 10s/step - loss: 5433.8633 - val_loss: 6237.7407\n",
      "Epoch 506/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 5372.3555 - val_loss: 6237.1353\n",
      "Epoch 507/1000\n",
      "4/4 [==============================] - 27s 7s/step - loss: 5450.3438 - val_loss: 6237.2373\n",
      "Epoch 508/1000\n",
      "4/4 [==============================] - 53s 14s/step - loss: 5416.3403 - val_loss: 6237.7925\n",
      "Epoch 509/1000\n",
      "4/4 [==============================] - 83s 22s/step - loss: 5410.0020 - val_loss: 6237.8550\n",
      "Epoch 510/1000\n",
      "4/4 [==============================] - 70s 20s/step - loss: 5436.5093 - val_loss: 6239.3467\n",
      "Epoch 511/1000\n",
      "4/4 [==============================] - 36s 8s/step - loss: 5414.2163 - val_loss: 6239.8677\n",
      "Epoch 512/1000\n",
      "4/4 [==============================] - 27s 7s/step - loss: 5416.1328 - val_loss: 6240.8633\n",
      "Epoch 513/1000\n",
      "4/4 [==============================] - 17s 5s/step - loss: 5463.5146 - val_loss: 6242.8335\n",
      "Epoch 514/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5390.7725 - val_loss: 6243.8154\n",
      "Epoch 515/1000\n",
      "4/4 [==============================] - 23s 7s/step - loss: 5401.5698 - val_loss: 6245.3223\n",
      "Epoch 516/1000\n",
      "4/4 [==============================] - 36s 8s/step - loss: 5391.3975 - val_loss: 6245.1582\n",
      "Epoch 517/1000\n",
      "4/4 [==============================] - 28s 6s/step - loss: 5423.9551 - val_loss: 6245.2378\n",
      "Epoch 518/1000\n",
      "4/4 [==============================] - 27s 6s/step - loss: 5415.2031 - val_loss: 6244.8726\n",
      "Epoch 519/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 5421.6504 - val_loss: 6243.4805\n",
      "Epoch 520/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5408.1831 - val_loss: 6242.5195\n",
      "Epoch 521/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 5406.2637 - val_loss: 6242.8071\n",
      "Epoch 522/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 5416.0054 - val_loss: 6243.9087\n",
      "Epoch 523/1000\n",
      "4/4 [==============================] - 24s 7s/step - loss: 5337.8931 - val_loss: 6245.0737\n",
      "Epoch 524/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 5478.0894 - val_loss: 6246.4956\n",
      "Epoch 525/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 5475.8613 - val_loss: 6248.5947\n",
      "Epoch 526/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5442.2363 - val_loss: 6250.7505\n",
      "Epoch 527/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5389.6597 - val_loss: 6252.5581\n",
      "Epoch 528/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5421.4146 - val_loss: 6253.6426\n",
      "Epoch 529/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5396.3730 - val_loss: 6254.2896\n",
      "Epoch 530/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 5410.6094 - val_loss: 6253.6567\n",
      "Epoch 531/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5456.9287 - val_loss: 6253.4609\n",
      "Epoch 532/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5426.1636 - val_loss: 6253.4302\n",
      "Epoch 533/1000\n",
      "4/4 [==============================] - 20s 4s/step - loss: 5412.7959 - val_loss: 6253.1865\n",
      "Epoch 534/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5451.3867 - val_loss: 6253.6528\n",
      "Epoch 535/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 5450.4473 - val_loss: 6254.0830\n",
      "Epoch 536/1000\n",
      "4/4 [==============================] - 32s 8s/step - loss: 5419.0693 - val_loss: 6254.3887\n",
      "Epoch 537/1000\n",
      "4/4 [==============================] - 27s 7s/step - loss: 5496.6001 - val_loss: 6254.9355\n",
      "Epoch 538/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5392.6655 - val_loss: 6255.5425\n",
      "Epoch 539/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 17s 5s/step - loss: 5438.9717 - val_loss: 6255.6729\n",
      "Epoch 540/1000\n",
      "4/4 [==============================] - 29s 7s/step - loss: 5393.5098 - val_loss: 6256.5107\n",
      "Epoch 541/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 5464.6611 - val_loss: 6257.8369\n",
      "Epoch 542/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5467.0864 - val_loss: 6258.5757\n",
      "Epoch 543/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5403.9106 - val_loss: 6258.7554\n",
      "Epoch 544/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5430.6616 - val_loss: 6258.8286\n",
      "Epoch 545/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5404.2485 - val_loss: 6259.3096\n",
      "Epoch 546/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5410.0732 - val_loss: 6259.1406\n",
      "Epoch 547/1000\n",
      "4/4 [==============================] - 40s 10s/step - loss: 5446.6890 - val_loss: 6257.7876\n",
      "Epoch 548/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5368.6260 - val_loss: 6256.9487\n",
      "Epoch 549/1000\n",
      "4/4 [==============================] - 28s 7s/step - loss: 5474.9673 - val_loss: 6257.1641\n",
      "Epoch 550/1000\n",
      "4/4 [==============================] - 80s 22s/step - loss: 5437.5444 - val_loss: 6257.7739\n",
      "Epoch 551/1000\n",
      "4/4 [==============================] - 53s 12s/step - loss: 5310.8262 - val_loss: 6257.8608\n",
      "Epoch 552/1000\n",
      "4/4 [==============================] - 32s 7s/step - loss: 5389.3926 - val_loss: 6256.4604\n",
      "Epoch 553/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5466.6211 - val_loss: 6255.6865\n",
      "Epoch 554/1000\n",
      "4/4 [==============================] - 32s 7s/step - loss: 5403.4961 - val_loss: 6255.3438\n",
      "Epoch 555/1000\n",
      "4/4 [==============================] - 32s 8s/step - loss: 5428.2476 - val_loss: 6255.6011\n",
      "Epoch 556/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5468.0146 - val_loss: 6256.7964\n",
      "Epoch 557/1000\n",
      "4/4 [==============================] - 27s 7s/step - loss: 5432.5420 - val_loss: 6258.9810\n",
      "Epoch 558/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5328.0688 - val_loss: 6259.7134\n",
      "Epoch 559/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5338.3203 - val_loss: 6258.1113\n",
      "Epoch 560/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5392.5400 - val_loss: 6256.5933\n",
      "Epoch 561/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 5433.4111 - val_loss: 6256.3237\n",
      "Epoch 562/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5416.9526 - val_loss: 6256.7432\n",
      "Epoch 563/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5441.1738 - val_loss: 6259.1465\n",
      "Epoch 564/1000\n",
      "4/4 [==============================] - 29s 7s/step - loss: 5460.0127 - val_loss: 6261.2026\n",
      "Epoch 565/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 5444.5757 - val_loss: 6262.0107\n",
      "Epoch 566/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5446.0757 - val_loss: 6262.4707\n",
      "Epoch 567/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5429.1787 - val_loss: 6264.0693\n",
      "Epoch 568/1000\n",
      "4/4 [==============================] - 20s 4s/step - loss: 5378.7764 - val_loss: 6265.2173\n",
      "Epoch 569/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5417.9453 - val_loss: 6267.0581\n",
      "Epoch 570/1000\n",
      "4/4 [==============================] - 21s 4s/step - loss: 5368.4312 - val_loss: 6268.4434\n",
      "Epoch 571/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5394.9902 - val_loss: 6268.2524\n",
      "Epoch 572/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5412.0693 - val_loss: 6267.2480\n",
      "Epoch 573/1000\n",
      "4/4 [==============================] - 28s 7s/step - loss: 5434.8525 - val_loss: 6268.0400\n",
      "Epoch 574/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5448.8408 - val_loss: 6268.4609\n",
      "Epoch 575/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5409.9795 - val_loss: 6268.5078\n",
      "Epoch 576/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5353.8452 - val_loss: 6269.0781\n",
      "Epoch 577/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5397.7847 - val_loss: 6268.5332\n",
      "Epoch 578/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5382.6895 - val_loss: 6267.9185\n",
      "Epoch 579/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5399.1948 - val_loss: 6267.9395\n",
      "Epoch 580/1000\n",
      "4/4 [==============================] - 30s 8s/step - loss: 5410.3145 - val_loss: 6267.7349\n",
      "Epoch 581/1000\n",
      "4/4 [==============================] - 30s 7s/step - loss: 5433.0674 - val_loss: 6266.8096\n",
      "Epoch 582/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 5437.5195 - val_loss: 6265.9009\n",
      "Epoch 583/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5438.4844 - val_loss: 6266.0024\n",
      "Epoch 584/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5413.0742 - val_loss: 6265.6245\n",
      "Epoch 585/1000\n",
      "4/4 [==============================] - 34s 9s/step - loss: 5410.0283 - val_loss: 6265.0107\n",
      "Epoch 586/1000\n",
      "4/4 [==============================] - 27s 6s/step - loss: 5357.4419 - val_loss: 6265.2861\n",
      "Epoch 587/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5398.9204 - val_loss: 6264.2437\n",
      "Epoch 588/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5414.0591 - val_loss: 6263.3096\n",
      "Epoch 589/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5379.4502 - val_loss: 6262.0903\n",
      "Epoch 590/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 5386.4668 - val_loss: 6260.8916\n",
      "Epoch 591/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5423.6309 - val_loss: 6260.6470\n",
      "Epoch 592/1000\n",
      "4/4 [==============================] - 24s 5s/step - loss: 5432.7373 - val_loss: 6259.9805\n",
      "Epoch 593/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5379.4526 - val_loss: 6260.3887\n",
      "Epoch 594/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5335.9619 - val_loss: 6259.7583\n",
      "Epoch 595/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5383.5088 - val_loss: 6258.5215\n",
      "Epoch 596/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5426.3423 - val_loss: 6257.6030\n",
      "Epoch 597/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5391.4927 - val_loss: 6257.3071\n",
      "Epoch 598/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5373.7466 - val_loss: 6258.2227\n",
      "Epoch 599/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5376.9897 - val_loss: 6259.8340\n",
      "Epoch 600/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5456.1338 - val_loss: 6261.0747\n",
      "Epoch 601/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5400.5918 - val_loss: 6262.1318\n",
      "Epoch 602/1000\n",
      "4/4 [==============================] - 17s 5s/step - loss: 5311.5708 - val_loss: 6262.5337\n",
      "Epoch 603/1000\n",
      "4/4 [==============================] - 20s 4s/step - loss: 5339.1548 - val_loss: 6263.6270\n",
      "Epoch 604/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 5392.1919 - val_loss: 6264.4155\n",
      "Epoch 605/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5365.4854 - val_loss: 6264.9878\n",
      "Epoch 606/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5357.7778 - val_loss: 6265.7998\n",
      "Epoch 607/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5412.5151 - val_loss: 6266.6357\n",
      "Epoch 608/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5440.4272 - val_loss: 6267.9360\n",
      "Epoch 609/1000\n",
      "4/4 [==============================] - 27s 6s/step - loss: 5387.0996 - val_loss: 6268.7192\n",
      "Epoch 610/1000\n",
      "4/4 [==============================] - 26s 5s/step - loss: 5393.3008 - val_loss: 6269.1270\n",
      "Epoch 611/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 5362.5679 - val_loss: 6268.9858\n",
      "Epoch 612/1000\n",
      "4/4 [==============================] - 17s 5s/step - loss: 5349.5903 - val_loss: 6267.8081\n",
      "Epoch 613/1000\n",
      "4/4 [==============================] - 24s 5s/step - loss: 5369.2749 - val_loss: 6266.2690\n",
      "Epoch 614/1000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 5382.1045 - val_loss: 6265.1929\n",
      "Epoch 615/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 5383.6201 - val_loss: 6264.4751\n",
      "Epoch 616/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 18s 4s/step - loss: 5459.7837 - val_loss: 6264.3154\n",
      "Epoch 617/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5374.3257 - val_loss: 6263.8447\n",
      "Epoch 618/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 5399.3413 - val_loss: 6264.3037\n",
      "Epoch 619/1000\n",
      "4/4 [==============================] - 25s 7s/step - loss: 5467.2559 - val_loss: 6265.5068\n",
      "Epoch 620/1000\n",
      "4/4 [==============================] - 28s 6s/step - loss: 5434.5742 - val_loss: 6267.3564\n",
      "Epoch 621/1000\n",
      "4/4 [==============================] - 28s 7s/step - loss: 5447.6025 - val_loss: 6268.6426\n",
      "Epoch 622/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 5435.2202 - val_loss: 6270.4883\n",
      "Epoch 623/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5392.1216 - val_loss: 6270.2642\n",
      "Epoch 624/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5371.5869 - val_loss: 6269.2144\n",
      "Epoch 625/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5373.1304 - val_loss: 6267.5767\n",
      "Epoch 626/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5408.2090 - val_loss: 6266.8354\n",
      "Epoch 627/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5432.3574 - val_loss: 6267.2441\n",
      "Epoch 628/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5359.7769 - val_loss: 6267.1348\n",
      "Epoch 629/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5443.8994 - val_loss: 6267.7563\n",
      "Epoch 630/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5398.0977 - val_loss: 6269.9004\n",
      "Epoch 631/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5362.0601 - val_loss: 6270.8872\n",
      "Epoch 632/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5354.9180 - val_loss: 6270.6631\n",
      "Epoch 633/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 5380.4150 - val_loss: 6269.5869\n",
      "Epoch 634/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5459.7158 - val_loss: 6268.8765\n",
      "Epoch 635/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5396.6909 - val_loss: 6268.0508\n",
      "Epoch 636/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5362.5630 - val_loss: 6267.7905\n",
      "Epoch 637/1000\n",
      "4/4 [==============================] - 28s 8s/step - loss: 5414.5093 - val_loss: 6268.7720\n",
      "Epoch 638/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5345.1562 - val_loss: 6267.4653\n",
      "Epoch 639/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5416.8032 - val_loss: 6266.5283\n",
      "Epoch 640/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5376.8276 - val_loss: 6266.6357\n",
      "Epoch 641/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5408.5112 - val_loss: 6266.0732\n",
      "Epoch 642/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5345.4888 - val_loss: 6266.4121\n",
      "Epoch 643/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5410.3545 - val_loss: 6266.2847\n",
      "Epoch 644/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 5421.5913 - val_loss: 6268.3701\n",
      "Epoch 645/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5390.8193 - val_loss: 6269.7603\n",
      "Epoch 646/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5471.5732 - val_loss: 6271.3301\n",
      "Epoch 647/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5442.6377 - val_loss: 6271.6899\n",
      "Epoch 648/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5443.6284 - val_loss: 6272.5303\n",
      "Epoch 649/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 5440.7656 - val_loss: 6272.9785\n",
      "Epoch 650/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5369.5801 - val_loss: 6272.5225\n",
      "Epoch 651/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 5391.7515 - val_loss: 6272.6792\n",
      "Epoch 652/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5386.4648 - val_loss: 6270.6675\n",
      "Epoch 653/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5407.9741 - val_loss: 6269.6592\n",
      "Epoch 654/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5433.8130 - val_loss: 6269.0513\n",
      "Epoch 655/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5371.5503 - val_loss: 6268.8340\n",
      "Epoch 656/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5370.5356 - val_loss: 6267.9463\n",
      "Epoch 657/1000\n",
      "4/4 [==============================] - 21s 4s/step - loss: 5416.4771 - val_loss: 6266.9121\n",
      "Epoch 658/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5380.8647 - val_loss: 6266.8872\n",
      "Epoch 659/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5400.2720 - val_loss: 6267.0659\n",
      "Epoch 660/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5389.3628 - val_loss: 6267.8599\n",
      "Epoch 661/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 5409.4160 - val_loss: 6269.5229\n",
      "Epoch 662/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5361.9429 - val_loss: 6270.4805\n",
      "Epoch 663/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5387.0054 - val_loss: 6272.2676\n",
      "Epoch 664/1000\n",
      "4/4 [==============================] - 20s 4s/step - loss: 5398.7261 - val_loss: 6273.4502\n",
      "Epoch 665/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5387.9473 - val_loss: 6275.2314\n",
      "Epoch 666/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5378.8931 - val_loss: 6276.3672\n",
      "Epoch 667/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5386.1768 - val_loss: 6277.5117\n",
      "Epoch 668/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5380.1992 - val_loss: 6278.8872\n",
      "Epoch 669/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5401.7280 - val_loss: 6279.7271\n",
      "Epoch 670/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5426.7524 - val_loss: 6280.1655\n",
      "Epoch 671/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 5399.1992 - val_loss: 6281.0044\n",
      "Epoch 672/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5452.6733 - val_loss: 6282.4048\n",
      "Epoch 673/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5334.4180 - val_loss: 6282.2622\n",
      "Epoch 674/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5353.0000 - val_loss: 6280.3442\n",
      "Epoch 675/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5396.9688 - val_loss: 6278.2793\n",
      "Epoch 676/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5413.0464 - val_loss: 6278.4141\n",
      "Epoch 677/1000\n",
      "4/4 [==============================] - 20s 4s/step - loss: 5389.6543 - val_loss: 6278.7407\n",
      "Epoch 678/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5388.0898 - val_loss: 6277.8032\n",
      "Epoch 679/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5451.9702 - val_loss: 6275.3804\n",
      "Epoch 680/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5450.4868 - val_loss: 6275.1885\n",
      "Epoch 681/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5429.9497 - val_loss: 6275.4277\n",
      "Epoch 682/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5450.5498 - val_loss: 6276.1562\n",
      "Epoch 683/1000\n",
      "4/4 [==============================] - 27s 6s/step - loss: 5363.7393 - val_loss: 6277.6426\n",
      "Epoch 684/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5418.8740 - val_loss: 6277.4556\n",
      "Epoch 685/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5358.8442 - val_loss: 6277.6411\n",
      "Epoch 686/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 5403.1270 - val_loss: 6277.3857\n",
      "Epoch 687/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5364.2271 - val_loss: 6278.6968\n",
      "Epoch 688/1000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 5418.6528 - val_loss: 6280.4199\n",
      "Epoch 689/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5407.1123 - val_loss: 6282.0205\n",
      "Epoch 690/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5379.3618 - val_loss: 6282.3174\n",
      "Epoch 691/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5434.8330 - val_loss: 6281.8960\n",
      "Epoch 692/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5462.6870 - val_loss: 6281.7944\n",
      "Epoch 693/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 20s 5s/step - loss: 5377.9878 - val_loss: 6280.9858\n",
      "Epoch 694/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5349.7910 - val_loss: 6279.2959\n",
      "Epoch 695/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5384.4604 - val_loss: 6276.7476\n",
      "Epoch 696/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 5355.8413 - val_loss: 6274.7251\n",
      "Epoch 697/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5418.8872 - val_loss: 6273.6436\n",
      "Epoch 698/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5330.5552 - val_loss: 6272.4263\n",
      "Epoch 699/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5402.5889 - val_loss: 6271.9829\n",
      "Epoch 700/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5458.0645 - val_loss: 6272.3105\n",
      "Epoch 701/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5362.3745 - val_loss: 6272.1040\n",
      "Epoch 702/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5392.5430 - val_loss: 6272.2490\n",
      "Epoch 703/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5334.6763 - val_loss: 6271.5459\n",
      "Epoch 704/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5372.0923 - val_loss: 6271.0518\n",
      "Epoch 705/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5403.2500 - val_loss: 6270.0591\n",
      "Epoch 706/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5400.7432 - val_loss: 6269.9600\n",
      "Epoch 707/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5387.7710 - val_loss: 6270.1587\n",
      "Epoch 708/1000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 5413.2271 - val_loss: 6270.4624\n",
      "Epoch 709/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 5362.3594 - val_loss: 6271.9438\n",
      "Epoch 710/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 5381.3887 - val_loss: 6273.5215\n",
      "Epoch 711/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5373.1670 - val_loss: 6275.0874\n",
      "Epoch 712/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5354.8706 - val_loss: 6277.0117\n",
      "Epoch 713/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5409.6597 - val_loss: 6277.7954\n",
      "Epoch 714/1000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 5389.2754 - val_loss: 6278.0088\n",
      "Epoch 715/1000\n",
      "4/4 [==============================] - 20s 6s/step - loss: 5385.6943 - val_loss: 6278.1592\n",
      "Epoch 716/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5405.7007 - val_loss: 6277.4189\n",
      "Epoch 717/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5389.5830 - val_loss: 6277.9443\n",
      "Epoch 718/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5354.8198 - val_loss: 6277.2500\n",
      "Epoch 719/1000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 5409.0791 - val_loss: 6277.7383\n",
      "Epoch 720/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5387.8677 - val_loss: 6278.4863\n",
      "Epoch 721/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5394.3281 - val_loss: 6278.8086\n",
      "Epoch 722/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5460.1211 - val_loss: 6279.5190\n",
      "Epoch 723/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5414.5654 - val_loss: 6280.1177\n",
      "Epoch 724/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 5394.2871 - val_loss: 6281.1753\n",
      "Epoch 725/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5404.0063 - val_loss: 6280.0215\n",
      "Epoch 726/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5352.4883 - val_loss: 6279.5762\n",
      "Epoch 727/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5352.3481 - val_loss: 6280.2129\n",
      "Epoch 728/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5363.5874 - val_loss: 6279.5488\n",
      "Epoch 729/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5360.1001 - val_loss: 6278.0312\n",
      "Epoch 730/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5345.3340 - val_loss: 6275.9893\n",
      "Epoch 731/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5399.6870 - val_loss: 6275.0400\n",
      "Epoch 732/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5345.7969 - val_loss: 6274.2847\n",
      "Epoch 733/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5446.2021 - val_loss: 6272.9351\n",
      "Epoch 734/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5364.3018 - val_loss: 6272.1758\n",
      "Epoch 735/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5356.2358 - val_loss: 6272.2124\n",
      "Epoch 736/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5380.4536 - val_loss: 6273.0562\n",
      "Epoch 737/1000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 5392.6997 - val_loss: 6274.1616\n",
      "Epoch 738/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5351.9219 - val_loss: 6275.4482\n",
      "Epoch 739/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5396.6895 - val_loss: 6275.0342\n",
      "Epoch 740/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5411.6831 - val_loss: 6275.3843\n",
      "Epoch 741/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5343.6465 - val_loss: 6275.2544\n",
      "Epoch 742/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5368.9302 - val_loss: 6275.1729\n",
      "Epoch 743/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5428.3325 - val_loss: 6275.1934\n",
      "Epoch 744/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5380.1226 - val_loss: 6275.5317\n",
      "Epoch 745/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5341.4043 - val_loss: 6276.3120\n",
      "Epoch 746/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5350.7334 - val_loss: 6276.4336\n",
      "Epoch 747/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5335.1797 - val_loss: 6277.2437\n",
      "Epoch 748/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5356.4487 - val_loss: 6277.0552\n",
      "Epoch 749/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5433.6304 - val_loss: 6276.4883\n",
      "Epoch 750/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5408.8105 - val_loss: 6276.9043\n",
      "Epoch 751/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5434.1899 - val_loss: 6276.6587\n",
      "Epoch 752/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5412.7339 - val_loss: 6277.4941\n",
      "Epoch 753/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 5351.1729 - val_loss: 6277.2402\n",
      "Epoch 754/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5416.7378 - val_loss: 6276.6655\n",
      "Epoch 755/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5373.6763 - val_loss: 6276.2661\n",
      "Epoch 756/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5380.4160 - val_loss: 6275.9810\n",
      "Epoch 757/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5374.8564 - val_loss: 6275.0005\n",
      "Epoch 758/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5405.0752 - val_loss: 6274.1753\n",
      "Epoch 759/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5321.4395 - val_loss: 6273.6216\n",
      "Epoch 760/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5338.8687 - val_loss: 6272.3252\n",
      "Epoch 761/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5382.4155 - val_loss: 6271.6826\n",
      "Epoch 762/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5429.1406 - val_loss: 6272.8120\n",
      "Epoch 763/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5450.3765 - val_loss: 6276.0161\n",
      "Epoch 764/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5388.6450 - val_loss: 6278.3003\n",
      "Epoch 765/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5390.7607 - val_loss: 6279.2056\n",
      "Epoch 766/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5408.1851 - val_loss: 6278.5947\n",
      "Epoch 767/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5364.3271 - val_loss: 6277.1089\n",
      "Epoch 768/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5396.9419 - val_loss: 6275.1323\n",
      "Epoch 769/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5405.4507 - val_loss: 6273.3696\n",
      "Epoch 770/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 5421.6143 - val_loss: 6274.4048\n",
      "Epoch 771/1000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 5373.7373 - val_loss: 6274.4995\n",
      "Epoch 772/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5328.2988 - val_loss: 6275.1743\n",
      "Epoch 773/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5370.3804 - val_loss: 6274.3716\n",
      "Epoch 774/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5312.2676 - val_loss: 6271.6562\n",
      "Epoch 775/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5394.3096 - val_loss: 6267.8955\n",
      "Epoch 776/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5401.4390 - val_loss: 6264.4619\n",
      "Epoch 777/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5294.8472 - val_loss: 6260.7832\n",
      "Epoch 778/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5412.1851 - val_loss: 6255.4404\n",
      "Epoch 779/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5388.4321 - val_loss: 6250.3208\n",
      "Epoch 780/1000\n",
      "4/4 [==============================] - 20s 4s/step - loss: 5378.5454 - val_loss: 6245.8218\n",
      "Epoch 781/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5325.9517 - val_loss: 6241.1069\n",
      "Epoch 782/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5371.0786 - val_loss: 6235.0923\n",
      "Epoch 783/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5313.0625 - val_loss: 6229.4004\n",
      "Epoch 784/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5332.2129 - val_loss: 6224.3389\n",
      "Epoch 785/1000\n",
      "4/4 [==============================] - 17s 5s/step - loss: 5323.5210 - val_loss: 6221.1035\n",
      "Epoch 786/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5372.8745 - val_loss: 6217.8628\n",
      "Epoch 787/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 5329.7183 - val_loss: 6216.2476\n",
      "Epoch 788/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5332.5737 - val_loss: 6212.9800\n",
      "Epoch 789/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5334.1914 - val_loss: 6210.2744\n",
      "Epoch 790/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5364.1860 - val_loss: 6208.5952\n",
      "Epoch 791/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5324.1162 - val_loss: 6207.3545\n",
      "Epoch 792/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5314.7168 - val_loss: 6205.8267\n",
      "Epoch 793/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5362.5898 - val_loss: 6204.9736\n",
      "Epoch 794/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5351.2061 - val_loss: 6203.8994\n",
      "Epoch 795/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5380.3823 - val_loss: 6202.8555\n",
      "Epoch 796/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5335.1016 - val_loss: 6204.0508\n",
      "Epoch 797/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5357.3770 - val_loss: 6204.9185\n",
      "Epoch 798/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5332.4365 - val_loss: 6204.7227\n",
      "Epoch 799/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5377.3950 - val_loss: 6204.0068\n",
      "Epoch 800/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5313.1826 - val_loss: 6203.5664\n",
      "Epoch 801/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5354.2451 - val_loss: 6202.6719\n",
      "Epoch 802/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 5336.6812 - val_loss: 6201.3540\n",
      "Epoch 803/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5322.7354 - val_loss: 6200.4058\n",
      "Epoch 804/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5380.3896 - val_loss: 6201.3008\n",
      "Epoch 805/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5316.3433 - val_loss: 6202.0806\n",
      "Epoch 806/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5338.0415 - val_loss: 6203.3604\n",
      "Epoch 807/1000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 5312.9473 - val_loss: 6203.4258\n",
      "Epoch 808/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5324.8652 - val_loss: 6203.5039\n",
      "Epoch 809/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 5217.6875 - val_loss: 6202.5117\n",
      "Epoch 810/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5328.9556 - val_loss: 6200.9385\n",
      "Epoch 811/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5327.0049 - val_loss: 6201.0713\n",
      "Epoch 812/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5290.5967 - val_loss: 6200.2031\n",
      "Epoch 813/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5305.5430 - val_loss: 6199.7451\n",
      "Epoch 814/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5350.4478 - val_loss: 6200.1426\n",
      "Epoch 815/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5322.2866 - val_loss: 6199.6924\n",
      "Epoch 816/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5303.9595 - val_loss: 6199.1890\n",
      "Epoch 817/1000\n",
      "4/4 [==============================] - 28s 8s/step - loss: 5251.9771 - val_loss: 6198.6753\n",
      "Epoch 818/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5338.2485 - val_loss: 6198.4941\n",
      "Epoch 819/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 5287.9399 - val_loss: 6197.7427\n",
      "Epoch 820/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5280.7607 - val_loss: 6196.5098\n",
      "Epoch 821/1000\n",
      "4/4 [==============================] - 27s 7s/step - loss: 5316.7871 - val_loss: 6196.3174\n",
      "Epoch 822/1000\n",
      "4/4 [==============================] - 20s 4s/step - loss: 5299.4263 - val_loss: 6197.7104\n",
      "Epoch 823/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5282.7363 - val_loss: 6200.3354\n",
      "Epoch 824/1000\n",
      "4/4 [==============================] - 17s 5s/step - loss: 5217.9790 - val_loss: 6202.4419\n",
      "Epoch 825/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5281.7993 - val_loss: 6203.4380\n",
      "Epoch 826/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5275.1401 - val_loss: 6201.9775\n",
      "Epoch 827/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5362.5513 - val_loss: 6201.4155\n",
      "Epoch 828/1000\n",
      "4/4 [==============================] - 17s 5s/step - loss: 5275.6646 - val_loss: 6201.1235\n",
      "Epoch 829/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5297.5181 - val_loss: 6202.6919\n",
      "Epoch 830/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5304.2476 - val_loss: 6203.9546\n",
      "Epoch 831/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5333.1338 - val_loss: 6203.4609\n",
      "Epoch 832/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5321.4907 - val_loss: 6202.9741\n",
      "Epoch 833/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5251.4810 - val_loss: 6202.0435\n",
      "Epoch 834/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 5302.7305 - val_loss: 6202.4844\n",
      "Epoch 835/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5309.5957 - val_loss: 6201.4502\n",
      "Epoch 836/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5289.3452 - val_loss: 6202.1221\n",
      "Epoch 837/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5297.8755 - val_loss: 6202.4468\n",
      "Epoch 838/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5290.5864 - val_loss: 6203.6738\n",
      "Epoch 839/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5267.7744 - val_loss: 6204.6118\n",
      "Epoch 840/1000\n",
      "4/4 [==============================] - 17s 5s/step - loss: 5293.5557 - val_loss: 6204.2637\n",
      "Epoch 841/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 5342.2744 - val_loss: 6207.0122\n",
      "Epoch 842/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5266.3462 - val_loss: 6208.6611\n",
      "Epoch 843/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5319.0254 - val_loss: 6209.9097\n",
      "Epoch 844/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5288.0698 - val_loss: 6210.5215\n",
      "Epoch 845/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5274.3745 - val_loss: 6210.0552\n",
      "Epoch 846/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5328.7988 - val_loss: 6209.6768\n",
      "Epoch 847/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 4s/step - loss: 5255.6079 - val_loss: 6208.0420\n",
      "Epoch 848/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5290.2251 - val_loss: 6208.1724\n",
      "Epoch 849/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5235.2402 - val_loss: 6207.3833\n",
      "Epoch 850/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5264.0908 - val_loss: 6207.0850\n",
      "Epoch 851/1000\n",
      "4/4 [==============================] - 20s 4s/step - loss: 5197.8794 - val_loss: 6206.9282\n",
      "Epoch 852/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5215.2568 - val_loss: 6206.1035\n",
      "Epoch 853/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5321.4980 - val_loss: 6206.4067\n",
      "Epoch 854/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5284.9463 - val_loss: 6208.0244\n",
      "Epoch 855/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5312.3672 - val_loss: 6211.1182\n",
      "Epoch 856/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5263.9893 - val_loss: 6213.1772\n",
      "Epoch 857/1000\n",
      "4/4 [==============================] - 20s 4s/step - loss: 5292.1611 - val_loss: 6214.6562\n",
      "Epoch 858/1000\n",
      "4/4 [==============================] - 17s 5s/step - loss: 5225.5728 - val_loss: 6213.6533\n",
      "Epoch 859/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5341.6226 - val_loss: 6213.1494\n",
      "Epoch 860/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5303.6260 - val_loss: 6214.3364\n",
      "Epoch 861/1000\n",
      "4/4 [==============================] - 50s 14s/step - loss: 5232.7759 - val_loss: 6214.1411\n",
      "Epoch 862/1000\n",
      "4/4 [==============================] - 113s 29s/step - loss: 5259.3491 - val_loss: 6212.5620\n",
      "Epoch 863/1000\n",
      "4/4 [==============================] - 64s 17s/step - loss: 5304.0190 - val_loss: 6212.7563\n",
      "Epoch 864/1000\n",
      "4/4 [==============================] - 31s 7s/step - loss: 5208.7080 - val_loss: 6212.6328\n",
      "Epoch 865/1000\n",
      "4/4 [==============================] - 20s 4s/step - loss: 5316.4409 - val_loss: 6213.0264\n",
      "Epoch 866/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5275.5640 - val_loss: 6216.3755\n",
      "Epoch 867/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5297.7896 - val_loss: 6219.5278\n",
      "Epoch 868/1000\n",
      "4/4 [==============================] - 27s 6s/step - loss: 5301.6768 - val_loss: 6222.2012\n",
      "Epoch 869/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5302.3706 - val_loss: 6226.2593\n",
      "Epoch 870/1000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 5318.1934 - val_loss: 6228.4722\n",
      "Epoch 871/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 5254.3892 - val_loss: 6228.3643\n",
      "Epoch 872/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5274.3071 - val_loss: 6229.2056\n",
      "Epoch 873/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5334.7759 - val_loss: 6227.1118\n",
      "Epoch 874/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5281.4443 - val_loss: 6225.1885\n",
      "Epoch 875/1000\n",
      "4/4 [==============================] - 28s 6s/step - loss: 5183.0078 - val_loss: 6222.4438\n",
      "Epoch 876/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5240.7739 - val_loss: 6221.7021\n",
      "Epoch 877/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5285.2056 - val_loss: 6219.2656\n",
      "Epoch 878/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5305.3867 - val_loss: 6218.3398\n",
      "Epoch 879/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5295.6714 - val_loss: 6216.2021\n",
      "Epoch 880/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5259.8706 - val_loss: 6214.6782\n",
      "Epoch 881/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 5285.1753 - val_loss: 6213.2383\n",
      "Epoch 882/1000\n",
      "4/4 [==============================] - 25s 5s/step - loss: 5253.9463 - val_loss: 6213.2617\n",
      "Epoch 883/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5325.2949 - val_loss: 6213.1782\n",
      "Epoch 884/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 5267.0947 - val_loss: 6212.4995\n",
      "Epoch 885/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5295.1714 - val_loss: 6212.8203\n",
      "Epoch 886/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5291.1792 - val_loss: 6213.5869\n",
      "Epoch 887/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5283.1343 - val_loss: 6215.5850\n",
      "Epoch 888/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5232.5435 - val_loss: 6217.3408\n",
      "Epoch 889/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5281.1289 - val_loss: 6218.2612\n",
      "Epoch 890/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5284.7266 - val_loss: 6218.3027\n",
      "Epoch 891/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5319.0928 - val_loss: 6220.5117\n",
      "Epoch 892/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 5210.8882 - val_loss: 6222.9473\n",
      "Epoch 893/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5268.0024 - val_loss: 6225.6304\n",
      "Epoch 894/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5263.9106 - val_loss: 6227.7295\n",
      "Epoch 895/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5241.3496 - val_loss: 6230.3252\n",
      "Epoch 896/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5288.4868 - val_loss: 6228.3789\n",
      "Epoch 897/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5243.3691 - val_loss: 6226.3760\n",
      "Epoch 898/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5250.0166 - val_loss: 6224.7061\n",
      "Epoch 899/1000\n",
      "4/4 [==============================] - 24s 5s/step - loss: 5251.7261 - val_loss: 6222.1978\n",
      "Epoch 900/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5297.3179 - val_loss: 6221.3291\n",
      "Epoch 901/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5243.8809 - val_loss: 6222.9077\n",
      "Epoch 902/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5284.0962 - val_loss: 6223.5044\n",
      "Epoch 903/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5276.6597 - val_loss: 6224.4360\n",
      "Epoch 904/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5280.0317 - val_loss: 6226.0435\n",
      "Epoch 905/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5268.9321 - val_loss: 6228.1548\n",
      "Epoch 906/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 5270.8286 - val_loss: 6229.5312\n",
      "Epoch 907/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5283.4146 - val_loss: 6229.4883\n",
      "Epoch 908/1000\n",
      "4/4 [==============================] - 17s 5s/step - loss: 5221.7183 - val_loss: 6227.2319\n",
      "Epoch 909/1000\n",
      "4/4 [==============================] - 20s 4s/step - loss: 5286.0400 - val_loss: 6225.8525\n",
      "Epoch 910/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5243.2988 - val_loss: 6224.6104\n",
      "Epoch 911/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5261.9331 - val_loss: 6222.7866\n",
      "Epoch 912/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5250.8037 - val_loss: 6222.6182\n",
      "Epoch 913/1000\n",
      "4/4 [==============================] - 24s 5s/step - loss: 5226.3838 - val_loss: 6221.6553\n",
      "Epoch 914/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5232.8745 - val_loss: 6220.7847\n",
      "Epoch 915/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5265.0249 - val_loss: 6219.8940\n",
      "Epoch 916/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5303.1650 - val_loss: 6220.3198\n",
      "Epoch 917/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5288.3198 - val_loss: 6221.6396\n",
      "Epoch 918/1000\n",
      "4/4 [==============================] - 20s 6s/step - loss: 5260.2041 - val_loss: 6222.4814\n",
      "Epoch 919/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5282.7788 - val_loss: 6221.7437\n",
      "Epoch 920/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5284.1201 - val_loss: 6220.0767\n",
      "Epoch 921/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5254.1533 - val_loss: 6219.4062\n",
      "Epoch 922/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5216.8472 - val_loss: 6219.3047\n",
      "Epoch 923/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5264.5195 - val_loss: 6219.9009\n",
      "Epoch 924/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 5229.4102 - val_loss: 6222.3643\n",
      "Epoch 925/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5300.2651 - val_loss: 6225.3579\n",
      "Epoch 926/1000\n",
      "4/4 [==============================] - 32s 8s/step - loss: 5229.0752 - val_loss: 6227.0391\n",
      "Epoch 927/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5257.7441 - val_loss: 6228.5068\n",
      "Epoch 928/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5250.9966 - val_loss: 6229.5146\n",
      "Epoch 929/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5258.4585 - val_loss: 6230.6167\n",
      "Epoch 930/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5201.1035 - val_loss: 6229.5732\n",
      "Epoch 931/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5265.0176 - val_loss: 6228.6514\n",
      "Epoch 932/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5255.8774 - val_loss: 6227.7808\n",
      "Epoch 933/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 5246.3452 - val_loss: 6226.7349\n",
      "Epoch 934/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5249.7173 - val_loss: 6224.9727\n",
      "Epoch 935/1000\n",
      "4/4 [==============================] - 20s 4s/step - loss: 5273.1304 - val_loss: 6224.7944\n",
      "Epoch 936/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5264.5308 - val_loss: 6221.7212\n",
      "Epoch 937/1000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 5295.1421 - val_loss: 6221.4639\n",
      "Epoch 938/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5226.4321 - val_loss: 6222.4077\n",
      "Epoch 939/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5251.5493 - val_loss: 6224.2065\n",
      "Epoch 940/1000\n",
      "4/4 [==============================] - 20s 4s/step - loss: 5239.2700 - val_loss: 6225.6377\n",
      "Epoch 941/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5236.1753 - val_loss: 6224.8032\n",
      "Epoch 942/1000\n",
      "4/4 [==============================] - 20s 4s/step - loss: 5283.4121 - val_loss: 6224.9868\n",
      "Epoch 943/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5245.6401 - val_loss: 6223.8013\n",
      "Epoch 944/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5315.5874 - val_loss: 6224.3608\n",
      "Epoch 945/1000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 5279.2529 - val_loss: 6224.3794\n",
      "Epoch 946/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 5253.3188 - val_loss: 6223.7041\n",
      "Epoch 947/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5172.9258 - val_loss: 6222.3608\n",
      "Epoch 948/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5254.4507 - val_loss: 6219.6084\n",
      "Epoch 949/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5250.8213 - val_loss: 6219.4932\n",
      "Epoch 950/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5203.8340 - val_loss: 6219.4727\n",
      "Epoch 951/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5289.5435 - val_loss: 6219.5190\n",
      "Epoch 952/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5236.5679 - val_loss: 6219.6377\n",
      "Epoch 953/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5241.3423 - val_loss: 6221.4678\n",
      "Epoch 954/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5245.4648 - val_loss: 6222.8999\n",
      "Epoch 955/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5279.1187 - val_loss: 6224.3467\n",
      "Epoch 956/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5245.9272 - val_loss: 6225.4434\n",
      "Epoch 957/1000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 5217.1416 - val_loss: 6224.3765\n",
      "Epoch 958/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5265.6792 - val_loss: 6222.6729\n",
      "Epoch 959/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5213.6167 - val_loss: 6220.7148\n",
      "Epoch 960/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 5230.4893 - val_loss: 6219.6987\n",
      "Epoch 961/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5236.3491 - val_loss: 6218.4609\n",
      "Epoch 962/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5286.0522 - val_loss: 6217.9683\n",
      "Epoch 963/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5258.1182 - val_loss: 6218.7881\n",
      "Epoch 964/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5270.6851 - val_loss: 6220.6367\n",
      "Epoch 965/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5282.6182 - val_loss: 6223.9624\n",
      "Epoch 966/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5205.8462 - val_loss: 6226.0698\n",
      "Epoch 967/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5264.7319 - val_loss: 6227.3091\n",
      "Epoch 968/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5222.9351 - val_loss: 6228.1328\n",
      "Epoch 969/1000\n",
      "4/4 [==============================] - 27s 7s/step - loss: 5224.2969 - val_loss: 6227.7251\n",
      "Epoch 970/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5232.2788 - val_loss: 6226.4580\n",
      "Epoch 971/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5299.4971 - val_loss: 6226.4136\n",
      "Epoch 972/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5272.7207 - val_loss: 6227.0806\n",
      "Epoch 973/1000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 5249.9263 - val_loss: 6227.7017\n",
      "Epoch 974/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5205.2656 - val_loss: 6228.0366\n",
      "Epoch 975/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5248.0254 - val_loss: 6227.9204\n",
      "Epoch 976/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5269.6162 - val_loss: 6227.7773\n",
      "Epoch 977/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5272.1250 - val_loss: 6226.4644\n",
      "Epoch 978/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5234.7578 - val_loss: 6223.8501\n",
      "Epoch 979/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5235.9824 - val_loss: 6222.1387\n",
      "Epoch 980/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5232.6895 - val_loss: 6222.3662\n",
      "Epoch 981/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5266.4502 - val_loss: 6224.4272\n",
      "Epoch 982/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5233.6562 - val_loss: 6224.0024\n",
      "Epoch 983/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5255.0059 - val_loss: 6225.1719\n",
      "Epoch 984/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5230.0356 - val_loss: 6224.9902\n",
      "Epoch 985/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 5247.2700 - val_loss: 6223.1694\n",
      "Epoch 986/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 5232.2988 - val_loss: 6222.9600\n",
      "Epoch 987/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5196.9531 - val_loss: 6221.9253\n",
      "Epoch 988/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5238.5679 - val_loss: 6221.4707\n",
      "Epoch 989/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5270.8638 - val_loss: 6222.6025\n",
      "Epoch 990/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5171.6631 - val_loss: 6223.4727\n",
      "Epoch 991/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5198.3872 - val_loss: 6220.9629\n",
      "Epoch 992/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 5213.9658 - val_loss: 6219.4985\n",
      "Epoch 993/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5162.9673 - val_loss: 6218.3765\n",
      "Epoch 994/1000\n",
      "4/4 [==============================] - 33s 7s/step - loss: 5244.0615 - val_loss: 6217.8408\n",
      "Epoch 995/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 5245.2124 - val_loss: 6219.3184\n",
      "Epoch 996/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5186.5991 - val_loss: 6220.2368\n",
      "Epoch 997/1000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5189.2271 - val_loss: 6219.6792\n",
      "Epoch 998/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5188.8496 - val_loss: 6217.9785\n",
      "Epoch 999/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5257.0962 - val_loss: 6218.5254\n",
      "Epoch 1000/1000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5208.2490 - val_loss: 6218.7231\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist1 = Model1.fit(x_train, y_train, epochs=1000, batch_size=4096, verbose=1, validation_split=0.25)\n",
    "plt.plot(hist1.history['loss'])\n",
    "plt.plot(hist1.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fc9e636f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           [(None, 128, 93)]         0         \n",
      "_________________________________________________________________\n",
      "Bi-LSTM1 (LSTM)              (None, 128, 46)           25760     \n",
      "_________________________________________________________________\n",
      "DropOut-1 (Dropout)          (None, 128, 46)           0         \n",
      "_________________________________________________________________\n",
      "Convolution-1 (Conv1D)       (None, 97, 46)            67758     \n",
      "_________________________________________________________________\n",
      "MaxPool-1 (MaxPooling1D)     (None, 48, 46)            0         \n",
      "_________________________________________________________________\n",
      "Bi-LSTM2 (LSTM)              (None, 48, 23)            6440      \n",
      "_________________________________________________________________\n",
      "DropOut-2 (Dropout)          (None, 48, 23)            0         \n",
      "_________________________________________________________________\n",
      "Convolution-2 (Conv1D)       (None, 17, 23)            16951     \n",
      "_________________________________________________________________\n",
      "MaxPool-2 (MaxPooling1D)     (None, 8, 23)             0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 9)                 1188      \n",
      "_________________________________________________________________\n",
      "Fully-Connected (Dense)      (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "Output (Dense)               (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 118,197\n",
      "Trainable params: 118,197\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def rul_mdl2(batch_size = None,in_feature = x_train.shape[2], out_f = 1, len_ts = x_train.shape[1]):\n",
    "    inp = layers.Input(batch_shape= (batch_size, len_ts, x_train.shape[2]), name=\"Input\")\n",
    "    l1 = layers.LSTM(units = int(x_train.shape[2]/2),return_sequences = True, name = 'Bi-LSTM1')(inp)\n",
    "    l1d = layers.Dropout(0.3, name = 'DropOut-1')(l1)\n",
    "    l1c = layers.Conv1D(filters = int(x_train.shape[2]/2),kernel_size = 32, name = 'Convolution-1')(l1d)\n",
    "    l1mp = layers.MaxPool1D(pool_size=2, name = 'MaxPool-1')(l1c)\n",
    "    l2 = layers.LSTM(units = int(x_train.shape[2]/4),return_sequences = True, name = 'Bi-LSTM2')(l1mp)\n",
    "    l2d = layers.Dropout(0.3, name = 'DropOut-2')(l2)\n",
    "    l2c = layers.Conv1D(filters = int(x_train.shape[2]/4),kernel_size = 32, name = 'Convolution-2')(l2d)\n",
    "    l2mp = layers.MaxPooling1D(pool_size=2, name = 'MaxPool-2')(l2c)\n",
    "    l3 = layers.LSTM(units = int(x_train.shape[2]/10), return_sequences = False)(l2mp)\n",
    "    l4 = layers.Dense(units = int(x_train.shape[2]/10), activation = 'relu', name = 'Fully-Connected')(l3)\n",
    "    out = layers.Dense(units = out_f, activation = 'linear', name = 'Output')(l4)\n",
    "    M = models.Model(inputs = inp, outputs =  out)\n",
    "    M.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return M\n",
    "Model2 = rul_mdl2()\n",
    "Model2.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f27a8429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "4/4 [==============================] - 84s 15s/step - loss: 15289.3389 - val_loss: 19418.0078\n",
      "Epoch 2/1000\n",
      "4/4 [==============================] - 69s 18s/step - loss: 15178.8086 - val_loss: 19287.7402\n",
      "Epoch 3/1000\n",
      "4/4 [==============================] - 67s 9s/step - loss: 15078.4727 - val_loss: 19195.4609\n",
      "Epoch 4/1000\n",
      "4/4 [==============================] - 42s 7s/step - loss: 14991.7646 - val_loss: 19069.1074\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 14912.8076 - val_loss: 19017.8672\n",
      "Epoch 6/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 14863.5918 - val_loss: 18945.8730\n",
      "Epoch 7/1000\n",
      "4/4 [==============================] - 25s 5s/step - loss: 14801.4160 - val_loss: 18894.8105\n",
      "Epoch 8/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 14764.4492 - val_loss: 18861.0195\n",
      "Epoch 9/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 14733.2080 - val_loss: 18830.3652\n",
      "Epoch 10/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 14711.1709 - val_loss: 18809.7363\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 14693.2002 - val_loss: 18790.0234\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 14675.6621 - val_loss: 18770.3926\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - 27s 7s/step - loss: 14658.2256 - val_loss: 18750.7949\n",
      "Epoch 14/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 14640.7539 - val_loss: 18731.1660\n",
      "Epoch 15/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 14623.3105 - val_loss: 18711.4336\n",
      "Epoch 16/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 14605.7197 - val_loss: 18691.6094\n",
      "Epoch 17/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 14588.1045 - val_loss: 18671.6484\n",
      "Epoch 18/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 14570.2793 - val_loss: 18651.5762\n",
      "Epoch 19/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 14552.4072 - val_loss: 18631.3457\n",
      "Epoch 20/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 14534.3643 - val_loss: 18610.9609\n",
      "Epoch 21/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 14516.1738 - val_loss: 18590.4082\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 14497.8740 - val_loss: 18569.6660\n",
      "Epoch 23/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 14479.4043 - val_loss: 18548.7266\n",
      "Epoch 24/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 14460.7334 - val_loss: 18527.6035\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - 27s 6s/step - loss: 14441.9072 - val_loss: 18506.2852\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 14422.8555 - val_loss: 18484.7773\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 14403.6953 - val_loss: 18463.0410\n",
      "Epoch 28/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 14384.3545 - val_loss: 18441.0762\n",
      "Epoch 29/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 14364.7510 - val_loss: 18418.9023\n",
      "Epoch 30/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 14345.0371 - val_loss: 18396.4902\n",
      "Epoch 31/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 14324.9980 - val_loss: 18373.8828\n",
      "Epoch 32/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 14304.8555 - val_loss: 18351.0449\n",
      "Epoch 33/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 14284.5254 - val_loss: 18327.9414\n",
      "Epoch 34/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 14263.9590 - val_loss: 18304.6191\n",
      "Epoch 35/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 14243.2256 - val_loss: 18281.0566\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 14222.2549 - val_loss: 18257.2695\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - 25s 5s/step - loss: 14201.0498 - val_loss: 18233.2656\n",
      "Epoch 38/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 14179.7539 - val_loss: 18209.0020\n",
      "Epoch 39/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 14158.1504 - val_loss: 18184.5234\n",
      "Epoch 40/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 14136.3164 - val_loss: 18159.8340\n",
      "Epoch 41/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 14114.3242 - val_loss: 18134.9141\n",
      "Epoch 42/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 14092.1777 - val_loss: 18109.7285\n",
      "Epoch 43/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 14069.7900 - val_loss: 18084.3047\n",
      "Epoch 44/1000\n",
      "4/4 [==============================] - 24s 5s/step - loss: 14047.2324 - val_loss: 18058.6211\n",
      "Epoch 45/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 14024.3486 - val_loss: 18032.7363\n",
      "Epoch 46/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 14001.3105 - val_loss: 18006.6211\n",
      "Epoch 47/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 13978.1133 - val_loss: 17980.2441\n",
      "Epoch 48/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 13954.6895 - val_loss: 17953.6309\n",
      "Epoch 49/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 13930.9873 - val_loss: 17926.8027\n",
      "Epoch 50/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 13907.1562 - val_loss: 17899.7441\n",
      "Epoch 51/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 13883.1699 - val_loss: 17872.4043\n",
      "Epoch 52/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 13858.8203 - val_loss: 17844.8691\n",
      "Epoch 53/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 13834.4590 - val_loss: 17817.0684\n",
      "Epoch 54/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 13809.6875 - val_loss: 17789.0840\n",
      "Epoch 55/1000\n",
      "4/4 [==============================] - 28s 8s/step - loss: 13784.8867 - val_loss: 17760.8281\n",
      "Epoch 56/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 13759.8379 - val_loss: 17732.3281\n",
      "Epoch 57/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 13734.5273 - val_loss: 17703.6152\n",
      "Epoch 58/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 13709.0449 - val_loss: 17674.6719\n",
      "Epoch 59/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 13683.3271 - val_loss: 17645.5039\n",
      "Epoch 60/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 13657.5703 - val_loss: 17616.0625\n",
      "Epoch 61/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 13631.3682 - val_loss: 17586.4473\n",
      "Epoch 62/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 13605.1221 - val_loss: 17556.5820\n",
      "Epoch 63/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 13578.6953 - val_loss: 17526.4766\n",
      "Epoch 64/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 13552.0293 - val_loss: 17496.1523\n",
      "Epoch 65/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 13525.1689 - val_loss: 17465.6094\n",
      "Epoch 66/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 13498.0859 - val_loss: 17434.8672\n",
      "Epoch 67/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 13470.8477 - val_loss: 17403.9043\n",
      "Epoch 68/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 13443.4814 - val_loss: 17372.6914\n",
      "Epoch 69/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 13415.7725 - val_loss: 17341.3066\n",
      "Epoch 70/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 13388.0098 - val_loss: 17309.6797\n",
      "Epoch 71/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 13360.0664 - val_loss: 17277.8125\n",
      "Epoch 72/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 13331.8828 - val_loss: 17245.7402\n",
      "Epoch 73/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 13303.5303 - val_loss: 17213.4570\n",
      "Epoch 74/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 13275.0605 - val_loss: 17180.9395\n",
      "Epoch 75/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 13246.2920 - val_loss: 17148.2520\n",
      "Epoch 76/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 13217.3096 - val_loss: 17115.4062\n",
      "Epoch 77/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 20s 5s/step - loss: 13188.3281 - val_loss: 17082.3105\n",
      "Epoch 78/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 13159.0898 - val_loss: 17049.0176\n",
      "Epoch 79/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 13129.6641 - val_loss: 17015.5273\n",
      "Epoch 80/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 13100.1016 - val_loss: 16981.8184\n",
      "Epoch 81/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 13070.3506 - val_loss: 16947.9043\n",
      "Epoch 82/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 13040.4346 - val_loss: 16913.7969\n",
      "Epoch 83/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 13010.2998 - val_loss: 16879.5137\n",
      "Epoch 84/1000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 12980.0684 - val_loss: 16845.0215\n",
      "Epoch 85/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 12949.6055 - val_loss: 16810.3477\n",
      "Epoch 86/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 12919.0977 - val_loss: 16775.4434\n",
      "Epoch 87/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 12888.2598 - val_loss: 16740.3926\n",
      "Epoch 88/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 12857.3672 - val_loss: 16705.1465\n",
      "Epoch 89/1000\n",
      "4/4 [==============================] - 24s 5s/step - loss: 12826.3760 - val_loss: 16669.6777\n",
      "Epoch 90/1000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 12795.0713 - val_loss: 16634.0723\n",
      "Epoch 91/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 12763.7656 - val_loss: 16598.2402\n",
      "Epoch 92/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 12732.1562 - val_loss: 16562.2734\n",
      "Epoch 93/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 12700.5527 - val_loss: 16526.0957\n",
      "Epoch 94/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 12668.6934 - val_loss: 16489.7559\n",
      "Epoch 95/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 12636.7559 - val_loss: 16453.2266\n",
      "Epoch 96/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 12604.5322 - val_loss: 16416.5684\n",
      "Epoch 97/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 12572.3457 - val_loss: 16379.7002\n",
      "Epoch 98/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 12539.8652 - val_loss: 16342.6826\n",
      "Epoch 99/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 12507.4463 - val_loss: 16305.4424\n",
      "Epoch 100/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 12474.7139 - val_loss: 16268.0654\n",
      "Epoch 101/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 12441.8389 - val_loss: 16230.5674\n",
      "Epoch 102/1000\n",
      "4/4 [==============================] - 28s 8s/step - loss: 12408.9277 - val_loss: 16192.8945\n",
      "Epoch 103/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 12375.9209 - val_loss: 16155.0420\n",
      "Epoch 104/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 12342.7109 - val_loss: 16117.0508\n",
      "Epoch 105/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 12309.4180 - val_loss: 16078.8994\n",
      "Epoch 106/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 12275.8574 - val_loss: 16040.6523\n",
      "Epoch 107/1000\n",
      "4/4 [==============================] - 32s 8s/step - loss: 12242.3369 - val_loss: 16002.2207\n",
      "Epoch 108/1000\n",
      "4/4 [==============================] - 34s 9s/step - loss: 12208.6162 - val_loss: 15963.6455\n",
      "Epoch 109/1000\n",
      "4/4 [==============================] - 33s 8s/step - loss: 12174.8350 - val_loss: 15924.9033\n",
      "Epoch 110/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 12140.8604 - val_loss: 15886.0371\n",
      "Epoch 111/1000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 12106.8779 - val_loss: 15847.0059\n",
      "Epoch 112/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 12072.7090 - val_loss: 15807.8506\n",
      "Epoch 113/1000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 12038.4307 - val_loss: 15768.5771\n",
      "Epoch 114/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 12004.1094 - val_loss: 15729.1533\n",
      "Epoch 115/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 11969.5811 - val_loss: 15689.6211\n",
      "Epoch 116/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 11934.9805 - val_loss: 15649.9668\n",
      "Epoch 117/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 11900.3291 - val_loss: 15610.1787\n",
      "Epoch 118/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 11865.6035 - val_loss: 15570.2441\n",
      "Epoch 119/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 11830.7129 - val_loss: 15530.2051\n",
      "Epoch 120/1000\n",
      "4/4 [==============================] - 27s 7s/step - loss: 11795.7109 - val_loss: 15490.0645\n",
      "Epoch 121/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 11760.7256 - val_loss: 15449.7725\n",
      "Epoch 122/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 11725.5361 - val_loss: 15409.3955\n",
      "Epoch 123/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 11690.2363 - val_loss: 15368.9238\n",
      "Epoch 124/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 11655.0566 - val_loss: 15328.2891\n",
      "Epoch 125/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 11619.5771 - val_loss: 15287.5928\n",
      "Epoch 126/1000\n",
      "4/4 [==============================] - 27s 7s/step - loss: 11584.0205 - val_loss: 15246.8281\n",
      "Epoch 127/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 11548.5215 - val_loss: 15205.9277\n",
      "Epoch 128/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 11512.8779 - val_loss: 15164.9189\n",
      "Epoch 129/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 11477.2217 - val_loss: 15123.7783\n",
      "Epoch 130/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 11441.3301 - val_loss: 15082.5781\n",
      "Epoch 131/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 11405.5459 - val_loss: 15041.2363\n",
      "Epoch 132/1000\n",
      "4/4 [==============================] - 29s 8s/step - loss: 11369.6035 - val_loss: 14999.8076\n",
      "Epoch 133/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 11333.5195 - val_loss: 14958.3174\n",
      "Epoch 134/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 11297.5059 - val_loss: 14916.7129\n",
      "Epoch 135/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 11261.3408 - val_loss: 14875.0352\n",
      "Epoch 136/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 11225.1797 - val_loss: 14833.2812\n",
      "Epoch 137/1000\n",
      "4/4 [==============================] - 29s 7s/step - loss: 11188.8516 - val_loss: 14791.4814\n",
      "Epoch 138/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 11152.5703 - val_loss: 14749.5938\n",
      "Epoch 139/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 11116.2832 - val_loss: 14707.5908\n",
      "Epoch 140/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 11079.7988 - val_loss: 14665.5449\n",
      "Epoch 141/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 11043.3330 - val_loss: 14623.4385\n",
      "Epoch 142/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 11006.9316 - val_loss: 14581.2314\n",
      "Epoch 143/1000\n",
      "4/4 [==============================] - 27s 6s/step - loss: 10970.4365 - val_loss: 14538.9531\n",
      "Epoch 144/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 10933.7324 - val_loss: 14496.6758\n",
      "Epoch 145/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 10897.2158 - val_loss: 14454.2930\n",
      "Epoch 146/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 10860.4014 - val_loss: 14411.9268\n",
      "Epoch 147/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 10823.8232 - val_loss: 14369.4541\n",
      "Epoch 148/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 10787.1465 - val_loss: 14326.9141\n",
      "Epoch 149/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 10750.4775 - val_loss: 14284.2998\n",
      "Epoch 150/1000\n",
      "4/4 [==============================] - 31s 8s/step - loss: 10713.5928 - val_loss: 14241.7148\n",
      "Epoch 151/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 10676.8359 - val_loss: 14199.0703\n",
      "Epoch 152/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 10640.0088 - val_loss: 14156.3994\n",
      "Epoch 153/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 24s 6s/step - loss: 10603.1240 - val_loss: 14113.7139\n",
      "Epoch 154/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 10566.3027 - val_loss: 14070.9619\n",
      "Epoch 155/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 10529.4209 - val_loss: 14028.1572\n",
      "Epoch 156/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 10492.5859 - val_loss: 13985.2891\n",
      "Epoch 157/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 10455.7109 - val_loss: 13942.3750\n",
      "Epoch 158/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 10418.7383 - val_loss: 13899.4570\n",
      "Epoch 159/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 10381.9258 - val_loss: 13856.4590\n",
      "Epoch 160/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 10344.7656 - val_loss: 13813.5342\n",
      "Epoch 161/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 10307.8936 - val_loss: 13770.5342\n",
      "Epoch 162/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 10270.9932 - val_loss: 13727.4912\n",
      "Epoch 163/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 10234.0371 - val_loss: 13684.4434\n",
      "Epoch 164/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 10197.0449 - val_loss: 13641.4219\n",
      "Epoch 165/1000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 10160.1455 - val_loss: 13598.3633\n",
      "Epoch 166/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 10123.1807 - val_loss: 13555.3115\n",
      "Epoch 167/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 10086.3848 - val_loss: 13512.1904\n",
      "Epoch 168/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 10049.3447 - val_loss: 13469.1250\n",
      "Epoch 169/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 10012.5068 - val_loss: 13426.0332\n",
      "Epoch 170/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 9975.5967 - val_loss: 13382.9590\n",
      "Epoch 171/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 9938.7578 - val_loss: 13339.8848\n",
      "Epoch 172/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 9902.0186 - val_loss: 13296.7832\n",
      "Epoch 173/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 9865.1543 - val_loss: 13253.7275\n",
      "Epoch 174/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 9828.3477 - val_loss: 13210.7246\n",
      "Epoch 175/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 9791.6953 - val_loss: 13167.6992\n",
      "Epoch 176/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 9754.8721 - val_loss: 13124.7324\n",
      "Epoch 177/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 9718.3213 - val_loss: 13081.7275\n",
      "Epoch 178/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 9681.5977 - val_loss: 13038.7891\n",
      "Epoch 179/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 9644.9766 - val_loss: 12995.8779\n",
      "Epoch 180/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 9608.4775 - val_loss: 12952.9609\n",
      "Epoch 181/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 9571.9854 - val_loss: 12910.0615\n",
      "Epoch 182/1000\n",
      "4/4 [==============================] - 31s 8s/step - loss: 9535.5156 - val_loss: 12867.1904\n",
      "Epoch 183/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 9498.9062 - val_loss: 12824.4287\n",
      "Epoch 184/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 9462.5820 - val_loss: 12781.6514\n",
      "Epoch 185/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 9426.3516 - val_loss: 12738.8535\n",
      "Epoch 186/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 9389.9922 - val_loss: 12696.1338\n",
      "Epoch 187/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 9353.7207 - val_loss: 12653.4736\n",
      "Epoch 188/1000\n",
      "4/4 [==============================] - 42s 11s/step - loss: 9317.6006 - val_loss: 12610.8330\n",
      "Epoch 189/1000\n",
      "4/4 [==============================] - 34s 9s/step - loss: 9281.4941 - val_loss: 12568.2432\n",
      "Epoch 190/1000\n",
      "4/4 [==============================] - 49s 11s/step - loss: 9245.4199 - val_loss: 12525.7031\n",
      "Epoch 191/1000\n",
      "4/4 [==============================] - 44s 11s/step - loss: 9209.3721 - val_loss: 12483.2227\n",
      "Epoch 192/1000\n",
      "4/4 [==============================] - 43s 11s/step - loss: 9173.4004 - val_loss: 12440.8037\n",
      "Epoch 193/1000\n",
      "4/4 [==============================] - 38s 9s/step - loss: 9137.7148 - val_loss: 12398.3535\n",
      "Epoch 194/1000\n",
      "4/4 [==============================] - 44s 12s/step - loss: 9101.8506 - val_loss: 12355.9980\n",
      "Epoch 195/1000\n",
      "4/4 [==============================] - 51s 14s/step - loss: 9065.9414 - val_loss: 12313.7842\n",
      "Epoch 196/1000\n",
      "4/4 [==============================] - 45s 11s/step - loss: 9030.3750 - val_loss: 12271.5674\n",
      "Epoch 197/1000\n",
      "4/4 [==============================] - 33s 7s/step - loss: 8994.8145 - val_loss: 12229.3965\n",
      "Epoch 198/1000\n",
      "4/4 [==============================] - 28s 7s/step - loss: 8959.2461 - val_loss: 12187.3174\n",
      "Epoch 199/1000\n",
      "4/4 [==============================] - 32s 7s/step - loss: 8923.7549 - val_loss: 12145.3252\n",
      "Epoch 200/1000\n",
      "4/4 [==============================] - 31s 8s/step - loss: 8888.4121 - val_loss: 12103.3760\n",
      "Epoch 201/1000\n",
      "4/4 [==============================] - 29s 7s/step - loss: 8853.1875 - val_loss: 12061.4697\n",
      "Epoch 202/1000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 8817.9570 - val_loss: 12019.6494\n",
      "Epoch 203/1000\n",
      "4/4 [==============================] - 25s 7s/step - loss: 8782.8125 - val_loss: 11977.9199\n",
      "Epoch 204/1000\n",
      "4/4 [==============================] - 28s 7s/step - loss: 8747.7812 - val_loss: 11936.2607\n",
      "Epoch 205/1000\n",
      "4/4 [==============================] - 43s 10s/step - loss: 8712.8643 - val_loss: 11894.6709\n",
      "Epoch 206/1000\n",
      "4/4 [==============================] - 34s 8s/step - loss: 8677.9443 - val_loss: 11853.2139\n",
      "Epoch 207/1000\n",
      "4/4 [==============================] - 32s 8s/step - loss: 8643.1797 - val_loss: 11811.8271\n",
      "Epoch 208/1000\n",
      "4/4 [==============================] - 29s 7s/step - loss: 8608.4971 - val_loss: 11770.4990\n",
      "Epoch 209/1000\n",
      "4/4 [==============================] - 28s 7s/step - loss: 8573.8486 - val_loss: 11729.2559\n",
      "Epoch 210/1000\n",
      "4/4 [==============================] - 34s 9s/step - loss: 8539.3184 - val_loss: 11688.0938\n",
      "Epoch 211/1000\n",
      "4/4 [==============================] - 29s 7s/step - loss: 8505.1328 - val_loss: 11646.9180\n",
      "Epoch 212/1000\n",
      "4/4 [==============================] - 28s 7s/step - loss: 8470.7461 - val_loss: 11605.8896\n",
      "Epoch 213/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 8436.5176 - val_loss: 11564.9805\n",
      "Epoch 214/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 8402.3789 - val_loss: 11524.1963\n",
      "Epoch 215/1000\n",
      "4/4 [==============================] - 27s 7s/step - loss: 8368.3760 - val_loss: 11483.5273\n",
      "Epoch 216/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 8334.5361 - val_loss: 11442.9277\n",
      "Epoch 217/1000\n",
      "4/4 [==============================] - 28s 7s/step - loss: 8300.7686 - val_loss: 11402.4209\n",
      "Epoch 218/1000\n",
      "4/4 [==============================] - 31s 8s/step - loss: 8266.9668 - val_loss: 11362.0635\n",
      "Epoch 219/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 8233.5957 - val_loss: 11321.7246\n",
      "Epoch 220/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 8200.0977 - val_loss: 11281.5352\n",
      "Epoch 221/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 8166.7246 - val_loss: 11241.4697\n",
      "Epoch 222/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 8133.5288 - val_loss: 11201.5137\n",
      "Epoch 223/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 8100.3770 - val_loss: 11161.6875\n",
      "Epoch 224/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 8067.4272 - val_loss: 11121.9590\n",
      "Epoch 225/1000\n",
      "4/4 [==============================] - 30s 7s/step - loss: 8034.6606 - val_loss: 11082.3047\n",
      "Epoch 226/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 8001.8315 - val_loss: 11042.8125\n",
      "Epoch 227/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 7969.2163 - val_loss: 11003.4258\n",
      "Epoch 228/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 7936.7920 - val_loss: 10964.1143\n",
      "Epoch 229/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 20s 5s/step - loss: 7904.3276 - val_loss: 10924.9688\n",
      "Epoch 230/1000\n",
      "4/4 [==============================] - 35s 8s/step - loss: 7872.1694 - val_loss: 10885.9180\n",
      "Epoch 231/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 7839.9824 - val_loss: 10847.0312\n",
      "Epoch 232/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 7807.9463 - val_loss: 10808.2773\n",
      "Epoch 233/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 7776.0225 - val_loss: 10769.6562\n",
      "Epoch 234/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 7744.5420 - val_loss: 10731.0195\n",
      "Epoch 235/1000\n",
      "4/4 [==============================] - 27s 7s/step - loss: 7712.7935 - val_loss: 10692.6133\n",
      "Epoch 236/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 7681.2974 - val_loss: 10654.3682\n",
      "Epoch 237/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 7650.0410 - val_loss: 10616.2139\n",
      "Epoch 238/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 7618.7041 - val_loss: 10578.2500\n",
      "Epoch 239/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 7587.6812 - val_loss: 10540.3838\n",
      "Epoch 240/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 7556.8179 - val_loss: 10502.6230\n",
      "Epoch 241/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 7525.9951 - val_loss: 10465.0156\n",
      "Epoch 242/1000\n",
      "4/4 [==============================] - 24s 5s/step - loss: 7495.4438 - val_loss: 10427.5303\n",
      "Epoch 243/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 7464.8276 - val_loss: 10390.2666\n",
      "Epoch 244/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 7434.5928 - val_loss: 10353.0967\n",
      "Epoch 245/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 7404.2881 - val_loss: 10316.1318\n",
      "Epoch 246/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 7374.3765 - val_loss: 10279.2627\n",
      "Epoch 247/1000\n",
      "4/4 [==============================] - 28s 7s/step - loss: 7344.3975 - val_loss: 10242.5898\n",
      "Epoch 248/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 7314.7573 - val_loss: 10206.0303\n",
      "Epoch 249/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 7285.1460 - val_loss: 10169.6387\n",
      "Epoch 250/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 7255.7554 - val_loss: 10133.3809\n",
      "Epoch 251/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 7226.4980 - val_loss: 10097.2676\n",
      "Epoch 252/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 7197.2417 - val_loss: 10061.3770\n",
      "Epoch 253/1000\n",
      "4/4 [==============================] - 32s 8s/step - loss: 7168.3530 - val_loss: 10025.6016\n",
      "Epoch 254/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 7139.5522 - val_loss: 9989.9805\n",
      "Epoch 255/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 7110.7891 - val_loss: 9954.5674\n",
      "Epoch 256/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 7082.2661 - val_loss: 9919.2988\n",
      "Epoch 257/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 7053.9229 - val_loss: 9884.1465\n",
      "Epoch 258/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 7025.7290 - val_loss: 9849.1143\n",
      "Epoch 259/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 6997.7744 - val_loss: 9814.1943\n",
      "Epoch 260/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 6969.8174 - val_loss: 9779.4668\n",
      "Epoch 261/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 6942.0410 - val_loss: 9744.9502\n",
      "Epoch 262/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 6914.5200 - val_loss: 9710.5908\n",
      "Epoch 263/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 6887.0918 - val_loss: 9676.4268\n",
      "Epoch 264/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 6859.8540 - val_loss: 9642.4395\n",
      "Epoch 265/1000\n",
      "4/4 [==============================] - 25s 7s/step - loss: 6832.7148 - val_loss: 9608.6396\n",
      "Epoch 266/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 6805.8857 - val_loss: 9574.9492\n",
      "Epoch 267/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 6779.0410 - val_loss: 9541.4814\n",
      "Epoch 268/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 6752.5566 - val_loss: 9508.1484\n",
      "Epoch 269/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 6726.2129 - val_loss: 9474.9453\n",
      "Epoch 270/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 6699.9766 - val_loss: 9441.9014\n",
      "Epoch 271/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 6673.7642 - val_loss: 9409.1006\n",
      "Epoch 272/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 6647.8843 - val_loss: 9376.4590\n",
      "Epoch 273/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 6622.0376 - val_loss: 9344.0273\n",
      "Epoch 274/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 6596.6045 - val_loss: 9311.6992\n",
      "Epoch 275/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 6571.1909 - val_loss: 9279.5762\n",
      "Epoch 276/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 6545.8916 - val_loss: 9247.6611\n",
      "Epoch 277/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 6520.9614 - val_loss: 9215.8594\n",
      "Epoch 278/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 6495.9985 - val_loss: 9184.2783\n",
      "Epoch 279/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 6471.1543 - val_loss: 9152.9336\n",
      "Epoch 280/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 6446.7656 - val_loss: 9121.6865\n",
      "Epoch 281/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 6422.2290 - val_loss: 9090.7012\n",
      "Epoch 282/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 6398.1118 - val_loss: 9059.8174\n",
      "Epoch 283/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 6374.2261 - val_loss: 9029.0254\n",
      "Epoch 284/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 6350.0938 - val_loss: 8998.5342\n",
      "Epoch 285/1000\n",
      "4/4 [==============================] - 25s 7s/step - loss: 6326.3325 - val_loss: 8968.2275\n",
      "Epoch 286/1000\n",
      "4/4 [==============================] - 26s 5s/step - loss: 6302.9697 - val_loss: 8938.0195\n",
      "Epoch 287/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 6279.6206 - val_loss: 8908.0020\n",
      "Epoch 288/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 6256.4038 - val_loss: 8878.1973\n",
      "Epoch 289/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 6233.3428 - val_loss: 8848.5938\n",
      "Epoch 290/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 6210.5381 - val_loss: 8819.1650\n",
      "Epoch 291/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 6187.8945 - val_loss: 8789.9316\n",
      "Epoch 292/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 6165.4624 - val_loss: 8760.8750\n",
      "Epoch 293/1000\n",
      "4/4 [==============================] - 24s 7s/step - loss: 6143.1343 - val_loss: 8732.0303\n",
      "Epoch 294/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 6121.0151 - val_loss: 8703.3672\n",
      "Epoch 295/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 6099.1060 - val_loss: 8674.8760\n",
      "Epoch 296/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 6077.2539 - val_loss: 8646.6035\n",
      "Epoch 297/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 6055.6494 - val_loss: 8618.5186\n",
      "Epoch 298/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 6034.2231 - val_loss: 8590.6064\n",
      "Epoch 299/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 6013.0410 - val_loss: 8562.8311\n",
      "Epoch 300/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5991.9229 - val_loss: 8535.2695\n",
      "Epoch 301/1000\n",
      "4/4 [==============================] - 27s 7s/step - loss: 5971.0840 - val_loss: 8507.8730\n",
      "Epoch 302/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5950.2666 - val_loss: 8480.7109\n",
      "Epoch 303/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5929.7798 - val_loss: 8453.6914\n",
      "Epoch 304/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5909.3872 - val_loss: 8426.8613\n",
      "Epoch 305/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5889.0527 - val_loss: 8400.2734\n",
      "Epoch 306/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 21s 6s/step - loss: 5869.1787 - val_loss: 8373.7939\n",
      "Epoch 307/1000\n",
      "4/4 [==============================] - 30s 7s/step - loss: 5849.3276 - val_loss: 8347.5176\n",
      "Epoch 308/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5829.6997 - val_loss: 8321.4268\n",
      "Epoch 309/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5810.0640 - val_loss: 8295.6006\n",
      "Epoch 310/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5790.7358 - val_loss: 8269.9600\n",
      "Epoch 311/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5771.6309 - val_loss: 8244.4941\n",
      "Epoch 312/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5752.6396 - val_loss: 8219.2256\n",
      "Epoch 313/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 5733.8652 - val_loss: 8194.1143\n",
      "Epoch 314/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5715.3330 - val_loss: 8169.1484\n",
      "Epoch 315/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 5696.7598 - val_loss: 8144.4395\n",
      "Epoch 316/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5678.4736 - val_loss: 8119.9111\n",
      "Epoch 317/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5660.3389 - val_loss: 8095.5605\n",
      "Epoch 318/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5642.4868 - val_loss: 8071.3447\n",
      "Epoch 319/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5624.7144 - val_loss: 8047.3345\n",
      "Epoch 320/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 5607.0479 - val_loss: 8023.5645\n",
      "Epoch 321/1000\n",
      "4/4 [==============================] - 30s 8s/step - loss: 5589.6128 - val_loss: 7999.9971\n",
      "Epoch 322/1000\n",
      "4/4 [==============================] - 27s 7s/step - loss: 5572.3589 - val_loss: 7976.6172\n",
      "Epoch 323/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 5555.4092 - val_loss: 7953.3647\n",
      "Epoch 324/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5538.3374 - val_loss: 7930.3872\n",
      "Epoch 325/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 5521.7388 - val_loss: 7907.4966\n",
      "Epoch 326/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5505.2236 - val_loss: 7884.7725\n",
      "Epoch 327/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5488.5557 - val_loss: 7862.3730\n",
      "Epoch 328/1000\n",
      "4/4 [==============================] - 33s 8s/step - loss: 5472.4897 - val_loss: 7840.0547\n",
      "Epoch 329/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5456.4932 - val_loss: 7817.8955\n",
      "Epoch 330/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5440.3901 - val_loss: 7796.0132\n",
      "Epoch 331/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5424.6807 - val_loss: 7774.2583\n",
      "Epoch 332/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 5409.2456 - val_loss: 7752.6055\n",
      "Epoch 333/1000\n",
      "4/4 [==============================] - 33s 7s/step - loss: 5393.7412 - val_loss: 7731.1992\n",
      "Epoch 334/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 5378.5039 - val_loss: 7709.9780\n",
      "Epoch 335/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5363.3657 - val_loss: 7688.9600\n",
      "Epoch 336/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5348.5088 - val_loss: 7668.1006\n",
      "Epoch 337/1000\n",
      "4/4 [==============================] - 24s 7s/step - loss: 5333.6938 - val_loss: 7647.4536\n",
      "Epoch 338/1000\n",
      "4/4 [==============================] - 28s 8s/step - loss: 5319.0464 - val_loss: 7627.0122\n",
      "Epoch 339/1000\n",
      "4/4 [==============================] - 27s 6s/step - loss: 5304.7075 - val_loss: 7606.7007\n",
      "Epoch 340/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5290.3638 - val_loss: 7586.6016\n",
      "Epoch 341/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5276.3208 - val_loss: 7566.6265\n",
      "Epoch 342/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5262.2183 - val_loss: 7546.8921\n",
      "Epoch 343/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 5248.4951 - val_loss: 7527.2861\n",
      "Epoch 344/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 5234.8916 - val_loss: 7507.8472\n",
      "Epoch 345/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 5221.2896 - val_loss: 7488.6460\n",
      "Epoch 346/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5207.9678 - val_loss: 7469.6045\n",
      "Epoch 347/1000\n",
      "4/4 [==============================] - 28s 8s/step - loss: 5194.8105 - val_loss: 7450.7251\n",
      "Epoch 348/1000\n",
      "4/4 [==============================] - 70s 19s/step - loss: 5181.7681 - val_loss: 7432.0244\n",
      "Epoch 349/1000\n",
      "4/4 [==============================] - 57s 11s/step - loss: 5168.9048 - val_loss: 7413.4849\n",
      "Epoch 350/1000\n",
      "4/4 [==============================] - 29s 7s/step - loss: 5156.2803 - val_loss: 7395.0630\n",
      "Epoch 351/1000\n",
      "4/4 [==============================] - 30s 7s/step - loss: 5143.5947 - val_loss: 7376.8989\n",
      "Epoch 352/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5131.1265 - val_loss: 7358.9355\n",
      "Epoch 353/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5118.9766 - val_loss: 7341.0840\n",
      "Epoch 354/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 5106.7520 - val_loss: 7323.4590\n",
      "Epoch 355/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 5094.9058 - val_loss: 7305.9351\n",
      "Epoch 356/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5083.0791 - val_loss: 7288.5986\n",
      "Epoch 357/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 5071.3364 - val_loss: 7271.4766\n",
      "Epoch 358/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 5059.9126 - val_loss: 7254.4619\n",
      "Epoch 359/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 5048.4595 - val_loss: 7237.6792\n",
      "Epoch 360/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 5037.2510 - val_loss: 7221.0425\n",
      "Epoch 361/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 5026.1465 - val_loss: 7204.5830\n",
      "Epoch 362/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 5015.2241 - val_loss: 7188.2676\n",
      "Epoch 363/1000\n",
      "4/4 [==============================] - 26s 5s/step - loss: 5004.5039 - val_loss: 7172.0688\n",
      "Epoch 364/1000\n",
      "4/4 [==============================] - 25s 7s/step - loss: 4993.7539 - val_loss: 7156.0928\n",
      "Epoch 365/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4983.2402 - val_loss: 7140.2700\n",
      "Epoch 366/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4972.7632 - val_loss: 7124.6460\n",
      "Epoch 367/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 4962.5610 - val_loss: 7109.1479\n",
      "Epoch 368/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4952.4033 - val_loss: 7093.8262\n",
      "Epoch 369/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4942.5068 - val_loss: 7078.6167\n",
      "Epoch 370/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4932.6836 - val_loss: 7063.5591\n",
      "Epoch 371/1000\n",
      "4/4 [==============================] - 29s 6s/step - loss: 4922.8696 - val_loss: 7048.7227\n",
      "Epoch 372/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4913.3188 - val_loss: 7034.0244\n",
      "Epoch 373/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4903.9033 - val_loss: 7019.4629\n",
      "Epoch 374/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4894.6206 - val_loss: 7005.0439\n",
      "Epoch 375/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4885.3979 - val_loss: 6990.8140\n",
      "Epoch 376/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4876.3086 - val_loss: 6976.7642\n",
      "Epoch 377/1000\n",
      "4/4 [==============================] - 39s 9s/step - loss: 4867.4727 - val_loss: 6962.8130\n",
      "Epoch 378/1000\n",
      "4/4 [==============================] - 27s 6s/step - loss: 4858.5771 - val_loss: 6949.0869\n",
      "Epoch 379/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4849.9009 - val_loss: 6935.5039\n",
      "Epoch 380/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4841.3994 - val_loss: 6922.0264\n",
      "Epoch 381/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4833.0010 - val_loss: 6908.6616\n",
      "Epoch 382/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4824.6484 - val_loss: 6895.4629\n",
      "Epoch 383/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 20s 5s/step - loss: 4816.4590 - val_loss: 6882.4067\n",
      "Epoch 384/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 4808.3687 - val_loss: 6869.5059\n",
      "Epoch 385/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4800.3354 - val_loss: 6856.7817\n",
      "Epoch 386/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4792.6934 - val_loss: 6844.0962\n",
      "Epoch 387/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4784.8794 - val_loss: 6831.6299\n",
      "Epoch 388/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4777.3032 - val_loss: 6819.2837\n",
      "Epoch 389/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4769.7480 - val_loss: 6807.1313\n",
      "Epoch 390/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4762.5190 - val_loss: 6795.0386\n",
      "Epoch 391/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4755.0938 - val_loss: 6783.1885\n",
      "Epoch 392/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4747.9932 - val_loss: 6771.4243\n",
      "Epoch 393/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 4740.9409 - val_loss: 6759.8071\n",
      "Epoch 394/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 4733.9243 - val_loss: 6748.3755\n",
      "Epoch 395/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4727.2227 - val_loss: 6736.9731\n",
      "Epoch 396/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4720.5264 - val_loss: 6725.6846\n",
      "Epoch 397/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 4713.7876 - val_loss: 6714.6030\n",
      "Epoch 398/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 4707.3032 - val_loss: 6703.6177\n",
      "Epoch 399/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4700.9937 - val_loss: 6692.7109\n",
      "Epoch 400/1000\n",
      "4/4 [==============================] - 25s 7s/step - loss: 4694.6216 - val_loss: 6681.9873\n",
      "Epoch 401/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4688.3477 - val_loss: 6671.4321\n",
      "Epoch 402/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4682.3076 - val_loss: 6660.9653\n",
      "Epoch 403/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 4676.2759 - val_loss: 6650.6421\n",
      "Epoch 404/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4670.4067 - val_loss: 6640.4224\n",
      "Epoch 405/1000\n",
      "4/4 [==============================] - 25s 7s/step - loss: 4664.5088 - val_loss: 6630.3911\n",
      "Epoch 406/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 4658.8320 - val_loss: 6620.4434\n",
      "Epoch 407/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4653.1899 - val_loss: 6610.6128\n",
      "Epoch 408/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 4647.7378 - val_loss: 6600.8247\n",
      "Epoch 409/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4642.2012 - val_loss: 6591.2236\n",
      "Epoch 410/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4636.9136 - val_loss: 6581.6870\n",
      "Epoch 411/1000\n",
      "4/4 [==============================] - 28s 7s/step - loss: 4631.6689 - val_loss: 6572.2715\n",
      "Epoch 412/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4626.4585 - val_loss: 6563.0225\n",
      "Epoch 413/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4621.3770 - val_loss: 6553.9009\n",
      "Epoch 414/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 4616.3994 - val_loss: 6544.9004\n",
      "Epoch 415/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 4611.4946 - val_loss: 6536.0161\n",
      "Epoch 416/1000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 4606.8115 - val_loss: 6527.1650\n",
      "Epoch 417/1000\n",
      "4/4 [==============================] - 24s 5s/step - loss: 4601.9854 - val_loss: 6518.5254\n",
      "Epoch 418/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4597.3696 - val_loss: 6509.9868\n",
      "Epoch 419/1000\n",
      "4/4 [==============================] - 28s 7s/step - loss: 4592.8306 - val_loss: 6501.5493\n",
      "Epoch 420/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 4588.3159 - val_loss: 6493.2305\n",
      "Epoch 421/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4583.9409 - val_loss: 6484.9756\n",
      "Epoch 422/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4579.5596 - val_loss: 6476.8491\n",
      "Epoch 423/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4575.3530 - val_loss: 6468.7930\n",
      "Epoch 424/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4571.2183 - val_loss: 6460.8242\n",
      "Epoch 425/1000\n",
      "4/4 [==============================] - 31s 8s/step - loss: 4567.0645 - val_loss: 6453.0171\n",
      "Epoch 426/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4563.0659 - val_loss: 6445.3101\n",
      "Epoch 427/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4559.0811 - val_loss: 6437.7339\n",
      "Epoch 428/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4555.2046 - val_loss: 6430.2402\n",
      "Epoch 429/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4551.5015 - val_loss: 6422.7563\n",
      "Epoch 430/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4547.8008 - val_loss: 6415.3525\n",
      "Epoch 431/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 4544.0273 - val_loss: 6408.1406\n",
      "Epoch 432/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4540.4409 - val_loss: 6401.0264\n",
      "Epoch 433/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4536.9800 - val_loss: 6393.9727\n",
      "Epoch 434/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 4533.4902 - val_loss: 6387.0430\n",
      "Epoch 435/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4530.1211 - val_loss: 6380.1895\n",
      "Epoch 436/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4526.7700 - val_loss: 6373.4482\n",
      "Epoch 437/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4523.4995 - val_loss: 6366.8047\n",
      "Epoch 438/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4520.3394 - val_loss: 6360.1958\n",
      "Epoch 439/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4517.2007 - val_loss: 6353.6626\n",
      "Epoch 440/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4514.0659 - val_loss: 6347.2788\n",
      "Epoch 441/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4511.0879 - val_loss: 6340.9531\n",
      "Epoch 442/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4508.1611 - val_loss: 6334.6948\n",
      "Epoch 443/1000\n",
      "4/4 [==============================] - 32s 9s/step - loss: 4505.2329 - val_loss: 6328.5522\n",
      "Epoch 444/1000\n",
      "4/4 [==============================] - 29s 7s/step - loss: 4502.4517 - val_loss: 6322.4697\n",
      "Epoch 445/1000\n",
      "4/4 [==============================] - 27s 6s/step - loss: 4499.6831 - val_loss: 6316.4844\n",
      "Epoch 446/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4496.9468 - val_loss: 6310.6094\n",
      "Epoch 447/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4494.2979 - val_loss: 6304.8271\n",
      "Epoch 448/1000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 4491.6387 - val_loss: 6299.1797\n",
      "Epoch 449/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 4489.1040 - val_loss: 6293.5967\n",
      "Epoch 450/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4486.6328 - val_loss: 6288.0557\n",
      "Epoch 451/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 4484.2002 - val_loss: 6282.5732\n",
      "Epoch 452/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4481.8027 - val_loss: 6277.1582\n",
      "Epoch 453/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 4479.4443 - val_loss: 6271.8262\n",
      "Epoch 454/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4477.1162 - val_loss: 6266.5874\n",
      "Epoch 455/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4474.8486 - val_loss: 6261.4209\n",
      "Epoch 456/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 4472.6191 - val_loss: 6256.3188\n",
      "Epoch 457/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4470.6108 - val_loss: 6251.1562\n",
      "Epoch 458/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4468.3887 - val_loss: 6246.1836\n",
      "Epoch 459/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 4466.3154 - val_loss: 6241.3037\n",
      "Epoch 460/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 21s 5s/step - loss: 4464.2852 - val_loss: 6236.5034\n",
      "Epoch 461/1000\n",
      "4/4 [==============================] - 24s 5s/step - loss: 4462.3193 - val_loss: 6231.7622\n",
      "Epoch 462/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4460.4297 - val_loss: 6227.0601\n",
      "Epoch 463/1000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 4458.5410 - val_loss: 6222.4468\n",
      "Epoch 464/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4456.6807 - val_loss: 6217.9253\n",
      "Epoch 465/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4454.8711 - val_loss: 6213.4785\n",
      "Epoch 466/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 4453.1328 - val_loss: 6209.0708\n",
      "Epoch 467/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4451.3857 - val_loss: 6204.7632\n",
      "Epoch 468/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4449.6646 - val_loss: 6200.5386\n",
      "Epoch 469/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4448.0415 - val_loss: 6196.3330\n",
      "Epoch 470/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4446.4121 - val_loss: 6192.1919\n",
      "Epoch 471/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 4444.8433 - val_loss: 6188.0757\n",
      "Epoch 472/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4443.3306 - val_loss: 6183.9795\n",
      "Epoch 473/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4441.7910 - val_loss: 6179.9756\n",
      "Epoch 474/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4440.3066 - val_loss: 6176.0435\n",
      "Epoch 475/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4438.8496 - val_loss: 6172.1816\n",
      "Epoch 476/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4437.4839 - val_loss: 6168.3423\n",
      "Epoch 477/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4436.0410 - val_loss: 6164.6494\n",
      "Epoch 478/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4434.7192 - val_loss: 6160.9873\n",
      "Epoch 479/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4433.4648 - val_loss: 6157.3232\n",
      "Epoch 480/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4432.1455 - val_loss: 6153.7627\n",
      "Epoch 481/1000\n",
      "4/4 [==============================] - 28s 7s/step - loss: 4430.9058 - val_loss: 6150.2280\n",
      "Epoch 482/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4429.7075 - val_loss: 6146.7085\n",
      "Epoch 483/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4428.4834 - val_loss: 6143.2769\n",
      "Epoch 484/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4427.2769 - val_loss: 6139.9331\n",
      "Epoch 485/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4426.1787 - val_loss: 6136.5737\n",
      "Epoch 486/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4425.0254 - val_loss: 6133.2915\n",
      "Epoch 487/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 4423.9614 - val_loss: 6130.0239\n",
      "Epoch 488/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4422.9150 - val_loss: 6126.7842\n",
      "Epoch 489/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4421.8398 - val_loss: 6123.6396\n",
      "Epoch 490/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4420.8223 - val_loss: 6120.5562\n",
      "Epoch 491/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4419.8540 - val_loss: 6117.5015\n",
      "Epoch 492/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4418.8750 - val_loss: 6114.5156\n",
      "Epoch 493/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4417.9580 - val_loss: 6111.5566\n",
      "Epoch 494/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4417.0571 - val_loss: 6108.6475\n",
      "Epoch 495/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4416.1406 - val_loss: 6105.8203\n",
      "Epoch 496/1000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 4415.2749 - val_loss: 6103.0132\n",
      "Epoch 497/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4414.4160 - val_loss: 6100.2573\n",
      "Epoch 498/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4413.6367 - val_loss: 6097.4844\n",
      "Epoch 499/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4412.8130 - val_loss: 6094.7896\n",
      "Epoch 500/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4412.0142 - val_loss: 6092.1484\n",
      "Epoch 501/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4411.2837 - val_loss: 6089.5137\n",
      "Epoch 502/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 4410.4678 - val_loss: 6087.0161\n",
      "Epoch 503/1000\n",
      "4/4 [==============================] - 27s 7s/step - loss: 4409.8105 - val_loss: 6084.4541\n",
      "Epoch 504/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4409.0605 - val_loss: 6082.0010\n",
      "Epoch 505/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4408.4023 - val_loss: 6079.5332\n",
      "Epoch 506/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4407.7329 - val_loss: 6077.0962\n",
      "Epoch 507/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4407.0771 - val_loss: 6074.7041\n",
      "Epoch 508/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4406.4165 - val_loss: 6072.3838\n",
      "Epoch 509/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 4405.7832 - val_loss: 6070.1099\n",
      "Epoch 510/1000\n",
      "4/4 [==============================] - 26s 5s/step - loss: 4405.1958 - val_loss: 6067.8359\n",
      "Epoch 511/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4404.6128 - val_loss: 6065.5933\n",
      "Epoch 512/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4404.0420 - val_loss: 6063.3877\n",
      "Epoch 513/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4403.4453 - val_loss: 6061.2695\n",
      "Epoch 514/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4402.9229 - val_loss: 6059.1323\n",
      "Epoch 515/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4402.4038 - val_loss: 6057.0049\n",
      "Epoch 516/1000\n",
      "4/4 [==============================] - 24s 5s/step - loss: 4401.8882 - val_loss: 6054.9077\n",
      "Epoch 517/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4401.3447 - val_loss: 6052.8901\n",
      "Epoch 518/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4400.9062 - val_loss: 6050.8232\n",
      "Epoch 519/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4400.4170 - val_loss: 6048.8223\n",
      "Epoch 520/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4399.9521 - val_loss: 6046.8760\n",
      "Epoch 521/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4399.4844 - val_loss: 6044.9941\n",
      "Epoch 522/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4399.0620 - val_loss: 6043.1074\n",
      "Epoch 523/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4398.6274 - val_loss: 6041.2632\n",
      "Epoch 524/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4398.2261 - val_loss: 6039.4429\n",
      "Epoch 525/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4397.8027 - val_loss: 6037.6943\n",
      "Epoch 526/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 4397.4243 - val_loss: 6035.9458\n",
      "Epoch 527/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4397.0518 - val_loss: 6034.2139\n",
      "Epoch 528/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4396.6660 - val_loss: 6032.5317\n",
      "Epoch 529/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4396.3208 - val_loss: 6030.8369\n",
      "Epoch 530/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4395.9580 - val_loss: 6029.1875\n",
      "Epoch 531/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4395.6265 - val_loss: 6027.5342\n",
      "Epoch 532/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4395.3013 - val_loss: 6025.9023\n",
      "Epoch 533/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4394.9648 - val_loss: 6024.3252\n",
      "Epoch 534/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4394.6792 - val_loss: 6022.7290\n",
      "Epoch 535/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4394.3555 - val_loss: 6021.2119\n",
      "Epoch 536/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4394.0620 - val_loss: 6019.7290\n",
      "Epoch 537/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 22s 5s/step - loss: 4393.7900 - val_loss: 6018.2456\n",
      "Epoch 538/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4393.4966 - val_loss: 6016.8354\n",
      "Epoch 539/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4393.2383 - val_loss: 6015.4175\n",
      "Epoch 540/1000\n",
      "4/4 [==============================] - 27s 7s/step - loss: 4392.9727 - val_loss: 6014.0244\n",
      "Epoch 541/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4392.7407 - val_loss: 6012.6108\n",
      "Epoch 542/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4392.4873 - val_loss: 6011.2358\n",
      "Epoch 543/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4392.2490 - val_loss: 6009.8853\n",
      "Epoch 544/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4392.0225 - val_loss: 6008.5542\n",
      "Epoch 545/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 4391.7788 - val_loss: 6007.2993\n",
      "Epoch 546/1000\n",
      "4/4 [==============================] - 25s 7s/step - loss: 4391.5547 - val_loss: 6006.0649\n",
      "Epoch 547/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4391.3589 - val_loss: 6004.8105\n",
      "Epoch 548/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4391.1455 - val_loss: 6003.5957\n",
      "Epoch 549/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4390.9536 - val_loss: 6002.3770\n",
      "Epoch 550/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4390.7583 - val_loss: 6001.1826\n",
      "Epoch 551/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4390.5659 - val_loss: 6000.0225\n",
      "Epoch 552/1000\n",
      "4/4 [==============================] - 33s 8s/step - loss: 4390.3843 - val_loss: 5998.8696\n",
      "Epoch 553/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4390.2051 - val_loss: 5997.7368\n",
      "Epoch 554/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 4390.0659 - val_loss: 5996.5513\n",
      "Epoch 555/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4389.8682 - val_loss: 5995.4819\n",
      "Epoch 556/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 4389.7026 - val_loss: 5994.4326\n",
      "Epoch 557/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4389.5557 - val_loss: 5993.3735\n",
      "Epoch 558/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 4389.4111 - val_loss: 5992.3135\n",
      "Epoch 559/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4389.2593 - val_loss: 5991.2866\n",
      "Epoch 560/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4389.1211 - val_loss: 5990.2690\n",
      "Epoch 561/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4388.9858 - val_loss: 5989.2617\n",
      "Epoch 562/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4388.8477 - val_loss: 5988.2920\n",
      "Epoch 563/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4388.7222 - val_loss: 5987.3350\n",
      "Epoch 564/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4388.5942 - val_loss: 5986.4082\n",
      "Epoch 565/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4388.4814 - val_loss: 5985.4609\n",
      "Epoch 566/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4388.3726 - val_loss: 5984.5234\n",
      "Epoch 567/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4388.2451 - val_loss: 5983.6475\n",
      "Epoch 568/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4388.1343 - val_loss: 5982.7817\n",
      "Epoch 569/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 4388.0303 - val_loss: 5981.9268\n",
      "Epoch 570/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4387.9292 - val_loss: 5981.0884\n",
      "Epoch 571/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4387.8184 - val_loss: 5980.3037\n",
      "Epoch 572/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4387.7402 - val_loss: 5979.4517\n",
      "Epoch 573/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4387.6494 - val_loss: 5978.6147\n",
      "Epoch 574/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4387.5532 - val_loss: 5977.8271\n",
      "Epoch 575/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 4387.4785 - val_loss: 5977.0254\n",
      "Epoch 576/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4387.3730 - val_loss: 5976.3232\n",
      "Epoch 577/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4387.3013 - val_loss: 5975.5903\n",
      "Epoch 578/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4387.2202 - val_loss: 5974.8755\n",
      "Epoch 579/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4387.1519 - val_loss: 5974.1465\n",
      "Epoch 580/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4387.0732 - val_loss: 5973.4536\n",
      "Epoch 581/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4387.0068 - val_loss: 5972.7500\n",
      "Epoch 582/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4386.9458 - val_loss: 5972.0259\n",
      "Epoch 583/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4386.8755 - val_loss: 5971.3374\n",
      "Epoch 584/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4386.8037 - val_loss: 5970.6904\n",
      "Epoch 585/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4386.7437 - val_loss: 5970.0444\n",
      "Epoch 586/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 4386.6851 - val_loss: 5969.4146\n",
      "Epoch 587/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4386.6353 - val_loss: 5968.7603\n",
      "Epoch 588/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4386.5703 - val_loss: 5968.1499\n",
      "Epoch 589/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4386.5210 - val_loss: 5967.5273\n",
      "Epoch 590/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4386.4624 - val_loss: 5966.9536\n",
      "Epoch 591/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4386.4053 - val_loss: 5966.4033\n",
      "Epoch 592/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4386.3701 - val_loss: 5965.7988\n",
      "Epoch 593/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4386.3086 - val_loss: 5965.2622\n",
      "Epoch 594/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4386.2773 - val_loss: 5964.6641\n",
      "Epoch 595/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4386.2246 - val_loss: 5964.1230\n",
      "Epoch 596/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4386.1904 - val_loss: 5963.5542\n",
      "Epoch 597/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4386.1372 - val_loss: 5963.0713\n",
      "Epoch 598/1000\n",
      "4/4 [==============================] - 27s 5s/step - loss: 4386.1045 - val_loss: 5962.5557\n",
      "Epoch 599/1000\n",
      "4/4 [==============================] - 28s 7s/step - loss: 4386.0693 - val_loss: 5962.0391\n",
      "Epoch 600/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4386.0288 - val_loss: 5961.5503\n",
      "Epoch 601/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.9961 - val_loss: 5961.0576\n",
      "Epoch 602/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.9614 - val_loss: 5960.5825\n",
      "Epoch 603/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.9229 - val_loss: 5960.1499\n",
      "Epoch 604/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.8989 - val_loss: 5959.6719\n",
      "Epoch 605/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.8633 - val_loss: 5959.2236\n",
      "Epoch 606/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.8374 - val_loss: 5958.7583\n",
      "Epoch 607/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4385.8042 - val_loss: 5958.3369\n",
      "Epoch 608/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.7778 - val_loss: 5957.9150\n",
      "Epoch 609/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.7490 - val_loss: 5957.5010\n",
      "Epoch 610/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 4385.7251 - val_loss: 5957.0757\n",
      "Epoch 611/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.7026 - val_loss: 5956.6470\n",
      "Epoch 612/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.6729 - val_loss: 5956.2627\n",
      "Epoch 613/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4385.6519 - val_loss: 5955.8540\n",
      "Epoch 614/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 22s 6s/step - loss: 4385.6333 - val_loss: 5955.4238\n",
      "Epoch 615/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.6094 - val_loss: 5955.0186\n",
      "Epoch 616/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.5825 - val_loss: 5954.6626\n",
      "Epoch 617/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.5649 - val_loss: 5954.2764\n",
      "Epoch 618/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.5435 - val_loss: 5953.9072\n",
      "Epoch 619/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.5298 - val_loss: 5953.5200\n",
      "Epoch 620/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.5020 - val_loss: 5953.2163\n",
      "Epoch 621/1000\n",
      "4/4 [==============================] - 28s 8s/step - loss: 4385.4873 - val_loss: 5952.8765\n",
      "Epoch 622/1000\n",
      "4/4 [==============================] - 28s 7s/step - loss: 4385.4771 - val_loss: 5952.4873\n",
      "Epoch 623/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.4590 - val_loss: 5952.1279\n",
      "Epoch 624/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.4395 - val_loss: 5951.8066\n",
      "Epoch 625/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.4224 - val_loss: 5951.5176\n",
      "Epoch 626/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.4136 - val_loss: 5951.1807\n",
      "Epoch 627/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 4385.3931 - val_loss: 5950.9111\n",
      "Epoch 628/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.3828 - val_loss: 5950.6069\n",
      "Epoch 629/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.3711 - val_loss: 5950.2861\n",
      "Epoch 630/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.3574 - val_loss: 5949.9658\n",
      "Epoch 631/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.3467 - val_loss: 5949.6401\n",
      "Epoch 632/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.3354 - val_loss: 5949.3428\n",
      "Epoch 633/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.3179 - val_loss: 5949.1313\n",
      "Epoch 634/1000\n",
      "4/4 [==============================] - 28s 6s/step - loss: 4385.3125 - val_loss: 5948.8540\n",
      "Epoch 635/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.2983 - val_loss: 5948.6235\n",
      "Epoch 636/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.2915 - val_loss: 5948.3643\n",
      "Epoch 637/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.2837 - val_loss: 5948.0981\n",
      "Epoch 638/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.2720 - val_loss: 5947.8701\n",
      "Epoch 639/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4385.2646 - val_loss: 5947.6309\n",
      "Epoch 640/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.2568 - val_loss: 5947.4038\n",
      "Epoch 641/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.2505 - val_loss: 5947.1626\n",
      "Epoch 642/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.2451 - val_loss: 5946.9214\n",
      "Epoch 643/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.2344 - val_loss: 5946.7246\n",
      "Epoch 644/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 4385.2266 - val_loss: 5946.5474\n",
      "Epoch 645/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4385.2236 - val_loss: 5946.3271\n",
      "Epoch 646/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4385.2168 - val_loss: 5946.1235\n",
      "Epoch 647/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.2090 - val_loss: 5945.9229\n",
      "Epoch 648/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.2007 - val_loss: 5945.7583\n",
      "Epoch 649/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.1987 - val_loss: 5945.5059\n",
      "Epoch 650/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 4385.1885 - val_loss: 5945.2852\n",
      "Epoch 651/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 4385.1895 - val_loss: 5945.0107\n",
      "Epoch 652/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.1763 - val_loss: 5944.8086\n",
      "Epoch 653/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.1709 - val_loss: 5944.6104\n",
      "Epoch 654/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.1675 - val_loss: 5944.3726\n",
      "Epoch 655/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 4385.1592 - val_loss: 5944.2163\n",
      "Epoch 656/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.1597 - val_loss: 5943.9854\n",
      "Epoch 657/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4385.1523 - val_loss: 5943.8027\n",
      "Epoch 658/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.1475 - val_loss: 5943.6421\n",
      "Epoch 659/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.1426 - val_loss: 5943.4932\n",
      "Epoch 660/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.1396 - val_loss: 5943.3271\n",
      "Epoch 661/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4385.1362 - val_loss: 5943.1489\n",
      "Epoch 662/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.1318 - val_loss: 5942.9966\n",
      "Epoch 663/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.1270 - val_loss: 5942.8584\n",
      "Epoch 664/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.1265 - val_loss: 5942.6523\n",
      "Epoch 665/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.1211 - val_loss: 5942.4907\n",
      "Epoch 666/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.1245 - val_loss: 5942.2676\n",
      "Epoch 667/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 4385.1157 - val_loss: 5942.1362\n",
      "Epoch 668/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4385.1138 - val_loss: 5942.0093\n",
      "Epoch 669/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.1128 - val_loss: 5941.8853\n",
      "Epoch 670/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.1074 - val_loss: 5941.8276\n",
      "Epoch 671/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.1074 - val_loss: 5941.6895\n",
      "Epoch 672/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.1040 - val_loss: 5941.5850\n",
      "Epoch 673/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.1021 - val_loss: 5941.4722\n",
      "Epoch 674/1000\n",
      "4/4 [==============================] - 29s 7s/step - loss: 4385.1025 - val_loss: 5941.3145\n",
      "Epoch 675/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0996 - val_loss: 5941.1738\n",
      "Epoch 676/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.0967 - val_loss: 5941.0830\n",
      "Epoch 677/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0952 - val_loss: 5940.9829\n",
      "Epoch 678/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0947 - val_loss: 5940.8730\n",
      "Epoch 679/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0923 - val_loss: 5940.7827\n",
      "Epoch 680/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4385.0928 - val_loss: 5940.6494\n",
      "Epoch 681/1000\n",
      "4/4 [==============================] - 24s 5s/step - loss: 4385.0889 - val_loss: 5940.5640\n",
      "Epoch 682/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0874 - val_loss: 5940.5010\n",
      "Epoch 683/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0864 - val_loss: 5940.4346\n",
      "Epoch 684/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0869 - val_loss: 5940.3135\n",
      "Epoch 685/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.0830 - val_loss: 5940.2314\n",
      "Epoch 686/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0825 - val_loss: 5940.1245\n",
      "Epoch 687/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 4385.0820 - val_loss: 5939.9971\n",
      "Epoch 688/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0801 - val_loss: 5939.8989\n",
      "Epoch 689/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0791 - val_loss: 5939.7954\n",
      "Epoch 690/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0781 - val_loss: 5939.6963\n",
      "Epoch 691/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0767 - val_loss: 5939.6104\n",
      "Epoch 692/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0752 - val_loss: 5939.5459\n",
      "Epoch 693/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4385.0752 - val_loss: 5939.4458\n",
      "Epoch 694/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0737 - val_loss: 5939.3701\n",
      "Epoch 695/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0732 - val_loss: 5939.3330\n",
      "Epoch 696/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0732 - val_loss: 5939.2500\n",
      "Epoch 697/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0728 - val_loss: 5939.1855\n",
      "Epoch 698/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0718 - val_loss: 5939.0962\n",
      "Epoch 699/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0708 - val_loss: 5939.0425\n",
      "Epoch 700/1000\n",
      "4/4 [==============================] - 24s 5s/step - loss: 4385.0713 - val_loss: 5938.9341\n",
      "Epoch 701/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4385.0688 - val_loss: 5938.8921\n",
      "Epoch 702/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0684 - val_loss: 5938.8535\n",
      "Epoch 703/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0674 - val_loss: 5938.8188\n",
      "Epoch 704/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.0723 - val_loss: 5938.6626\n",
      "Epoch 705/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0664 - val_loss: 5938.5938\n",
      "Epoch 706/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0664 - val_loss: 5938.5469\n",
      "Epoch 707/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0659 - val_loss: 5938.5249\n",
      "Epoch 708/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4385.0654 - val_loss: 5938.4634\n",
      "Epoch 709/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 4385.0649 - val_loss: 5938.4097\n",
      "Epoch 710/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0645 - val_loss: 5938.3379\n",
      "Epoch 711/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 4385.0640 - val_loss: 5938.3013\n",
      "Epoch 712/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4385.0649 - val_loss: 5938.1934\n",
      "Epoch 713/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0645 - val_loss: 5938.1777\n",
      "Epoch 714/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0649 - val_loss: 5938.0854\n",
      "Epoch 715/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0630 - val_loss: 5938.0649\n",
      "Epoch 716/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.0645 - val_loss: 5938.0781\n",
      "Epoch 717/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 4385.0630 - val_loss: 5938.0015\n",
      "Epoch 718/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0630 - val_loss: 5937.9014\n",
      "Epoch 719/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 4385.0610 - val_loss: 5937.8521\n",
      "Epoch 720/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 4385.0605 - val_loss: 5937.8057\n",
      "Epoch 721/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.0635 - val_loss: 5937.7041\n",
      "Epoch 722/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0605 - val_loss: 5937.6533\n",
      "Epoch 723/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 4385.0601 - val_loss: 5937.6255\n",
      "Epoch 724/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0605 - val_loss: 5937.6372\n",
      "Epoch 725/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.0601 - val_loss: 5937.5776\n",
      "Epoch 726/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.0610 - val_loss: 5937.4985\n",
      "Epoch 727/1000\n",
      "4/4 [==============================] - 29s 7s/step - loss: 4385.0601 - val_loss: 5937.5239\n",
      "Epoch 728/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0596 - val_loss: 5937.5132\n",
      "Epoch 729/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0591 - val_loss: 5937.4629\n",
      "Epoch 730/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0586 - val_loss: 5937.4419\n",
      "Epoch 731/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0596 - val_loss: 5937.3848\n",
      "Epoch 732/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0591 - val_loss: 5937.3872\n",
      "Epoch 733/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0586 - val_loss: 5937.3564\n",
      "Epoch 734/1000\n",
      "4/4 [==============================] - 27s 6s/step - loss: 4385.0591 - val_loss: 5937.3608\n",
      "Epoch 735/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0605 - val_loss: 5937.2432\n",
      "Epoch 736/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0581 - val_loss: 5937.2231\n",
      "Epoch 737/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0576 - val_loss: 5937.1914\n",
      "Epoch 738/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.0591 - val_loss: 5937.1328\n",
      "Epoch 739/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0601 - val_loss: 5937.0537\n",
      "Epoch 740/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 4385.0596 - val_loss: 5937.0947\n",
      "Epoch 741/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0581 - val_loss: 5937.0410\n",
      "Epoch 742/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0581 - val_loss: 5937.0293\n",
      "Epoch 743/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0581 - val_loss: 5937.0073\n",
      "Epoch 744/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.0591 - val_loss: 5937.0444\n",
      "Epoch 745/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0581 - val_loss: 5937.0767\n",
      "Epoch 746/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0576 - val_loss: 5937.0439\n",
      "Epoch 747/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 4385.0591 - val_loss: 5936.9888\n",
      "Epoch 748/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0581 - val_loss: 5936.9800\n",
      "Epoch 749/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0581 - val_loss: 5937.0215\n",
      "Epoch 750/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0596 - val_loss: 5937.0435\n",
      "Epoch 751/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.0576 - val_loss: 5937.0063\n",
      "Epoch 752/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4385.0581 - val_loss: 5936.9258\n",
      "Epoch 753/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4385.0596 - val_loss: 5936.8428\n",
      "Epoch 754/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0571 - val_loss: 5936.8398\n",
      "Epoch 755/1000\n",
      "4/4 [==============================] - 25s 7s/step - loss: 4385.0581 - val_loss: 5936.8638\n",
      "Epoch 756/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0586 - val_loss: 5936.7720\n",
      "Epoch 757/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 4385.0576 - val_loss: 5936.7837\n",
      "Epoch 758/1000\n",
      "4/4 [==============================] - 25s 7s/step - loss: 4385.0581 - val_loss: 5936.7183\n",
      "Epoch 759/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0571 - val_loss: 5936.6865\n",
      "Epoch 760/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0576 - val_loss: 5936.6357\n",
      "Epoch 761/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0586 - val_loss: 5936.5986\n",
      "Epoch 762/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0566 - val_loss: 5936.5742\n",
      "Epoch 763/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0562 - val_loss: 5936.5728\n",
      "Epoch 764/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0566 - val_loss: 5936.5718\n",
      "Epoch 765/1000\n",
      "4/4 [==============================] - 24s 5s/step - loss: 4385.0581 - val_loss: 5936.6089\n",
      "Epoch 766/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0566 - val_loss: 5936.5718\n",
      "Epoch 767/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0566 - val_loss: 5936.5488\n",
      "Epoch 768/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0562 - val_loss: 5936.5083\n",
      "Epoch 769/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0562 - val_loss: 5936.4746\n",
      "Epoch 770/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.0571 - val_loss: 5936.4185\n",
      "Epoch 771/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0581 - val_loss: 5936.3813\n",
      "Epoch 772/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0562 - val_loss: 5936.3940\n",
      "Epoch 773/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.0566 - val_loss: 5936.4019\n",
      "Epoch 774/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 4385.0571 - val_loss: 5936.4399\n",
      "Epoch 775/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0562 - val_loss: 5936.4404\n",
      "Epoch 776/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.0562 - val_loss: 5936.4263\n",
      "Epoch 777/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 4385.0571 - val_loss: 5936.3691\n",
      "Epoch 778/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0557 - val_loss: 5936.3755\n",
      "Epoch 779/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0586 - val_loss: 5936.4097\n",
      "Epoch 780/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.0562 - val_loss: 5936.3887\n",
      "Epoch 781/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 4385.0586 - val_loss: 5936.4321\n",
      "Epoch 782/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0562 - val_loss: 5936.3657\n",
      "Epoch 783/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0566 - val_loss: 5936.3037\n",
      "Epoch 784/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0566 - val_loss: 5936.2793\n",
      "Epoch 785/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0562 - val_loss: 5936.2866\n",
      "Epoch 786/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0566 - val_loss: 5936.2500\n",
      "Epoch 787/1000\n",
      "4/4 [==============================] - 25s 6s/step - loss: 4385.0566 - val_loss: 5936.2339\n",
      "Epoch 788/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0576 - val_loss: 5936.2808\n",
      "Epoch 789/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0586 - val_loss: 5936.3389\n",
      "Epoch 790/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0571 - val_loss: 5936.3145\n",
      "Epoch 791/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0566 - val_loss: 5936.2769\n",
      "Epoch 792/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 4385.0562 - val_loss: 5936.2646\n",
      "Epoch 793/1000\n",
      "4/4 [==============================] - 30s 7s/step - loss: 4385.0566 - val_loss: 5936.2734\n",
      "Epoch 794/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 4385.0566 - val_loss: 5936.2705\n",
      "Epoch 795/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 4385.0562 - val_loss: 5936.2622\n",
      "Epoch 796/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4385.0566 - val_loss: 5936.3037\n",
      "Epoch 797/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0562 - val_loss: 5936.3262\n",
      "Epoch 798/1000\n",
      "4/4 [==============================] - 27s 7s/step - loss: 4385.0566 - val_loss: 5936.3237\n",
      "Epoch 799/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0591 - val_loss: 5936.4209\n",
      "Epoch 800/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0562 - val_loss: 5936.3984\n",
      "Epoch 801/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0571 - val_loss: 5936.4067\n",
      "Epoch 802/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0566 - val_loss: 5936.3325\n",
      "Epoch 803/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0571 - val_loss: 5936.3438\n",
      "Epoch 804/1000\n",
      "4/4 [==============================] - 25s 7s/step - loss: 4385.0571 - val_loss: 5936.3271\n",
      "Epoch 805/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4385.0586 - val_loss: 5936.2241\n",
      "Epoch 806/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.0562 - val_loss: 5936.2417\n",
      "Epoch 807/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0586 - val_loss: 5936.1704\n",
      "Epoch 808/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 4385.0562 - val_loss: 5936.1841\n",
      "Epoch 809/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 4385.0562 - val_loss: 5936.1890\n",
      "Epoch 810/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0562 - val_loss: 5936.1851\n",
      "Epoch 811/1000\n",
      "4/4 [==============================] - 27s 8s/step - loss: 4385.0562 - val_loss: 5936.1782\n",
      "Epoch 812/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0571 - val_loss: 5936.1953\n",
      "Epoch 813/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 4385.0571 - val_loss: 5936.2466\n",
      "Epoch 814/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4385.0562 - val_loss: 5936.2549\n",
      "Epoch 815/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0566 - val_loss: 5936.2437\n",
      "Epoch 816/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.0562 - val_loss: 5936.2378\n",
      "Epoch 817/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0566 - val_loss: 5936.2388\n",
      "Epoch 818/1000\n",
      "4/4 [==============================] - 24s 5s/step - loss: 4385.0571 - val_loss: 5936.2920\n",
      "Epoch 819/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.0566 - val_loss: 5936.2939\n",
      "Epoch 820/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.0562 - val_loss: 5936.2793\n",
      "Epoch 821/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0562 - val_loss: 5936.2769\n",
      "Epoch 822/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.0566 - val_loss: 5936.2847\n",
      "Epoch 823/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0562 - val_loss: 5936.2568\n",
      "Epoch 824/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 4385.0557 - val_loss: 5936.2329\n",
      "Epoch 825/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.0566 - val_loss: 5936.1826\n",
      "Epoch 826/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0571 - val_loss: 5936.1641\n",
      "Epoch 827/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.0552 - val_loss: 5936.0962\n",
      "Epoch 828/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0557 - val_loss: 5936.0244\n",
      "Epoch 829/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0581 - val_loss: 5935.9272\n",
      "Epoch 830/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0562 - val_loss: 5935.9150\n",
      "Epoch 831/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0562 - val_loss: 5935.9219\n",
      "Epoch 832/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0581 - val_loss: 5935.9463\n",
      "Epoch 833/1000\n",
      "4/4 [==============================] - 25s 5s/step - loss: 4385.0562 - val_loss: 5935.9321\n",
      "Epoch 834/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0562 - val_loss: 5935.9253\n",
      "Epoch 835/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 4385.0562 - val_loss: 5935.9194\n",
      "Epoch 836/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4385.0562 - val_loss: 5935.9683\n",
      "Epoch 837/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0581 - val_loss: 5935.9233\n",
      "Epoch 838/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4385.0562 - val_loss: 5935.9492\n",
      "Epoch 839/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.0562 - val_loss: 5935.9487\n",
      "Epoch 840/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0571 - val_loss: 5935.9419\n",
      "Epoch 841/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0562 - val_loss: 5935.9844\n",
      "Epoch 842/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0562 - val_loss: 5936.0259\n",
      "Epoch 843/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0562 - val_loss: 5936.0571\n",
      "Epoch 844/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0571 - val_loss: 5936.0781\n",
      "Epoch 845/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 25s 7s/step - loss: 4385.0566 - val_loss: 5936.0840\n",
      "Epoch 846/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 4385.0571 - val_loss: 5936.0815\n",
      "Epoch 847/1000\n",
      "4/4 [==============================] - 19s 4s/step - loss: 4385.0566 - val_loss: 5936.0942\n",
      "Epoch 848/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0586 - val_loss: 5936.1743\n",
      "Epoch 849/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0581 - val_loss: 5936.1099\n",
      "Epoch 850/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.0562 - val_loss: 5936.1489\n",
      "Epoch 851/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0571 - val_loss: 5936.1523\n",
      "Epoch 852/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0557 - val_loss: 5936.1919\n",
      "Epoch 853/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0566 - val_loss: 5936.2197\n",
      "Epoch 854/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0576 - val_loss: 5936.1816\n",
      "Epoch 855/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0562 - val_loss: 5936.2354\n",
      "Epoch 856/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 4385.0571 - val_loss: 5936.2241\n",
      "Epoch 857/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 4385.0576 - val_loss: 5936.3213\n",
      "Epoch 858/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0566 - val_loss: 5936.3193\n",
      "Epoch 859/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0591 - val_loss: 5936.4160\n",
      "Epoch 860/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 4385.0562 - val_loss: 5936.4062\n",
      "Epoch 861/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 4385.0571 - val_loss: 5936.4380\n",
      "Epoch 862/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0571 - val_loss: 5936.4009\n",
      "Epoch 863/1000\n",
      "4/4 [==============================] - 31s 7s/step - loss: 4385.0562 - val_loss: 5936.3564\n",
      "Epoch 864/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0562 - val_loss: 5936.3325\n",
      "Epoch 865/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0576 - val_loss: 5936.2358\n",
      "Epoch 866/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0566 - val_loss: 5936.2397\n",
      "Epoch 867/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.0566 - val_loss: 5936.2500\n",
      "Epoch 868/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4385.0571 - val_loss: 5936.2363\n",
      "Epoch 869/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0562 - val_loss: 5936.2144\n",
      "Epoch 870/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0562 - val_loss: 5936.2051\n",
      "Epoch 871/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.0566 - val_loss: 5936.1719\n",
      "Epoch 872/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.0571 - val_loss: 5936.2163\n",
      "Epoch 873/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.0581 - val_loss: 5936.2271\n",
      "Epoch 874/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 4385.0562 - val_loss: 5936.1543\n",
      "Epoch 875/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0562 - val_loss: 5936.1128\n",
      "Epoch 876/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0562 - val_loss: 5936.0767\n",
      "Epoch 877/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0562 - val_loss: 5936.0371\n",
      "Epoch 878/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.0562 - val_loss: 5935.9912\n",
      "Epoch 879/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0566 - val_loss: 5936.0000\n",
      "Epoch 880/1000\n",
      "4/4 [==============================] - 25s 7s/step - loss: 4385.0562 - val_loss: 5935.9873\n",
      "Epoch 881/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0566 - val_loss: 5935.9844\n",
      "Epoch 882/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0552 - val_loss: 5935.9380\n",
      "Epoch 883/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0586 - val_loss: 5935.8369\n",
      "Epoch 884/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0557 - val_loss: 5935.8301\n",
      "Epoch 885/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0571 - val_loss: 5935.7759\n",
      "Epoch 886/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0566 - val_loss: 5935.8296\n",
      "Epoch 887/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4385.0571 - val_loss: 5935.8394\n",
      "Epoch 888/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0557 - val_loss: 5935.8691\n",
      "Epoch 889/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0571 - val_loss: 5935.8745\n",
      "Epoch 890/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0566 - val_loss: 5935.8369\n",
      "Epoch 891/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 4385.0562 - val_loss: 5935.8262\n",
      "Epoch 892/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0581 - val_loss: 5935.8838\n",
      "Epoch 893/1000\n",
      "4/4 [==============================] - 24s 5s/step - loss: 4385.0562 - val_loss: 5935.8862\n",
      "Epoch 894/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.0581 - val_loss: 5935.8237\n",
      "Epoch 895/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0562 - val_loss: 5935.8438\n",
      "Epoch 896/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4385.0566 - val_loss: 5935.9146\n",
      "Epoch 897/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0571 - val_loss: 5935.9429\n",
      "Epoch 898/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0566 - val_loss: 5935.9219\n",
      "Epoch 899/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4385.0566 - val_loss: 5935.8994\n",
      "Epoch 900/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.0586 - val_loss: 5935.9658\n",
      "Epoch 901/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 4385.0571 - val_loss: 5935.9331\n",
      "Epoch 902/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0562 - val_loss: 5935.9326\n",
      "Epoch 903/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0562 - val_loss: 5935.9722\n",
      "Epoch 904/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0571 - val_loss: 5936.0449\n",
      "Epoch 905/1000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 4385.0562 - val_loss: 5936.0425\n",
      "Epoch 906/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0591 - val_loss: 5935.9707\n",
      "Epoch 907/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0562 - val_loss: 5936.0059\n",
      "Epoch 908/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0571 - val_loss: 5936.0610\n",
      "Epoch 909/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.0596 - val_loss: 5936.1484\n",
      "Epoch 910/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4385.0562 - val_loss: 5936.1118\n",
      "Epoch 911/1000\n",
      "4/4 [==============================] - 31s 8s/step - loss: 4385.0576 - val_loss: 5936.0576\n",
      "Epoch 912/1000\n",
      "4/4 [==============================] - 27s 6s/step - loss: 4385.0571 - val_loss: 5936.1187\n",
      "Epoch 913/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0566 - val_loss: 5936.0693\n",
      "Epoch 914/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 4385.0601 - val_loss: 5936.0068\n",
      "Epoch 915/1000\n",
      "4/4 [==============================] - 23s 6s/step - loss: 4385.0562 - val_loss: 5936.0649\n",
      "Epoch 916/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4385.0562 - val_loss: 5936.0947\n",
      "Epoch 917/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.0571 - val_loss: 5936.0688\n",
      "Epoch 918/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0571 - val_loss: 5936.1323\n",
      "Epoch 919/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0581 - val_loss: 5936.0952\n",
      "Epoch 920/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0562 - val_loss: 5936.1289\n",
      "Epoch 921/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.0571 - val_loss: 5936.1187\n",
      "Epoch 922/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0562 - val_loss: 5936.1499\n",
      "Epoch 923/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4385.0566 - val_loss: 5936.1445\n",
      "Epoch 924/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0562 - val_loss: 5936.1465\n",
      "Epoch 925/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0566 - val_loss: 5936.1895\n",
      "Epoch 926/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.0566 - val_loss: 5936.1826\n",
      "Epoch 927/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 4385.0562 - val_loss: 5936.2305\n",
      "Epoch 928/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4385.0576 - val_loss: 5936.2959\n",
      "Epoch 929/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 4385.0576 - val_loss: 5936.2690\n",
      "Epoch 930/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0566 - val_loss: 5936.3071\n",
      "Epoch 931/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0566 - val_loss: 5936.3130\n",
      "Epoch 932/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0571 - val_loss: 5936.2998\n",
      "Epoch 933/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.0566 - val_loss: 5936.3818\n",
      "Epoch 934/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.0571 - val_loss: 5936.3955\n",
      "Epoch 935/1000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 4385.0586 - val_loss: 5936.3340\n",
      "Epoch 936/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0581 - val_loss: 5936.4180\n",
      "Epoch 937/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0571 - val_loss: 5936.4258\n",
      "Epoch 938/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0562 - val_loss: 5936.4189\n",
      "Epoch 939/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0576 - val_loss: 5936.4443\n",
      "Epoch 940/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0566 - val_loss: 5936.3794\n",
      "Epoch 941/1000\n",
      "4/4 [==============================] - 24s 7s/step - loss: 4385.0571 - val_loss: 5936.3271\n",
      "Epoch 942/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.0566 - val_loss: 5936.2949\n",
      "Epoch 943/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0566 - val_loss: 5936.3315\n",
      "Epoch 944/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.0571 - val_loss: 5936.3755\n",
      "Epoch 945/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0571 - val_loss: 5936.3691\n",
      "Epoch 946/1000\n",
      "4/4 [==============================] - 21s 6s/step - loss: 4385.0581 - val_loss: 5936.3115\n",
      "Epoch 947/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0571 - val_loss: 5936.2808\n",
      "Epoch 948/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0576 - val_loss: 5936.3613\n",
      "Epoch 949/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0576 - val_loss: 5936.3130\n",
      "Epoch 950/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0571 - val_loss: 5936.3379\n",
      "Epoch 951/1000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 4385.0576 - val_loss: 5936.3701\n",
      "Epoch 952/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0566 - val_loss: 5936.3115\n",
      "Epoch 953/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0566 - val_loss: 5936.3047\n",
      "Epoch 954/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0586 - val_loss: 5936.3789\n",
      "Epoch 955/1000\n",
      "4/4 [==============================] - 30s 8s/step - loss: 4385.0571 - val_loss: 5936.3262\n",
      "Epoch 956/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4385.0571 - val_loss: 5936.2959\n",
      "Epoch 957/1000\n",
      "4/4 [==============================] - 26s 7s/step - loss: 4385.0566 - val_loss: 5936.2227\n",
      "Epoch 958/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0571 - val_loss: 5936.1597\n",
      "Epoch 959/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0566 - val_loss: 5936.1743\n",
      "Epoch 960/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.0591 - val_loss: 5936.0781\n",
      "Epoch 961/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0596 - val_loss: 5935.9893\n",
      "Epoch 962/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.0566 - val_loss: 5936.0547\n",
      "Epoch 963/1000\n",
      "4/4 [==============================] - 25s 7s/step - loss: 4385.0562 - val_loss: 5936.0635\n",
      "Epoch 964/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0566 - val_loss: 5936.0820\n",
      "Epoch 965/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0576 - val_loss: 5936.0815\n",
      "Epoch 966/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0562 - val_loss: 5936.1362\n",
      "Epoch 967/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0571 - val_loss: 5936.1826\n",
      "Epoch 968/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0562 - val_loss: 5936.2998\n",
      "Epoch 969/1000\n",
      "4/4 [==============================] - 27s 6s/step - loss: 4385.0562 - val_loss: 5936.3521\n",
      "Epoch 970/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0571 - val_loss: 5936.4331\n",
      "Epoch 971/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0581 - val_loss: 5936.5156\n",
      "Epoch 972/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.0566 - val_loss: 5936.5278\n",
      "Epoch 973/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0571 - val_loss: 5936.5137\n",
      "Epoch 974/1000\n",
      "4/4 [==============================] - 22s 5s/step - loss: 4385.0605 - val_loss: 5936.3716\n",
      "Epoch 975/1000\n",
      "4/4 [==============================] - 28s 6s/step - loss: 4385.0562 - val_loss: 5936.3760\n",
      "Epoch 976/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0566 - val_loss: 5936.4106\n",
      "Epoch 977/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0562 - val_loss: 5936.3853\n",
      "Epoch 978/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0562 - val_loss: 5936.3433\n",
      "Epoch 979/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0562 - val_loss: 5936.2808\n",
      "Epoch 980/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0571 - val_loss: 5936.2290\n",
      "Epoch 981/1000\n",
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0601 - val_loss: 5936.3130\n",
      "Epoch 982/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0586 - val_loss: 5936.2134\n",
      "Epoch 983/1000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 4385.0566 - val_loss: 5936.2222\n",
      "Epoch 984/1000\n",
      "4/4 [==============================] - 21s 5s/step - loss: 4385.0566 - val_loss: 5936.2466\n",
      "Epoch 985/1000\n",
      "4/4 [==============================] - 18s 4s/step - loss: 4385.0562 - val_loss: 5936.2671\n",
      "Epoch 986/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4385.0605 - val_loss: 5936.1816\n",
      "Epoch 987/1000\n",
      "4/4 [==============================] - 24s 5s/step - loss: 4385.0581 - val_loss: 5936.2969\n",
      "Epoch 988/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0566 - val_loss: 5936.3423\n",
      "Epoch 989/1000\n",
      "4/4 [==============================] - 26s 6s/step - loss: 4385.0601 - val_loss: 5936.2705\n",
      "Epoch 990/1000\n",
      "4/4 [==============================] - 40s 10s/step - loss: 4385.0576 - val_loss: 5936.3291\n",
      "Epoch 991/1000\n",
      "4/4 [==============================] - 35s 9s/step - loss: 4385.0586 - val_loss: 5936.4697\n",
      "Epoch 992/1000\n",
      "4/4 [==============================] - 27s 6s/step - loss: 4385.0566 - val_loss: 5936.4639\n",
      "Epoch 993/1000\n",
      "4/4 [==============================] - 24s 6s/step - loss: 4385.0581 - val_loss: 5936.4438\n",
      "Epoch 994/1000\n",
      "4/4 [==============================] - 22s 6s/step - loss: 4385.0576 - val_loss: 5936.5317\n",
      "Epoch 995/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4385.0566 - val_loss: 5936.5312\n",
      "Epoch 996/1000\n",
      "4/4 [==============================] - 33s 9s/step - loss: 4385.0571 - val_loss: 5936.5229\n",
      "Epoch 997/1000\n",
      "4/4 [==============================] - 23s 5s/step - loss: 4385.0562 - val_loss: 5936.5190\n",
      "Epoch 998/1000\n",
      "4/4 [==============================] - 19s 5s/step - loss: 4385.0566 - val_loss: 5936.5610\n",
      "Epoch 999/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 20s 5s/step - loss: 4385.0581 - val_loss: 5936.5049\n",
      "Epoch 1000/1000\n",
      "4/4 [==============================] - 18s 5s/step - loss: 4385.0571 - val_loss: 5936.5273\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist2 = Model2.fit(x_train, y_train, epochs=1000, batch_size=4096, verbose=1, validation_split=0.25)\n",
    "plt.plot(hist2.history['loss'])\n",
    "plt.plot(hist2.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0c4cbf55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406/406 [==============================] - 21s 24ms/step\n",
      "406/406 [==============================] - 13s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "rul_pred1,rul_pred2 = Model1.predict(x_test, verbose =1),Model2.predict(x_test, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e1989e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.reshape(-1,1)\n",
    "res = np.concatenate([y_test, rul_pred1,rul_pred2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4ea3bf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12969, 1)\n",
      "(12969, 1)\n",
      "(12969, 3)\n"
     ]
    }
   ],
   "source": [
    "print(rul_pred1.shape)\n",
    "print(y_test.shape)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "53bed6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(res, columns=['Actual_RUL', 'RUL_pred1', 'RUL_pred2'])\n",
    "res_df.to_csv('Result_naive_DL_RUL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123fc4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b3eb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
